[{"title":"VSCode Remote is all you need!","date":"2019-06-10T14:21:26.000Z","path":"2019/06/10/vscode-remote/","text":"2019年5月的build大会，最让人沸腾的东西就是VSCode Remote这么个东西，号称让机器学习开发者进入远程开发时代，直接打开、管理远程服务器、容器中的文件夹和文件，甚至实现了对远程代码文件的Intelli Sense这套微软的看家本领。这也意味着开发者终于不用在本地电脑中安装五花八门的深度学习框架来写代码了。 7月的VSCode 1.35版本，终于把这个功能放到了VSCode 的 Stable 分支（虽然插件还是预览版），今晚折腾了好一会终于用上了这个真正解放和发展生产力的东西。 Requirements下面将本地称为local，服务器统一称为host。需要安装的东西各有不同。 Local VSCode更新到1.35版本 安装Remote相关插件 Remote plugins 安装OpenSSH，生成公钥。 Host 连接互联网 安装ssh 如果是Python开发者，建议安装anaconda并且搞几个虚拟环境备用 Python的话，为了自动完成、代码补全和错误提示功能，需要安装下面这些东西 pep8 autopep8 flake pylint Configuration同样地，配置也分为host和local两部分。 Host在自己用户home目录下面的.ssh文件夹里面，创建authorized_keys，将local的公钥（id_rsa.pub文件）复制进去。 Local打开VScode，在命令面板shift+⌘+P输入remote，选择Remote-SSH，选择Connect to Host。 选择Connect to Host 输入的内容，形式是username@host-ip。 对于常用的服务器，也可以创建别名，选择“打开配置文件“ 配置文件 按照提示输入别名和username还有ip就完事了。 第一次连接的时候，vscode会在Host安装VSCode Server，需要几分钟时间。记得服务器保持联网。 连接成功时，注意左下角提示 Let‘s Get your hands dirty！连接成功之后会弹出新窗口，选择Open a folder，会让你直接选择Host上面的文件夹 打开文件夹 在正式写代码之前，还需要一些配置，因为本地的插件在远程没办法直接用了。 在插件边栏也会提示你，一些东西可以直接在Remote安装 安装插件到服务器 这里只安装Python。 Plugin Settings事实上，Host和Local在编程环境上是完全隔离的，所以要使用Python代码智能提示，需要安装上面提到的插件，还要在setting里面进行配置。 注意Remote标签 要配置的东西和本地的Python插件差不多，就不赘述了。Reference部分有相关的链接。 效果一切配置完成之后，让我们看看疗效吧！ 错误提示和代码运行 可以看到，运行.py会直接调用远程Python的东西，这里直接识别了Host的Titan XP计算卡。 另外代码提示也是可以正常工作的 Intelli Sense Beyond这套东西可以说是让我对微软重拾信心，它不仅仅可以用于python的开发，Remote-Container功能也能够让代码调试更加方便，比如golang和java的复杂环境配置，直接就可以新开一个容器然后Remote过去，避免本地PATH等混乱的问题。 更多的应用需要开发者们的更大的想象力。 当然也需要微软的不懈努力和不掉链子。再次把崇高的赞美送给这个一万亿的公司。 Reference Developing on Remote Machines using SSH and Visual Studio Code Linting Python in Visual Studio Code","tags":[{"name":"python","slug":"python","permalink":"https://antarx.com/tags/python/"},{"name":"vscode","slug":"vscode","permalink":"https://antarx.com/tags/vscode/"}]},{"title":"fish环境中使用conda解决python多版本问题","date":"2019-04-11T03:02:38.000Z","path":"2019/04/11/conda/","text":"最近在忙百度的一个比赛，官方提供的框架是Python2.7版本的，然而自己生产环境已经用惯python3了，当然不希望重新折腾一番。网上看到有利用conda解决多版本python共存问题的办法（说到底也是使用虚拟环境），无奈都是基于bash的。好不容易基于fish配置完毕，分享一下。 设置虚拟环境首先是利用anaconda设置虚拟环境，使用命令conda create --name python2 python=2.7创建一个基于python2.7的虚拟环境。接下来就是激活虚拟环境的问题，也是碰到最多坑的地方。在bash下面，可以使用source activate python2完成虚拟环境的激活，在fish下面就各种问题，网上找了一下，有个解决方案还算完美。大致如下 使用conda info --root获取安装路径 在config.fish中添加source &lt;PATH_TO_ROOT&gt;/etc/fish/conf.d/conda.fish 执行完毕之后，就可以在fish中使用conda activate python2激活前面创建的虚拟环境了。 参考链接 用 Anaconda 完美解决 Python2 和 python3 共存问题 - FooFish-Python之禅 anaconda - Cannot run source activate with conda in Fish-shell - Stack Overflow","tags":[{"name":"fish","slug":"fish","permalink":"https://antarx.com/tags/fish/"},{"name":"conda","slug":"conda","permalink":"https://antarx.com/tags/conda/"},{"name":"python","slug":"python","permalink":"https://antarx.com/tags/python/"}]},{"title":"济南三天小憩","date":"2019-04-11T01:31:29.000Z","path":"2019/04/11/402/","text":"清明假期去济南瞎*乱逛了三天，对济南这个城市印象还挺深刻的，回来写个流水账。多图预警 “玩水”济南被称为“泉城”，泉眼之多甚至影响了地铁的修建。围绕着泉的景点们自然是非常值得细细品味一下的。 首先便是泉城广场，应该是济南最大的广场，各种知名景点均匀分布在泉城广场的南北两侧。于是第一天从泉城广场出发，沿着护城河一路暴走，先后经过黑虎泉“地带”，大明湖，然后绕回来到趵突泉。 泉城广场 护城河一带是各种泉眼，最具特色的地方是泉水非常清澈，甚至到达了饮用水的标准，一路上各种“扫码取水”随处可见，也有很多大爷大妈带着桶过来打水饮用。跟着他们试饮了一口，确实是够清澈，“有点甜”。 大明湖估摸是济南最出名的景点，毕竟谁没听过“大明湖畔的夏雨荷”呢。大明湖大部分地段都是免费景点，不收取门票直接游玩。一路上柳树成荫，绿意盎然。里面有辛弃疾故居值得参观一下。另外有“超然楼”，是他们主要的收费景点。因为它是个现代的景点，就没花钱进去了（个人还是喜欢看古建筑多一些），在外面拍拍照感觉也还不错。 大明湖 超然楼 从大明湖暴走到趵突泉的路上还经过了五龙潭公园，正在举办樱花节，不过当时已经天色近晚，趵突泉和五龙潭都是六点就停止售票，所以选择了趵突泉。 趵突泉 趵突泉最早是在小学语文课本里面就学到了，真正看到本体的时候并没有想象中的那么震撼，公园里面还有个李清照故居，可以跟着导游听听故事hhhh “游山”济南的⛰️，也是只有“千佛山”这么一座山，第二天的重点便是对付这座山，总体感觉就是“不枉此行”。 千佛山 千佛山因为佛像多而闻名，山腰有个万佛洞，山顶是舜祠等。最带给我震撼的，便是万佛洞了。进去有种探险的感觉，可以看到形态各异的佛像，有三五米高的雕像和卧佛，也有各种“微型”但依然形态各异的佛像组成洞壁。一开始进去的时候有种无穷无尽的错觉，而形态各异的这些佛像又可以让人觉得兴趣昂然。 爬到山顶的过程，非常不幸运选了一条陡峭、狭窄而拥挤的小路，给我一种倾斜45度仰望天空的夜晚芙蓉街的错觉，无形中增加了体力成本和心理上的厌恶感。幸好下山的时候，反而误打误撞走了非常宽敞的路，不知不觉便下来了，打消了之前的厌恶情绪。 山顶 那天刚好碰上了济南人的“三月三”庙会和“可能是故意安排在庙会期间”的大型纸面相亲活动，终于见识到了网上流传已久的那种大爷大妈拿着仔女的信息去挨个看“候选人”的信息然后认真记笔记的“名场面”，还挺震撼的。怎么说呢希望自己以后不会成为这种任君选择的其中一张纸牌吧（。有种摆在货架的过期罐头的感觉emmmmmm 相亲角 人文名胜济南作为山东的省会城市，高校众多。原本想着去山东大学和山师闲逛一番的，无奈时间确实凑不出来，只有在去洪家楼地区的天主教堂出来之后去隔壁的山东大学洪家楼校区逛了一圈。 洪家楼的天主教堂给人的感觉还是蛮震撼的，虽然已经过了可以进去参观的时间点，在外面看也非常的shocking。从远处拍照甚至有点欧陆田园的感觉。 天主教堂 最后一天本来想去山东博物馆和美术馆的，但是博物馆排队的人实在太多，担心时间安排不过来赶不上火车，于是就去了美术馆，刚好赶上了齐白石的画展。在课本中学到的齐白石相关的画虾的典故，和看到真迹，是完全不同的两个感受。除了这个齐白石展览之外，美术馆展出的都是一些现代画展，我这样的俗人并不能看出味道来，只能图个乐子便是了。 齐白石画展 网红景点网红景点单独拎出来。“宽厚里”和“芙蓉街”是网红景点的二霸，之前看攻略的时候有人说是芙蓉街在抖音上火起来带旺了济南的人气的说法。宽厚里是一系列“网红小店”的聚集地，有种鼓浪屿“龙头路”和北京南锣鼓巷的感觉。一开始是对这些一点都不感冒的，不过实际逛下来，两个景点是截然不同的感觉啊。 宽厚里是早上从黑虎泉出来之后去的，或许是因为人不多，或许是因为本身地区就非常大，整体感觉还蛮不错的，一个和同行友人一致认同的重要因素是虽然里面都是网红店但居然没有重复的（此处怒斥接下来提到的芙蓉街）。所以一路逛下来有一种持续的新奇的感觉，非常的奇妙。顺便里面的店卖的东西出品也都还不错，以至于第二天晚上又过去消遣一番。 芙蓉街是第一天的“压轴”景点，然而也是因为这个景点让我们同时差点毁掉了一天的好心情，狭窄，拥挤，一条长长的街下来全是卖着重复的、不亚于流水线生产出来的垃圾食物，空气中飘散着劣质油脂的“腻味”，直教人想逃离。进去的时候还碰上了限流措施然后绕了一大圈才进去，结果给我看这个？虽然一开始就被提醒这里和王府井小吃街差不多，然而没想到这还差远了都。也是整个旅行的一大“不悦”。 饮食文化以前看亚洲电视黄麗梅的《中国八大名菜》就已经知道，鲁菜一直以来在排场和精致程度上都是能够和正统广府粤菜比肩的。这次在济南去了泉城广场附近的一家私房菜馆（感觉济南这边私房菜还挺多的），给我的感觉就是，确实名不虚传。糖醋鲤鱼能够通过调味干掉鲤鱼的腥味同时还能保留鱼肉的鲜嫩，然后另一个叫做“老坛子”的羹类美食，更是把海参，小鲍鱼，虫草花，松茸这些“惹味”炖在一块，充分发挥了食材的“鲜”，让人回味无穷。 下次一定要去青岛烟台这些地方大吃海鲜（小声 另外，济南比较出名的还有糖沫和把子肉。糖沫怎么说呢，和“糖”可是一点都不沾边，有种猪肉粥的感觉，中规中矩吧。把子肉据说是十几块钱一大块的五花肉，然而大家都看着图片都一致嫌腻，所以“打扰了” 除了这些以外，在做攻略的时候就觉得，济南好像没啥特色啊，没有那种看上去就值得专门跑去这个城市品尝的美味，事实上确实也是这样的，毕竟某点评APP上前十必去餐馆还是什么猪肚鸡和日本料理这些hhh但是人家消费便宜啊，随便吃就是了。三天下来在吃得方面倒也并没有发现明显的雷区。 消费济南的消费水平又是一个让我“愉悦”的地方。一顿火锅点了三四个肉菜吃下来人均也就六十出头，在私房菜馆点了三个分量大到boom的肉菜人均不到80，还吃到了海参这样的海味和一整条鲤鱼，宽厚里这样的网红地方排第一的烧烤，撸串喝酒下来人均不到五十。在北京下一次馆子的消费都够这吃一天了。 大概是在北京待久了，去哪都觉得物价便宜吧hhhh 另外还有一点就是，去年年底学到的一个很重要的消费观是先存钱后花钱，然后建立了一个账户专门存钱旅行，这次出门终于感受到这种消费观的“威力”，在存钱和预算允许的范围内随便花钱的感觉真的太爽了！ 交通济南因为地下泉眼太多，地铁迟迟修不起来，临行前几天终于开通了济南一号线，然而却是从一个郊区通往另外一个郊区，和所有景点都毫无关系。所以一路上都是以“暴走🚶”和巴士为主，巴士最先进的地方是支持支付宝微信二维码还有银联闪付，三星Pay解决所有问题，并不需要考虑自备零钱的事情还是挺好的。 济南被戏称为“堵城”，打车的时候司机都在吐槽堵车经历，🚥设置不合理和道路规划成为了一个大问题，虽然近几年开了经十路这种八车道十车道，还是没有完美解决所有问题。白天看地图市中心区几乎所有道路都是红到发黑的emmmm 至于共享单车这种“新四大发明”，只看到了摩拜和哈罗，然而还是没逃脱想骑车的时候看到的都是别人在骑，不用骑车的时候看到一堆🚴available的“共享定律” 对于游客来说，最大好处就是，几乎所有景点都集中在泉城广场为中心的四平方公里的地区，游玩的话靠11路公共汽车便可以解决所有问题。 环境环境上这里并没有给我太好的印象，虽然晚上风非常的大甚至可以把人吹倒，然而白天还是要面临轻度污染，拍照出来都是灰蒙蒙一片，也太不友好了。所以吧，这里也并不是一个适合带着相机游玩的地方了。回到北京呼吸着倒春寒带来的PM2.5指数under 50空气都让我有种如释重负的感觉。 人文气息人文方面的话，总体来说和天津一样是非常悠闲的一个城市，除了几个景点人挤人以外，其他地方生活节奏并没有太快，流淌着舒适安逸的味道。 Misc之所以管这次出门叫做“小憩”，因为济南的悠闲的氛围，极其舒适的消费水平都让人有种逃离大城市的感觉，而景点浓度也不高，不用把三天行程安排的满满当当疲于奔命，称之为休憩真的再合适不过了，和短促的三天假期搭配起来堪称完美。 说要推荐的话，超过三天的假期专门去那就肯定是不划算的了。短假期过去溜达一圈还是可以的，或者作为威海青岛烟台蓬莱这种山东沿海景点游历完毕之后的最后一站也未尝不可（今天晚上从基友口中听到的这波骚操作哈哈哈哈哈）。","tags":[]},{"title":"11月论文阅读总结","date":"2018-11-29T08:48:39.000Z","path":"2018/11/29/papers-nov/","text":"转博了之后平时的工作重心从写代码慢慢的转移到科研读论文复现论文等上面来。选研究方向的时候也费了好大一番功夫去纠结，一开始想继续做微服务和SDN的东西，后面却逐渐发现往深入去做的话又兜兜转转回到了通信的轨道上了。后面终于下定决心做知识图谱的东西。整个十一月都在看知识图谱的论文，主要集中在知识表示领域的几种Translation模型上。 什么是Translation？知识图谱是一种偏向于人类认知的“数据结构”，将实体之间用关系的方式进行链接，比如说“中国的首都是北京“这句话，用知识图谱进行建模的方式就是，“中国”（实体）的首都是（“关系表示”）“北京”（另一个实体）。 这样，一条知识就可以用图这个数据结构的一条边（edge）来表示。参考图的关系描述方式，知识图谱中可以使用 $h,r,t$ 三元组来表示一条“知识”，$h$ 是head，头部知识，知识的端点，在上面的例子中，为“中国”，$r$是relation，表示关系的意思，$t$是tail，在上面的例子中，为“北京”。 知识终究是要喂给计算机进行处理的，计算机只能处理数据信息。知识图谱上面的东西都是离散的，符合人类认知逻辑的，和计算机处理的数据没有半毛钱的关系。因此，就有了知识表示的说法。怎么把图结构表示成计算机可以处理的数据的形式。 Translation，是对知识表示的一种“形容”，目标是将三元组映射到计算机可以处理的连续数值向量空间中，当然了，最好这个空间的维度可以低一些。 Translation Embedding（TransE）TransE，是最早的研究用嵌入（embed）方法来进行知识表示的一篇论文。基本思想就是最直观的将实体关系数据嵌入到低维度向量空间中。 关于TransE，网路上有很多讨论的文章（毕竟出来最早），讨论的内容都大同小异，可以参考TransE算法的理解 | Yaoleo TransE所完成的，是最基本的知识嵌入，忽略了知识中普遍存在的一对多、多对一、自反关系的问题，自反关系中，$r$会被建模成$0$向量；多对一的关系中，因为它的Scoring Function设定为 $\\Vert h-r+t \\Vert$， 假设$h_0,…,h_m$ 均与$t$形成关系$r$，那么$h_0,…,h_m$的向量表示是相等的。一对多的关系同理。 因此，有了TransH。 Translation Hyperplane这个方法是紧跟随TransE提出来的。主要有两个改进的地方（对比TransE） 引入entity的分布式表示。将Relation的表示放在了与entity的不同空间当中（也是Hyperplane的由来）。两个空间（relation和entity之间）的向量表示是一个投影关系（projection） 将现有知识图谱的“未完成”问题考虑进来，负样本的构造过程不再像以往模型那样随机选择，而是基于伯努利分布的一个选择过程。而且对与多对一和一对多时候的“污染源”也是有区别的。 此外Scoring Function和Loss Function也有改进。 OpenKE Toolkit第三篇论文是2018年清华大学发布的，是一个工具包的简介。基于Trans的模型有不下五六种，模型的训练和测试成为了一个难题。而且每提出一个新的算法都要对前面的东西进行重复验证。所以这篇论文中将这几种常见模型的算法集中到了一起，提供统一的接口和数据库，并且保证了向后兼容性。提供了TF和PyTorch的接口，实现GPU训练和CPU多线程并行训练。 在这篇论文中作者还指出，前面的各种Translation算法，本质上最大的区别就是Scoring Function和Loss Function的区别。 参考链接 清华大学开源OpenKE：知识表示学习平台 | 机器之心 里面有上面提到的所有论文的链接。 Zhen Wang, J. Z. J. F. Z. C. (2014). Knowledge Graph Embedding by Translating on Hyperplanes, 1–8. OpenKE: An Open Toolkit for Knowledge Embedding. (2018). OpenKE: An Open Toolkit for Knowledge Embedding, 1–6. Translating Embeddings for Modeling Multi-relational Data. (2013). Translating Embeddings for Modeling Multi-relational Data, 1–9.","tags":[{"name":"科研","slug":"科研","permalink":"https://antarx.com/tags/科研/"}]},{"title":"","date":"2018-11-02T03:22:40.000Z","path":"2018/11/02/configs/sorts/","text":"{\"\":[],\"__positions\":{},\"__raw_positions\":{}}","tags":[]},{"title":"新款 Mac mini 购买可行性分析","date":"2018-11-02T03:20:29.000Z","path":"2018/11/02/macmini/","text":"新款 Mac mini 购买可行性分析（持续更新）10 月 30 号苹果的新品发布会，我望眼欲穿的Mac mini 终于在时隔四年之后迎来了“大更新”，正如之前很多 KOL 所“预言”的一样，是一次面向专业人士的一次更新，最高支援了 i7 六核处理器和 64GB 内存和 2TB 固态，还有万兆以太网接口可选。昨天也同步更新了大陆的价格信息。网络上对于这款产品的评价也是褒贬不一，到底这款产品是不是值得购买呢。 处理器这里只关注 i5 和 i7 版本。 官网处理器规格表 Apple 一般都会和英特尔有定制处理器，根据英特尔® 产品规格，查找 i5 处理器的规格表 第八代 i5 处理器 从基准频率，睿频频率和 L3 缓存规格，基本可以确认，Mac mini 使用的 i5 处理器就是这款 8500B，是基于桌面版的 8500 的修改款。同样可以找到第八代智能英特尔® 酷睿™ i7 处理器 产品规格，可以基本确认 Mac mini 的 i7 处理器是 8700B，是桌面版 8700（不带 k）的修改版（为了适配 Mac mini 的体积而进行散热性能的更改）。可以看到，对比上一代的 Mac mini 使用的低压移动平台处理器，这次的升级可以说是一脚踩爆了牙膏管。要注意的是，第八代 i5 和 i7 处理器（上面说的这两款），最大的区别是超线程支持上，也就是说只有 i7 8700B 这款处理器支持超线程，为 6C12T（6 Core 12 Thread）规格。 内存内存其实没啥好说的，横跨 8GB 到 64GB。比较有意思的是，这一代重新采用了 SO-DIMM 的可插拔内存，理论上可以买 8GB 版本回来自己扩充到 32G 内存，还能省 2000 元。具体的内存更换教程和内存条兼容性报告，等发售和测试之后再更新。 一点吐槽和一点疑问官网的自定义配置上，从 8GB 内存升格到 32GB 内存居然要加四千多。问题是现在内存价格已经回落了啊！！！官网的宣传图片和规格上说是可插拔内存插槽，是不是意味着可以买低内存版本回来自己加爆到 32*2=64G 内存呢？具体情况关注 ifixit 的拆解情况再作判断。 显卡/GPU应该是这次“面向专业人士的升级”中最值得吐槽的地方。之前微博上一直有说法，这次的 Mac mini 会选配 GTX 1050 图形处理器。然而，然而，最后的结果是，全系列，Intel UHD630 集成图形处理器。这个 GPU 是什么概念呢，在显卡天梯图上，这款产品的规格甚至比 2015 mid 的MacBook Pro 15 吋低配的 4770HQ 处理器内置的 Iris 5200 还要低。（能不能顺利带动我的 P2415Q 是很让我困惑的一件事，虽然官网规格说支援同时带两个 4k 显示器） 接口之前一直很担心 Mac mini 更新会不会只给 Thunderbolt 3 接口，甚至连以太网接口会不会砍掉，幸好最后库克证明是我多虑了。 Apple官网接口规格 四个 Thunderbolt 3 接口，两个 USB3.0 接口，还有 HDMI2.0 和千兆以太网接口（可选万兆），覆盖了日常使用的所有接口类型，总而言之，管够！ 外接设备的可能性探讨最重要的外接设备形式，就是自 macOS High Sierra 10.13.4 开始支援的 eGPU 了。关于 Mac 对 eGPU 原理的讨论，大别ibuick的微博上面有篇文章讨论的非常详细，我这里就不班门弄斧。有需要的可以自行参阅研究。总的来说，外接 eGPU 可以满足视频渲染、照片处理等重型任务的需求，对于程序员（包括我）最关心的科学计算、深度学习任务可不可以使用 eGPU 进行加速的问题，目前调查到的情况有这几点： 显卡硬件方面。 NVIDIA Pascal 及以上架构的显卡（GTX10 开始）在 macOS Mojave 10.14 系统上还没发布驱动包（据说是还没通过苹果的审核）。 AMD 显卡，有ROCm, a New Era in GPU Computing方案实现 TensorFlow 调用 AMD GPU 资源进行计算加速。问题是 ROCm 到目前为止不支持 macOS。 软件兼容性层。NVIDIA 有发布 CUDA 以及 CuDNN for macOS。 同样的，这两个软件依然没有支持 macOS Mojave TensorFlow for macOS 可以通过自编译的方式实现 GPU 支持。 就算以后打通了 NVIDIA eGPU + CUDA + CuDNN + TensorFlow for macOS 的完整流程，由于 Docker for macOS 是一种虚拟机实现方案，所以也许永远不会有 Nvidia-Docker for macOS 来实现更简单的开发环境部署和 Python 环境隔离。 对于 macOS High Sierra 系统和 Pascal 以下的显卡，已经有非常详细的教程Training Your Neural Net with eGPU Acceleration on Mac with Tensorflow 1.5实现 2.3 所说的完整流程。 其他外接设备显示器 预算有限的，可以选 dell P2415Q，目前非 Ultrafine 荧幕里面 PPi 最接近视网膜的。接一般的 4k 荧幕（泛指所有尺寸在 27 寸及以上的 4k 荧幕），同样可以实现 HiDPI 缩放，具体判断是接入显示器之后，设置连接模式为扩展，然后打开显示器选项，选择缩放，看到的是下面这样的截图 而不是让你选择物理分辨率。HiDPI 技术对显示效果的影响，具体来说就是两种显示器（支持 HiDPI 和普通显示器），macOS 在渲染输出的时候会采用不同的色彩空间（对于后者，在系统中会被识别成“电视”，使用 YUV），看起来会觉得后者的字体锯齿甚至比 Windows10 外接高分屏荧幕更加严重。2k 显示器可以通过软件修改的方式实现 HiDPI，缺点是每次系统升级都可能导致不能用。 预算充足的，直接 LG Ultrafine 系列。机械键盘ikbc G104 和阿米洛的 Mac 系列都是原生 Mac 键位支持。也可以买 Windows 键盘回来自己改键位和键帽，全凭个人喜好了。","tags":[{"name":"macOS","slug":"macOS","permalink":"https://antarx.com/tags/macOS/"}]},{"title":"go模块入门","date":"2018-09-03T07:25:44.000Z","path":"2018/09/03/gomod/","text":"Go 模块入门Go1.11 的一个重要特性就是 go modules，作为 Go 一直以来版本管理顽疾的官方解决方案，自然是非常值得重视的。最近看到一篇文章对它阐述的非常好，所以就翻译过来。 原文链接：Introduction to Go Modules – Roberto Selbach Go 语言的1.11版本即将带来modules 的实验性支持，这是 Go 语言中一个全新的依赖管理系统。 早前我写过一篇文章来阐述 Go 的模块，但里面的很多东西在那篇文章之后都发生了变化，所以就有了这篇文章，用更多的上手实践来介绍这个特性。 在这篇文章里，我们会创建一个新的包（package）和发布一些版本来验证 go 模块是如何工作的。 创建一个模块首先，我们创建一个命名为“testmod”的包。一个重要的细节是，包文件夹应该在$GOPATH以外，因为在$GOPATH目录下，模块功能是默认关闭的。某种程度上可以认为 Go modules 是削弱$GOPATH职能的第一步。 12$ mkdir testmod$ cd testmod 包的内容非常简单， 12345678package testmodimport \"fmt\"// Hi returns a friendly greetingfunc Hi(name string) string &#123; return fmt.Sprintf(\"Hi, %s\", name)&#125; 这样不是一个模块，需要做以下变更 12$ go mod init github.com/robteix/testmodgo: creating new go.mod: module github.com/robteix/testmod 这个命令会在目录下创建go.mod文件，内容如下 1module github.com/robteix/testmod 这些步骤已经将我们的包转换成一个模块，我们可以把这些代码推送到仓库中， 1234$ git init $ git add * $ git commit -am \"First commit\"$ git push -u origin master 这样，其他人可以通过go get github.com/robteix/testmod来使用这个包 这个操作会拉取master分支下的代码。这依然有效，但我们应该停止这么做因为我们找到了更好的方法。拉取master分支的做法是具有潜在危险性的，因为我们不能确定软件包的作者会不会作出一些让我们的调用不再生效的更改。这是 modules 主要想改善的状况。 Module Versioning 简介Go 模块是支持版本的概念的，也支持特别对待一些特殊的版本。首先（运用这些特性之前）你要熟悉语义化版本的概念。 更重要的是，Go 使用仓库标签的方式来查找版本，某些版本会与众不同，比如version 2或者更高的版本应该享受与0或1版本不同的导入路径。 与此同时，Go 会默认拉取仓库中最新的可用标记版本（tagged version），这是非常值得注意的地方因为在此之前你或许已经习惯了使用 master 分支。 现在你需要知道的是为了发布我们的软件包，我们需要对软件仓库的代码用版本号来打标签，让我们开始吧！ 第一次发布让我们把写好的软件包发布出去。我们使用版本号标签的方式来实现，比如说发布1.0.0版本 12$ git tag v1.0.0$ git push --tags 这会在我的 GitHub 仓库上面将当前的提交标记为1.0.0发布版。 为这次发布创建一个新分支是一个好主意，尽管 Go 不会强制要求我们这样做。 12$ git checkout -b v1$ git push -u origin v1 现在我们可以专注于 master 分支，不用担心会破坏我们的发布版本。 使用我们的模块我们将会创建一个简易程序来演示如何使用我们的模块/ 1234567891011package mainimport ( \"fmt\" \"github.com/robteix/testmod\")func main() &#123; fmt.Println(testmod.Hi(\"roberto\"))&#125; 在之前，你可以通过go get github.com/robteix/testmod来下载软件包，但使用模块功能，事情会变得有趣。首先我们要在自己的程序中开启模块功能 1go mod init mod 它会创建go.mod文件，内容如下 1module mod 当我们在试图构建我们的代码的时候事情变得有趣起来， 123$ go buildgo: finding github.com/robteix/testmod v1.0.0go: downloading github.com/robteix/testmod v1.0.0 正如我们所见，go命令获取程序需要用到的软件包。这时候如果我们打开go.mod文件，可以看到 12module modrequire github.com/robteix/testmod v1.0.0 另外我们会看到一个名为go.sum的新文件，包含了软件包的哈希值，确保我们下载了正确的版本和对应的二进制文件。 12github.com/robteix/testmod v1.0.0 h1:9EdH0EArQ/rkpss9Tj8gUnwx3w5p0jkzJrd5tRAhxnA=github.com/robteix/testmod v1.0.0/go.mod h1:UVhi5McON9ZLc5kl5iN2bTXlL6ylcxE9VInV71RrlO8= 发布修复 bug 的版本现在假设我们意识到程序中存在的一个问题，打招呼的语句缺少标点符号。人们会因为我们这个程序的不够友好而勃然大怒，所以我们用新版本来修复这个问题 12345// Hi returns a friendly greetingfunc Hi(name string) string &#123;- return fmt.Sprintf(\"Hi, %s\", name)+ return fmt.Sprintf(\"Hi, %s!\", name)&#125; 我们在v1分支进行更改因为这与我们稍后在v2版本要做的事情毫无关系。在实际应用中，你或许会直接在 master 分支上干这件事情。无论哪种方式，我们需要修复我们v1分支上的代码并且标记成一个新的发布版本。 123$ git commit -m \"Emphasize our friendliness\" testmod.go$ git tag v1.0.1$ git push --tags origin v1 更新模块在默认情况下，Go 在未经许可之前不会更新模块，这是一件好事因为我们希望软件构建过程是可以预测的。如果 Go 模块每次有新版本发布的时候都会自动更新，我们会回到 Go1.11的一个非常原始的版本。现在，我们需要告诉 Go 来更新模块。 在老版本的go get，我们可以这样做 go get -u来获取minor或者 patch 更新，比如从1.0.0更新到1.0.1或者1.1.0 go get -u=patch 来获取最新的patch更新（会更新到1.0.1但不会更新1.1.0） go get package@version 来更新特定的版本。 在上面所说的措施里面，没有一个可行的举措来更新到最新的major版本，我们稍后会看到，这是有原因的。 因为我们的程序使用的是1.0.0版本的软件包，我们刚刚创建了1.0.1版本，以下任意一个命令会更新我们的软件包到1.0.1 123$ go get -u$ go get -u=patch$ go get github.com/robteix/testmod@v1.0.1 运行以上任意命令之后，go.mod文件更改为 12module modrequire github.com/robteix/testmod v1.0.1 主版本更新根据语义化版本的语法，主版本（major version）不同于小版本更新（minors）。主版本可以破坏后向兼容性。Go模块的观点中，主版本是完全不同的软件包。这一点最开始看来非常的奇怪，但是讲得通的：两个版本的库是不兼容的，这是两个完全不同的库。 让我们创建软件包的一个主要版本，为greeting函数提供一个新的参数， 12345678910111213141516171819202122package testmodimport ( \"errors\" \"fmt\")// Hi returns a friendly greeting in language langfunc Hi(name, lang string) (string, error) &#123; switch lang &#123; case \"en\": return fmt.Sprintf(\"Hi, %s!\", name), nil case \"pt\": return fmt.Sprintf(\"Oi, %s!\", name), nil case \"es\": return fmt.Sprintf(\"¡Hola, %s!\", name), nil case \"fr\": return fmt.Sprintf(\"Bonjour, %s!\", name), nil default: return \"\", errors.New(\"unknown language\") &#125;&#125; 使用我们 API 的现有软件在新版本之下不能运行因为他们不会传递一个语言参数而且不会返回一个错误，我们的新 API 不再与1.x 版本兼容。所以是时候更新2.0.0版本。 我之前提过有些版本有一些具体的特性，这里是具体的例子，Version 2 及以上的版本要修改导入路径，他们现在是不同的库。 我们通过在导入路径中加入新版本号来实现 1module github.com/robteix/testmod/v2 剩下要做的事和之前的差不多，把代码推送到软件仓库，标签为2.0。0版本，创建 v2分支 123456$ git commit testmod.go -m \"Change Hi to allow multilang\"$ git checkout -b v2 # optional but recommended$ echo \"module github.com/robteix/testmod/v2\" &gt; go.mod$ git commit go.mod -m \"Bump version to v2\"$ git tag v2.0.0$ git push --tags origin v2 # or master if we don't have a branch 主要版本更新虽然我们发布了软件库的新的、不兼容的版本，但现有的软件不会失效，因为它会继续使用现有的1.0.1版本，go get -u不会更新到2.0.0版本。 在某些场合，库的使用者可能会想要更新到2.0.0版本因为可能存在需要多语言支持的用户。 通过适度的修改来实现 1234567891011121314package mainimport ( \"fmt\" \"github.com/robteix/testmod/v2\" )func main() &#123; g, err := testmod.Hi(\"Roberto\", \"pt\") if err != nil &#123; panic(err) &#125; fmt.Println(g)&#125; 之后，当我运行go build的时候，它会下载2.0.0版本。注意到，即使这个导入路径是以“v2”结尾，Go 依然可以正确引用模块名字（“testmod”） 正如我之前提到的是，主版本从各方面来说都是完全不同的包版本，Go 模块不会连接到两个不同的版本，这意味着我们可以在同一个程序里面使用两个不兼容的库版本。 123456789101112131415package mainimport ( \"fmt\" \"github.com/robteix/testmod\" testmodML \"github.com/robteix/testmod/v2\")func main() &#123; fmt.Println(testmod.Hi(\"Roberto\")) g, err := testmodML.Hi(\"Roberto\", \"pt\") if err != nil &#123; panic(err) &#125; fmt.Println(g)&#125; 这个举措降低了包管理体系里面常见问题的负面影响：在同一软件中依赖了同一个库的不同版本。 整理回到那个只用testmod v2.0.0版本的软件，我们再看go.mod的内容，我们注意到 123module modrequire github.com/robteix/testmod v1.0.1require github.com/robteix/testmod/v2 v2.0.0 默认情况下 Go 不会主动移除过时版本的依赖，如果你不再使用并且想进行清理，你可以使用tidy命令 1go mod tidy 现在go.mod里面只有我们在使用的软件包版本。 Vendoring默认情况下 Go 模块忽略vendor/目录。这个构想是为了废除vendoring机制，但如果我们依然想加入vendor依赖的话，依然可以实现。 1go mod vendor 它会在你项目的根目录下创建vendor/目录，目录里面是你源代码的所有依赖关系。 同样地，go build会忽略这个目录下的所有内容，如果你想从这个目录中构建依赖关系，你需要输入 1go build -mod vendor 我觉得很多开发者会在自己的机器上面使用正常状态下的go build而在持续集成的环境里使用-mod vendor 需要再次强调的是，Go 模块已经彻底抛弃了 vendoring 思想，转而使用 Go 模块代理，因为很多人不想直接依赖上游版本控制服务。 结论这篇东西多多少少看起来有点劝退的意味，不过我尝试在一篇文章里解释多个概念，事实上 Go 模块是非常透明的，我们只需要像往常一样在代码中导入需要使用的代码然后go命令会帮我们做完剩下的所有事情。 当我们构建应用的时候，会自动拉取依赖关系。Go 模块同样削弱了$GOPATH的必要性，这玩意是新入门的 Go 开发者的一大绊脚石，他们往往无法理解问什么所有东西都要放到同一个目录中。","tags":[{"name":"go","slug":"go","permalink":"https://antarx.com/tags/go/"},{"name":"文章翻译","slug":"文章翻译","permalink":"https://antarx.com/tags/文章翻译/"}]},{"title":"豆瓣电影海报下载-Workflow","date":"2018-07-17T13:03:53.000Z","path":"2018/07/17/dbmv/","text":"Preface最近实验室里买了打印机，手账 er 多年以来的为电影手账贴上海报缩略图的心愿终于有机会打成了。 那么问题来了，去哪找电影海报可以更快更方便呢？每次都是打开网页-&gt;搜索-&gt;图片另存为，太麻烦。于是我盯上了 Alfred，于是就有了这个工具。 使用首先配置好文件储存的路径，如下图 配置文件 在 Alfred 中输入 dbmv，选择 setting，在配置文件中的img_path输入想要保存图片的目录。 然后就可以愉快的使用了。 ⌘ + Space 唤醒 Alfred 窗口，输入 dbmv 启动 Workflow。 选择 Movie 输入想要搜索的电影名字 在搜索结果中选择要下载的电影海报， 回车确认，然后在目标路径就会看到下载好的海报了。 使用 dbmv 下载地址Releases · gawainx/dbmv 特别鸣谢本 Workflow 系基于做了一个豆瓣搜索的 Workflow for Alfred - 海边的石头作品的改写。","tags":[{"name":"Mac","slug":"Mac","permalink":"https://antarx.com/tags/Mac/"},{"name":"Alfred","slug":"Alfred","permalink":"https://antarx.com/tags/Alfred/"}]},{"title":"gxd-cli is gawainx' docker client","date":"2018-06-27T08:42:27.000Z","path":"2018/06/27/gxd-cli/","text":"gxd-cli : 一种快速创建多容器工具通过 docker run 命令行启动容器的时候，配置网络、挂载卷是一件非常麻烦的事，gxd-cli将这些麻烦的工作简化成修改配置文件TOML达成在不需要记忆繁琐的 docker 命令行参数就能快速启动多容器。 功能列表 创建多容器，创建每个容器过程可以配置一下选项 挂载卷（支持以pwd指代当前路径） 指定容器的网络 自定义容器名 设定容器暴露的端口 创建网络 快速生成模板文件 安装支持从源码构建，构建之前首先保证系统已经安装golang和dep步骤如下: 123git clone git@github.com:gawainx/gxd-cli.gitdep ensure -updatego install 安装完毕后在命令行通过gxd-cli调用。 项目地址gawainx/gxd-cli","tags":[{"name":"go","slug":"go","permalink":"https://antarx.com/tags/go/"},{"name":"docker","slug":"docker","permalink":"https://antarx.com/tags/docker/"}]},{"title":"golang/dep 包管理（一）原理","date":"2018-06-12T13:17:51.000Z","path":"2018/06/12/dep/","text":"Golang 包依赖管理工具golang 一直以来一个为人诟病的问题就是没有完善可用的包管理工具（类比 java 的 gradle 和 maven，Python 的 pip，nodejs 的 npm），这与 golang 的追求简约高效的原则有关。golang 1.5版本之后引入了vendor机制，1.8之后终于有了官方的包管理工具，golang/dep。 四元组架构 相关链接Golang依赖管理工具：Dep - 乐金明的博客 | Robin BlogModels and Mechanisms · depgolang/dep: Go dependency management tool","tags":[{"name":"go","slug":"go","permalink":"https://antarx.com/tags/go/"},{"name":"golang","slug":"golang","permalink":"https://antarx.com/tags/golang/"}]},{"title":"TED 200 资源整理","date":"2018-06-11T08:43:05.000Z","path":"2018/06/11/ted-categories/","text":"【TED演讲】怎样的压力，会让一个人放弃生命？ 「TED/4P字幕」语言如何形塑出我们的思考方式，多学一门语言的好处 /How language shapes the way we think 邪教组织如何重新连接大脑 【TED双语】推动学习革命_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili WB Yeats Poems Inspired By Maud Gonne | Indie Author Orna Ross &gt; He Wishes for the Cloths of Heaven, Had I the heavens’ embroidered cloths, Enwrought with golden and silver light, The blue and the dim and the dark cloths Of night and light and the half-light, I would spread the cloths under your feet: But I, being poor, have only my dreams; I have spread my dreams under your feet; Tread softly because you tread on my dreams.","tags":[]},{"title":"go docker client 使用教程（二）","date":"2018-06-01T03:05:44.000Z","path":"2018/06/01/go-docker-02/","text":"Docker client for golang 使用教程（二）：网络端口绑定将微服务放到 docker 容器中运行的时候，端口绑定是一个无可避免的问题。在 docker 命令行中，可以通过简单的-p 8080:80解决问题。但在 golang client 中，问题却变得复杂起来。 首先来看创建容器的函数签名func (cli *Client) ContainerCreate(ctx context.Context, config *container.Config, hostConfig *container.HostConfig, networkingConfig *network.NetworkingConfig, containerName string) (container.ContainerCreateCreatedBody, error),client 把运行配置拆分成了container.Config 和 container.HostConfig ，也就是容器内部设置和宿主机设置两项。 要实现端口绑定，首先要在容器设置中设定暴露的端口（exposed ports）。 1234567exports := make(nat.PortSet, 10)port, _ := nat.NewPort(\"tcp\", \"80\")exports[port] = struct&#123;&#125;&#123;&#125;// in config:cli.ContainerCreate(ctx, &amp;container.Config&#123; ExposedPorts:exports,&#125; 然后，在 host.config 中，设置Host 端口与容器暴露出来的端口的绑定。 1234567891011ports := make(nat.PortMap)pb := make([]nat.PortBinding,0)pb = append(pb,nat.PortBinding&#123; HostPort:\"8080\",&#125;)ports[port] = pb//in Host.config&amp;container.HostConfig&#123; PortBindings:ports,&#125; 至此，在代码中就实现了端口绑定的操作。然而，如果只执行到这一步，编译器一般会报非常诡异的 类型不匹配错误 参考go操作docker - 简书的解决方法，删除gopath里面pkg下面docker的vendor里面相应的connections包，然后运行go get github.com/docker/go-connections/nat ，问题解决。 相关链接 client - GoDoc go操作docker - 简书","tags":[{"name":"go","slug":"go","permalink":"https://antarx.com/tags/go/"},{"name":"golang","slug":"golang","permalink":"https://antarx.com/tags/golang/"},{"name":"docker","slug":"docker","permalink":"https://antarx.com/tags/docker/"}]},{"title":"go docker client 使用教程（一）","date":"2018-05-29T03:05:41.000Z","path":"2018/05/29/go-docker-01/","text":"Docker client for golang 使用教程（一）Docker 官方提供了适用于 golang 的 client，可惜的是网上几乎没有完整可用的使用教程或者例子。在开发gxd-cli的过程中，需要大量使用到这个 SDK，所以便有了这个系列。 本篇涉及通过代码运行第一个容器，以及如何挂载卷。 运行第一个容器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/* *Gawain Open Source Project *Author: Gawain Antarx *Create Date: 2018-May-29 **/package mainimport ( \"github.com/docker/docker/client\" \"github.com/docker/docker/api/types\" \"github.com/docker/docker/api/types/container\" \"io\" \"os\" \"context\" \"fmt\")func main() &#123; ctx := context.Background() cli, err := client.NewClientWithOpts(client.WithVersion(\"1.37\")) if err != nil &#123; panic(err) &#125; resp, err := cli.ContainerCreate(ctx, &amp;container.Config&#123; Image: \"alpine:latest\", Cmd: []string&#123;\"echo\",\"hello\"&#125;, &#125;, nil, nil, \"\") if err != nil &#123; panic(err) &#125; if err := cli.ContainerStart(ctx, resp.ID, types.ContainerStartOptions&#123;&#125;); err != nil &#123; panic(err) &#125; statusCh, errCh := cli.ContainerWait(ctx, resp.ID, container.WaitConditionNotRunning) select &#123; case err := &lt;-errCh: if err != nil &#123; panic(err) &#125; case &lt;-statusCh: &#125; out, err := cli.ContainerLogs(ctx, resp.ID, types.ContainerLogsOptions&#123;ShowStdout: true&#125;) if err != nil &#123; panic(err) &#125; io.Copy(os.Stdout, out)&#125; 官方使用client.NewEnvClient()来初始化client，在 IDE 中提示这个接口已经过时，推荐使用client.NewClientWithOpts()。要注意的是，直接调用的时候一般会提示 API 版本不匹配，需要加client.WithVersion(&quot;1.37&quot;)作为参数传入。1.37部分可以根据它的错误提示自行修改。 绑定卷将自己代码放入容器中运行时最基本的操作，在命令行中通过-v {host vol}:{container vol}实现，在 golang sdk 中，开发者却没有提供这部分的重要说明。通过查阅issue155以及issue1，得到的解决方案如下。 卷绑定通过client.ContainerStart()里面的参数client.HostConfig结构的Binds传入，传入的类型是[]string，这个字符串序列的中每个字符串的格式{host_vol}:{com_col}，也就是和命令行的一致。","tags":[{"name":"docker","slug":"docker","permalink":"https://antarx.com/tags/docker/"}]},{"title":"LaTeX排版学术论文工具链","date":"2018-05-21T02:48:35.000Z","path":"2018/05/21/latex-toolchain/","text":"LaTeX 排版工具链 这里整理了 $\\LaTeX$ 排版学术论文的工具链。根据自己的实践和大家的留言补充定期更新。 操作系统，软件等$\\LaTeX$ 可以在 Windows、Linux 和 macOS 平台上运行。Windows 上可以安装 MikTex，Linux 上有 TeX Live，考虑美观度和排版过程的愉悦度，本人使用的 LaTeX 排版环境大致如下： OS : macOS(Darwin) 编辑器：Microsoft VSCode 插件：LaTeX Workshop $\\LaTeX$ 软件：MacTeX 工具包 PDF 阅读工具：skim 模板IEEE tranbare_jrnl.tex最新版本应该是 v1.7，但在网上好像找不到这个最新的版本，准备整理一个多文件编译的版本放到 GitHub 上。 欢迎留言补充其它模板。:) 数学公式数学符号集 插入伪代码（算法宏包的相关使用）LaTeX算法排版 代码使用listings宏包。LaTeX/Source Code Listings但这个宏包没有 golang 语法高亮支持的！要使 golang 语法高亮，可添加宏包listings-golang 图片与表格首先要理解浮动体的概念，LaTeX 中的浮动体：浮动算法 学习资源LaTeX 开源小屋Begin LaTeX in minutesLaTeX 入门","tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://antarx.com/tags/LaTeX/"}]},{"title":"博客迁移腾讯云小记","date":"2018-05-11T09:30:58.000Z","path":"2018/05/11/hexossl/","text":"博客迁移腾讯云实战记录源于年初的一次突发奇想，将博客站点迁移到了腾讯云，五月份终于完成了备案，然后添加了 HTTPS 支援，并完成容器化。在这里把折腾的过程记录下来。 转移腾讯云原来的博客是放到 github page 上面，访问 antarx.com 是通过 CNAME 文件解析到 gawainx.github.io，只需要在config.yaml配置好，写完直接hexo d -g完事。 迁移到腾讯云之后，还想每次部署都这么方便，就免不了完成一些相关工作。 资源准备这里准备的资源主要就是服务器的购入，可以根据自己博客的规模需要选择合适的套餐。如果是学生党记得使用学生优惠。买完服务器就是装系统的事，根据自己的使用习惯自行选择，我用的是 ubuntu16.04.如果想容器化的话需要安装 Docker。 安装 git1sudo apt-get install git 新建 git 裸仓库123456sudo mkdir /var/repo/sudo chown -R $USER:$USER /var/repo/sudo chmod -R 755 /var/repo/cd /var/repo/git init --bare hexo_static.git 创建存放 hexo 生成的网页的文件夹123sudo mkdir -p /var/www/hexosudo chown -R $USER:$USER /var/www/hexosudo chmod -R 755 /var/www/hexo 这两步要注意的是文件夹的 owner 问题，要实现自动部署的话一般新建一个 git 账户然后全权接管部署网页的相关工作，那么上面创建的两个文件夹在后期的 owner 记得要变更为 git 用户。 创建 git 钩子在hexo_static.git文件夹的 hooks 目录下面新建钩子文件并写入如下代码，然后将文件变更成可执行文件。 12345678vim /var/repo/hexo_static.git/hooks/post-receive# post-receive file content#!/bin/bashgit --work-tree=/var/www/hexo --git-dir=/var/repo/hexo_static.git checkout -fchmod +x /var/repo/hexo_static.git/hooks/post-receive 自动部署所谓自动部署，就是在每次部署的时候不需要键入密码。在自己电脑上，创建公钥，复制到剪贴板 12ssh-keygen -t rsa -C \"xx@xx.com\"pbcopy &lt; ~/.ssh/id_rsa.pub 服务器上，切换到 git 用户（没有的话请新建），输入 1234567su gitcd ~mkdir .sshvim .ssh/authorized_keys#粘贴自己电脑的 公钥，然后保存chmod 600 ~/.ssh/authorized_keyschmod 700 ~/.ssh 本地 hexo-git 配置在config.yaml键入 1234deploy: type: git repo: git@CVM 云服务器的IP地址:/var/repo/hexo_static branch: master 添加 SSL 证书并容器化 NginxLinux 配置软件向来复杂，所以毫不犹豫选用 docker 容器进行 Nginx 部署。输入docker pull nginx拉取 Nginx 镜像。 首先基于镜像运行一个 nginx 容器，然后将容器里面的/etc/nginx/目录拷贝出来。可以看到文件内容如下图 Nginx 配置目录 。这里顺带一提 Nginx 的两个配置文件，nginx.conf和deafult.conf，一般而言修改nginx.conf然后把deafult里面的内容注释掉会比较妥当。 添加 SSL 证书在拷贝出来的nginx.conf文件，在http的选型里面，加入以下内容 123456789101112131415server &#123; listen 443; server_name 你的站点名称; #填写绑定证书的域名 ssl on; ssl_certificate /cert/你的证书.crt; ssl_certificate_key /cert/你的私钥.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置 ssl_prefer_server_ciphers on; location / &#123; root /blog; #站点目录 index index.html index.htm; &#125; &#125; 如果强制使用 HTTPS，还要加上以下配置，将80端口的流量重定向到443端口。 12345server &#123; listen 80; server_name antarx.com; rewrite ^(.*)$ https://$&#123;server_name&#125;$1 permanent; &#125; 这两个 server 是独立的，都加到http的配置里面。顺带一提 Nginx 要求的证书是 PEM 格式。 运行博客容器 1docker run -d -p 443:443 -p 80:80 -v `pwd`:/etc/nginx -v /var/www/hexo:/hexo -v \"$PWD/cert\":/cert --name ng nginx 这里注意到的是三个挂载卷，分别是配置文件，博客网页文件和证书文件。 容器运行之后，在腾讯云的域名管理里面添加 DNS 记录，OK，大功告成。 相关链接在 Ubuntu 14.04 服务器上部署 Hexo 博客Hello Hexo之静态博客搭建+自动部署证书安装指引Nginx 容器教程（可能无法访问）","tags":[{"name":"hexo","slug":"hexo","permalink":"https://antarx.com/tags/hexo/"}]},{"title":"gorequest中文文档(非官方)","date":"2018-05-05T11:19:43.000Z","path":"2018/05/05/gorequest-doc/","text":"Gorequest指南gorequest为 golang 程序提供了极为简便的方式发起 HTTP 请求。网上关于这个库的中文教程不多，因此把官方的 README 文件翻译过来，结合自己的一些使用经验，希望能为各位 Gopher 提供一些帮助。 GopherGoRequest 特性 支持发送Get/Post/Put/Head/Delete/Patch/Options 请求 建议的请求头设置 JSON 支持：以 JSON 格式字符串作为函数参数的方式简化传输 JSON 的步骤。 分段支持：分段请求（Multipart Request）的方式发送数据或传输文件 代理：支援通过代理的方式发送请求。 Timeout：为请求设置时间限制 TLS(传输层安全协议)相关设定。 TLSClientConfig - taking control over tls where at least you can disable security check for https 重定向策略 Cookie：为请求添加 cookie CookieJar - automatic in-memory cookiejar 基本的权限认证。 安装1$ go get github.com/parnurzeal/gorequest 文档参阅Go Doc后续我会根据自己在开发中使用经验将文档翻译过来。 使用 GoRequest 的一万个理由？通过 GoRequest 可以使工作变得更简单，使可以发起 HTTP 请求这件事更加优雅而充满乐趣。 不使用本库发起简单 GET 请求： 1resp, err := http.Get(\"http://example.com/\") 使用 GoRequest 12request := gorequest.New()resp, body, errs := request.Get(\"http://example.com/\").End() 如果你不想重用request，也可以写成下面这样 1resp, body, errs := gorequest.New().Get(\"http://example.com/\").End() 如果你需要设定 HTTP 头，设定重定向策略等，使用标准库会瞬间使事情变得异常复杂，在发起仅仅一个 GET 请求的过程，你就需要一个 Client，通过一系列不同的命令来设定 HTTP 头（HTTP Headers）。 12345678client := &amp;http.Client&#123; CheckRedirect: redirectPolicyFunc,&#125;req, err := http.NewRequest(\"GET\", \"http://example.com\", nil)req.Header.Add(\"If-None-Match\", `W/\"wyzzy\"`)resp, err := client.Do(req) 现在，你有更加美妙的方式来完成这件事 12345request := gorequest.New()resp, body, errs := request.Get(\"http://example.com\"). RedirectPolicy(redirectPolicyFunc). Set(\"If-None-Match\", `W/\"wyzzy\"`). End() 发起 DELETE, HEAD, POST, PUT, PATCH 请求的过程和发起 GET 请求类似。 123456request := gorequest.New()resp, body, errs := request.Post(\"http://example.com\").End()// PUT -&gt; request.Put(\"http://example.com\").End()// DELETE -&gt; request.Delete(\"http://example.com\").End()// HEAD -&gt; request.Head(\"http://example.com\").End()// ANYTHING -&gt; request.CustomMethod(\"TRACE\", \"http://example.com\").End() 处理 JSON用标准库发起 JSON POST ，你需要先将 map 或者 struct格式的数据包装（Marshal）成 JSON 格式的数据，将头参数设定为’application/json’（必要时还要设定其他头），然后要新建一个http.CLient变量。经过这一系列的步骤，你的代码变得冗长而难以维护 1234567891011m := map[string]interface&#123;&#125;&#123; \"name\": \"backy\", \"species\": \"dog\",&#125;mJson, _ := json.Marshal(m)contentReader := bytes.NewReader(mJson)req, _ := http.NewRequest(\"POST\", \"http://example.com\", contentReader)req.Header.Set(\"Content-Type\", \"application/json\")req.Header.Set(\"Notes\",\"GoRequest is coming!\")client := &amp;http.Client&#123;&#125;resp, _ := client.Do(req) 至于 GoRequest， JSON 支持是必须的，所以，用这个库你只需要一行代码完成所有工作 12345request := gorequest.New()resp, body, errs := request.Post(\"http://example.com\"). Set(\"Notes\",\"gorequst is coming!\"). Send(`&#123;\"name\":\"backy\", \"species\":\"dog\"&#125;`). End() 另外，它同样支持结构体类型。所以，你可以在你的请求中发送不同的数据类型（So, you can have a fun Mix &amp; Match sending the different data types for your request）。 12345678910type BrowserVersionSupport struct &#123; Chrome string Firefox string&#125;ver := BrowserVersionSupport&#123; Chrome: \"37.0.2041.6\", Firefox: \"30.0\" &#125;request := gorequest.New()resp, body, errs := request.Post(\"http://version.com/update\"). Send(ver). Send(`&#123;\"Safari\":\"5.1.10\"&#125;`). End() Not only for Send() but Query() is also supported. Just give it a try! :) 回调（Callback）此外，GoRequest 支持回调函数，这让你可以更加灵活的使用这个库。下面是回调函数的一个例子 1234func printStatus(resp gorequest.Response, body string, errs []error)&#123; fmt.Println(resp.Status)&#125;gorequest.New().Get(\"http://example.com\").End(printStatus) Multipart/Form-Data你可以将请求的内容类型设定为multipart来以multipart/form-data的方式发送所有数据。这个特性可以帮助你发送多个文件。下面是一个例子 1234gorequest.New().Post(\"http://example.com/\"). Type(\"multipart\"). Send(`&#123;\"query1\":\"test\"&#125;`). End() 如果感兴趣可以在文档中查看SendFile函数部分获取更多。 代理（Proxy）需要使用代理的时候，可以用 GoRequest Proxy Func 很好的处理。 1234request := gorequest.New().Proxy(\"http://proxy:999\")resp, body, errs := request.Get(\"http://example-proxy.com\").End()// To reuse same client with no_proxy, use empty string:resp, body, errs = request.Proxy(\"\").Get(\"http://example-no-proxy.com\").End() 基本认证添加基本的认证头信息 12request := gorequest.New().SetBasicAuth(\"username\", \"password\")resp, body, errs := request.Get(\"http://example-proxy.com\").End() 超时处理（Timeout）与 time 库结合可以设置成任何的时间限制。 12request := gorequest.New().Timeout(2*time.Millisecond)resp, body, errs:= request.Get(\"http://example.com\").End() Timeout 函数同时设定了连接和 IO 的时间限制。 以字节方式处理返回体（EndBytes）1resp, bodyBytes, errs := gorequest.New().Get(\"http://example.com/\").EndBytes() 以结构体的方式处理返回体假设 URL http://example.com/ 的返回体{&quot;hey&quot;:&quot;you&quot;}。 1234567heyYou struct &#123; Hey string `json:\"hey\"`&#125;var heyYou heyYouresp, _, errs := gorequest.New().Get(\"http://example.com/\").EndStruct(&amp;heyYou) 连续重复请求（Retry）假设你在得到 BadRequest 或服务器内部错误（InternalServerError）时进行连续三次，间隔五秒的连接尝试 1234request := gorequest.New()resp, body, errs := request.Get(\"http://example.com/\"). Retry(3, 5 * time.Second, http.StatusBadRequest, http.StatusInternalServerError). End() 重定向 Redirects can be handled with RedirectPolicy which behaves similarly to net/http Client’s CheckRedirect function. Simply specify a function which takes the Request about to be made and a slice of previous Requests in order of oldest first. When this function returns an error, the Request is not made. 12345678request := gorequest.New()resp, body, errs := request.Get(\"http://example.com/\"). RedirectPolicy(func(req Request, via []*Request) error &#123; if req.URL.Scheme != \"https\" &#123; return http.ErrUseLastResponse &#125; &#125;). End() Debug 模式 For debugging, GoRequest leverages httputil to dump details of every request/response. (Thanks to @dafang).You can just use SetDebug or environment variable GOREQUEST_DEBUG=0|1 to enable/disable debug mode and SetLogger to set your own choice of logger.Thanks to @QuentinPerez, we can see even how gorequest is compared to CURL by using SetCurlCommand. 注意gorequest.New()函数应该一次调用，对返回的实例尽可能多次使用。 Credits Renee French - the creator of Gopher mascot Wisi Mongkhonsrisawat for providing an awesome GoRequest’s Gopher image :) LicenseGoRequest is MIT License.","tags":[{"name":"go","slug":"go","permalink":"https://antarx.com/tags/go/"}]},{"title":"使用mage实现交叉编译","date":"2018-04-23T03:17:36.000Z","path":"2018/04/23/mage2/","text":"golang 为微服务的开发带来了无可比拟的便利。使用的时候也自然而言发现一些问题，因为 golang 不像 Java 有 Maven 这样的打包工具，而是直接编译成二进制可执行文件，所以在开发机（macOS）上编译出来的可执行文件是无法在服务器或者 docker 容器里运行的，如果把源代码提交上去服务器编译，又会带来重新下载依赖包的麻烦（golang 的包依赖关系管理方面的缺失是我认为 golang 为数不多的缺点之一）。最近一直在思考有没有类似 Makefile 的方式来解决这件事（如果只想交叉编译的话直接用 go build或者借助 gox 等工具也不是不可以，可还是，不够方便）。直到之前 ing 大神给我推荐了 Hugo 这个静态博客框架，虽然目前因为找不到合适的博客主题没有从 hexo 迁移过去，但看源代码的时候有了一个重要的收获，就是mage关于 mage 的基本安装和使用详见mage 使用教程(一) golang 交叉编译的基本原理交叉编译的实现主要是依靠三个参数，CGO_ENABLE,GOOS,GOARCHCGO_ENABLE在源代码中使用 C/C++时必须开启，这样就无法实现交叉编译了，这部分代码还是得具体平台生成特定的代码。因此，交叉编译是在没有混编代码的前提下的。将CGO_ENABLE设为0，表示关闭。GOOS是目标操作系统，macOS 对应的是darwin，Linux 平台对应的是linux。GOARCH是目标架构，一般设为amd64按照如上所述设定要编译参数之后再执行go build即可生成目标平台的代码。 实现123456789101112131415161718192021222324// +build mega// magefile.gofunc Linux()&#123; //设置环境变量 var e= make(map[string]string) e[\"CGO_ENABLE\"] = \"0\" e[\"GOOS\"] = \"linux\" e[\"GOARCH\"] = \"amd64\" name := fmt.Sprintf(\"%s-linux-%s\",prefix,VERSION) //创建 bin 文件夹 if err := os.Mkdir(\"bin\", 0700); err != nil &amp;&amp; !os.IsExist(err) &#123; fmt.Errorf(\"failed to create %s: %v\", \"bin\", err) os.Exit(1) &#125; path := filepath.Join(\"bin\",name) fmt.Println(\"Building app for linux...\") //运行构建命令 err := sh.RunWith(e,\"go\",\"build\",\"-o\",path,\"main.go\",\"utils.go\",\"RESTHandler.go\",\"module.go\") if err != nil&#123; fmt.Println(err) return &#125; fmt.Printf(\"Sucessfully Built.Output File: %s\\n\",path)&#125; 在magefile所在文件夹输入 mage linux 即可编译生成适用于 Linux 的运行文件。","tags":[{"name":"golang","slug":"golang","permalink":"https://antarx.com/tags/golang/"}]},{"title":"mage 使用教程(一)","date":"2018-04-23T02:24:36.000Z","path":"2018/04/23/mage1/","text":"Mage 是使用 golang 开发的类 Make的软件构建工具。借助这个工具只需要编写符合 golang 语言规范的代码就可以实现比较复杂的源代码编译。 安装安装 mage 之前首先要安装 golang1.7或以上版本。安装好之后，执行以下代码 123go get -u -d github.com/magefile/magecd $GOPATH/src/github.com/magefile/magego run bootstrap.go 编译完成之后，名为 mage 的可执行文件放在$GOPATH/bin目录下，将$GOPATH/bin加入到系统路径即可在终端中直接输入mage运行软件。 第一个 MagefileMagefile 实质是符合 golang 语法的源代码，并且加入了特定的注记，规则如下： 在包名之前\b加入一行，// +build mage 包名必须为 main 每个可导出函数\b会变成可被 mage 执行的选项（类似 Makefile 的每一个 tag） 每个可导出函数前的注释会被转换成帮助文档 文件名可以但不一定必须是 Magefile.go 在任意目录输入mage -init可以生成Magefile.go 模板代码。可以输入以下代码实验\b以上规则 1234567891011121314// +build magepackage mainimport( \"fmt\" \"log\")//Buildfunc Build()&#123; fmt.Println(\"Building...\")&#125;//Installfunc Install()&#123; log.Println(\"Installing...\")&#125; 预备，构建构建只需要一行代码mage build，程序就会自动执行 Build 函数，完成整个构建过程。","tags":[{"name":"golang","slug":"golang","permalink":"https://antarx.com/tags/golang/"}]},{"title":"golang 处理 yaml 格式数据","date":"2018-04-11T09:18:58.000Z","path":"2018/04/11/goyaml/","text":"YAML 格式的数据常用来作为配置文件使用, 因此相对来说字段比较固定, 在 golang 中进行解析时跟上一篇提到的解析 json 数据有所区别 ##","tags":[{"name":"golang","slug":"golang","permalink":"https://antarx.com/tags/golang/"}]},{"title":"go 语言中 JSON 数据的处理","date":"2018-03-30T07:20:31.000Z","path":"2018/03/30/gojson/","text":"Golang 中处理 JSON 格式数据主要依赖encoding/json这个库，很多教程（包括 Go 语言圣经）讲 JSON 数据处理时都会定义一个结构体对应于 JSON 数据的各个字段，这种处理方法在 JSON 中字段相对固定时非常实用。但对于字段可能不断变化或者只有一两个字段是固定的时候，如何处理这个问题往往令很多人感到困惑。最近研究 gin 这个库的时候发现一个思路非常值得学习借鉴。 What说了这么多，其实并不神秘，就是来自 gin 框架源码中的一句关键定义 12// H is a shortcup for map[string]interface&#123;&#125;type H map[string]interface&#123;&#125; 定义了这个数据结构之后，gin 框架就可以处理几乎所有的 JSON 数据。 同理，我们在自己的代码中想不受结构体限制灵活处理 JSON 数据时，也可以在程序代码中添加类似的定义 1type message map[string]interface&#123;&#125; 从字符串解析 JSON 数据时，只需要 123//body is string messagevar result mssjson.Unmarshal([]byte(body),&amp;result) 包装 JSON 也类似 12//mes is message typebty,err := json.Marshal(mes) 值得一说的是平时处理 JSON 数据经常出现的反斜杠双引号问题，用这种方法处理时并没有出现。 Why背后原理分析。 这一行代码之所以这么实用是因为interface{}这个 golang 中的“万金油”。Golang 中不存在类和对象的概念，因此空接口就成了所有变量的“超类”一样的存在，可以承载一切的变量。 潜在问题 and Further More处理 JSON Array 时会出现问题，就是明知它是数组却不能直接用下标进行操作（会提示{}interface 不支持下标，导致编译失败），实际运行时用反射包的reflect.TypeOf查看JSON 数组解析出来的类型明明是[]interface{}，是接口slice，是支持下标操作的。 原因是 Golang 是静态语言，代码中所有变量的类型都是在编译期确定的，我们所定义的类型中 map 的 value 部分是{}interface，在 运行时接收到需要解析的 JSON 数据之前编译器和我们都不知道它“事实上”是一个 slice。 这个在项目应用中实际存在的矛盾也解决我学 OOP 语言一直以来的困惑，就是反射是什么？为什么现代编程语言都选择加入反射作为基本特性（Java，C#，还有本文中的 Golang），就是因为我们有在运行时获取某个对象/变量的实际类型的需要。 由于目前学习还不够深入，不能对反射机制展开深入的探讨，在这里讲一下如何利用类型断言机制解决上面说到的问题。 123456cs,ok := result[\"containers\"].([]interface&#123;&#125;) if ok&#123; for i,item := range cs&#123; //do something &#125; &#125; cs,ok := result[&quot;containers&quot;].([]interface{})这一句就是解决问题的关键所在，也就是称为运行时类型断言的机制。a.(Type)是尝试对a进行类型转换的操作，如果转换成功则返回一个转换成 Type 类型的变量和true指示转换成功，失败则返回false。 值得一提的是，断言失败不会导致编译失败（要是会导致编译失败也就不能解决上面这个问题了），所以为了代码健壮性需要对转换结果进行判断比较好。","tags":[{"name":"go","slug":"go","permalink":"https://antarx.com/tags/go/"}]},{"title":"redis的杂七杂八","date":"2018-02-25T15:09:10.000Z","path":"2018/02/25/redis/","text":"Redis 是目前应用比较广泛的数据库。最近的实验室项目中用到它作为实时数据库。把这个过程中学到的一些东西记录下来，权且作为小白的入门参考吧 基本概念Redis 是一种基于内存的数据库，这意味着在使用过程中的所有数据都是存放在内存当中的，省去硬盘读写的过程使得对数据库的操作会非常的快，很适合并发。 Redis 的基本储存单位是key-value，比 mongodb 中的“文档”的概念有着更细的粒度。key部分一般是字符串类型，value部分可以有以下五种类型： string。字符串类型 hash。一系列k-v的集合，适合用来储存对象实例或者 JSON list。简单的字符串列表，也就是说可以通过 list 数据结构在一个key对应的value字段储存多个字符串。这多个字符串是有序排列的。“序”指的是插入的顺序（可以选从头部或者尾部插入） set。String 类型的无序集合。满足唯一性。 有序集合。set 的有序版本 命令行操作服务器（server 端）安装 Redis 之后，在命令行窗口输入redis-server即可在本机运行一个radis 的 server 端，默认的端口是6379. DockerRedis 服务器端和其他主流数据库一样可以很方便的放到 Docker 容器里运行。 下载 Redis 镜像 1sudo docker pull redis 基于 redis 镜像运行容器 1sudo docker run --name redis-server -p 6379:6379 -d redis 镜像内部已经设置了运行redis-server和监听6379端口，所以不需要额外的设置项，只需要在运行容器时将端口暴露出来（与宿主机的6379端口或者自己指定的端口绑定）就可以了 client 端shell 界面下输入redis-cli -h 127.0.0.1 -p 6379启动 redis-client。其中，-h指定服务器的地址，-p指定服务器的端口。 基本操作命令注意到，命令的操作字段是不区分大小写的。 value 为 String 类型时。set key value用于为 key 设置值为 value。 get key用于获取键为 key 的值。 value 为 list类型时。lpush key value1 [value2]…用于将一个或者多个值。 LPOP key可以移出并获取列表的第一个元素。这两个操作换成rpush和rpop可以向列表尾部插入元素。LLEN key可以获取 key 对应的列表的长度。LRANGE key start stop用于获取特定key 的指定范围的元素，特别地，LRANGE key 0 -1可以用来遍历列表。 更加详细的命令教程可以参考Redis教程-菜鸟教程 编程语言支持Java在 Java 中主要通过 jedis 数据库驱动实现对 Redis 数据库的操作。 安装依赖 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; JedisPool和 JedisClientjedis 使用 JedisPool 作为一个Redis连接池，用于解决对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题。 连接池初始化代码如下 1234567891011121314151617public static JedisPool getPool(String host, int port)&#123; if(pool == null)&#123; JedisPoolConfig config = new JedisPoolConfig(); //设置最大连接数 config.setMaxTotal(100); config.setMaxIdle(5); if(host == null)&#123; pool = new JedisPool(config, \"127.0.0.1\", port); &#125;else&#123; pool = new JedisPool(config, host, port); &#125; &#125; return pool; &#125; 要使用Client 时，使用pool.getResource()方法获取单个JedisClient实例，在此基础上对 Redis 数据库进行操作。 GolangGo 语言中用来连接 Redis 数据库的库五花八门，主要分两个派系，将对 Redis 的操作封装成方法的，开发者通过调用库的方法实现对 Redis 数据库的操作；另一派是直接将 Redis 命令作为字符串提供给库来实现各种操作的。 这里以&quot;github.com/garyburd/redigo/redis&quot;为例。 安装依赖 1go get github.com/garyburd/redigo/redis 获取 redis pool实例 123456789101112redis.Pool&#123; MaxIdle:10, MaxActive:15, IdleTimeout:240*time.Second, Dial: func() (redis.Conn, error) &#123; c, err := redis.Dial(\"tcp\", redisURL) if err != nil&#123; return nil, err &#125; return c, err &#125;, &#125; 从 pool 中获取 Client 实例 1rClient := redisPool.Get() 执行操作 1rClient.Do(\"LPUSH\",\"key\", \"value\") Do 方法用于执行对 Redis 数据库的操作命令。方法的第一个参数字符串命令（就是在 shell 交互时的各种命令。","tags":[{"name":"golang","slug":"golang","permalink":"https://antarx.com/tags/golang/"},{"name":"Java","slug":"Java","permalink":"https://antarx.com/tags/Java/"},{"name":"Redis","slug":"Redis","permalink":"https://antarx.com/tags/Redis/"}]},{"title":"Keras 手写数字识别","date":"2018-01-23T10:42:42.000Z","path":"2018/01/23/aml/","text":"之前机器学习课程布置的大作业是用尽可能多的模型来探索经典的手写数字识别问题。这里分享一下Keras的基本使用 Keras简介Keras 是由纯 Python 写成的，调用 TensorFlow 或者 Theano（最新版本还支持 CNTK）进行运算的类库。相比于 TensorFlow，Keras 使用起来更加简洁方便，便于调参，非常适合初学者进行机器学习探索。 安装在安装好 anaconda 的前提下，输入conda install keras即可进行安装。 注意到，安装过程会自动判断机器是否已经安装好了TensorFlow，如果没有的话会自动进行安装。所以，如果想安装 TensorFlow GPU 版本加速计算过程的话，要先手动安装好 TensorFlow 的 GPU 版本，然后再安装 Keras。 实现单层感知机核心代码如下 12345678910111213141516171819202122232425batch_size = 128classes = 10epoch = 10img_size = 28 * 28print('Loading Data...')(X_train, y_train),(X_test,y_test) = mnist.load_data()X_train = X_train.reshape(y_train.shape[0], img_size).astype('float32') / 255X_test = X_test.reshape(y_test.shape[0], img_size).astype('float32') / 255#encode labelsY_train = np_utils.to_categorical(y_train,classes)Y_test = np_utils.to_categorical(y_test,classes)model = Sequential([Dense(10, input_shape=(img_size,), activation='softmax'),])model.compile(optimizer='rmsprop', loss='mean_absolute_error', metrics=['accuracy'])print(\"Training...\")model.fit(X_train, Y_train,batch_size=batch_size, epochs=epoch, verbose=1, validation_data=(X_test,Y_test))score = model.evaluate(X_test,Y_test,verbose=0)print('accuracy: &#123;&#125;'.format(score[1])) 前面很大一部分都是进行数据加载和处理，与模型有关的代码只有三行 model = Sequential([Dense(10, input_shape=(img_size,), activation=&#39;softmax&#39;),])这一行是模型基本形态的定义，以图像的 size 作为输入，激活函数采用 softmax。 model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;mean_absolute_error&#39;, metrics=[&#39;accuracy&#39;])这一行则是对模型的微观参数进行客制化。optimizer指定的是优化策略，rmsprop是一种改进的随机梯度下降策略。loss指的是损失函数。metrics是评估方法，这里用准确率进行评估。 model.fit(X_train, Y_train,batch_size=batch_size, epochs=epoch, verbose=1, validation_data=(X_test,Y_test))这一句是训练过程，指定训练数据，训练轮次（迭代次数），是否输出训练过程，验证数据。 多层全连接网络核心代码部分 12345678model = Sequential([Dense(512,input_shape=(img_size,)), Activation('relu'), Dropout(0.2), Dense(512, input_shape=(512,)), Activation('relu'), Dropout(0.2), Dense(10,input_shape=(512,),activation='softmax') ]) 每一个 Dense 都是一个神经元训练层。训练层输出接 ReLU 激活函数层。如此类推。最后一层接单层感知机获取结果。值得注意的是两个 Dropout 层，用于应付过拟合问题，经过 Dropout 层会随机丢弃数据集中一定比率的激活值，同时将剩余的神经元的输出进行放大。 卷积神经网络1234567891011model = Sequential()model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))model.add(Conv2D(64, (3, 3), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Dropout(0.25))model.add(Flatten())model.add(Dense(128, activation='relu'))model.add(Dropout(0.5))model.add(Dense(num_classes, activation='softmax')) 卷积神经网络中主角变成了 Conv2D （卷积层）和 Pooling 层（池化）。","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://antarx.com/tags/机器学习/"}]},{"title":"网研机试101","date":"2018-01-08T10:13:08.000Z","path":"2018/01/08/buptoj/","text":"2018考研的初试已经结束了，平时看考研群里已经有很多人在讨论在焦虑机试应该怎么复习，作为过来人在这里就随便说说自己的一些经验吧。 实现说明一下，这篇文章基本就是个扫盲，不能保证你看完文章就能从 A0变 AK，但帮助你脱离新手区，扫除对机试的恐惧，保个底让机试不会成为复试阶段的软肋还是可以的。 简单介绍首先得先了解机试的基本情况。按照去年的考试风格，是两个小时四道题的 OJ（Online Judge）形式，也就是在线提交，在线判题返回程序在测试结果集的运行结果。AC（accept）代表正确解题，WA（Wrong Answer）表示错误答案，另外还有超时、超出内存空间等等结果。所有考试前准备的目的，就是为了更多的 AC，或者保底情况，避免 A0。 编程语言该用什么语言北邮 OJ 平台可以用的编程语言有三种，C（gcc4.8），C++（g++ 4.8）和 Java（注意：没有 Python，没有 JavaScript）。另外，C++是不支持 c++11的，Java 只支持到 Java6。 在这个天煞的背景下，考虑到程序时间限制（1ms）和开发速度（避免无谓的造轮子），用 C + STL 是最理想的选择。 展开来说，就是用 C 的那一套输入输出（scanf 和 printf），C 与 C++通用的循环控制、选择结构、数组等，在加上 C++独特的“宝具”——STL 标准库，来进行解题。提交的时候编译器选 g++即可。 STL 标准库内容非常多，只需要了解 Map，stack，list，queue就够了。 IDE？不存在的两个小时做四道题对大脑转数的要求还是挺高的，更何况在那种紧张的气氛和不熟悉的开发环境之下。要保证解题能够快狠准，就需要从现在开始培养一定的针对考试的编程习惯，包括 编辑器和编译器、调试器的使用等等。 首先，抛弃手上所有的 IDE，包括但不限于 Visual Studio和 Clion，DevC++，或者只在疑难杂症的时候拿它们当单步调试的工具（但也不能依赖）。考试环境只提供了（没有智能提示的）devcpp，（长得贼丑的）CFree两种最“原始”的开发工具，也就拿来当代码高亮，保证括号补全没有基本的语法问题差不多了，很多现代 IDE、开发工具可以做的事它们一概做不了。 要适应这种艰苦恶劣的考试环境，就得从准备机试的时候开始，把开发工具换成 VScode and g++。VScode 是微软提供的跨平台编辑器，有着漂亮的界面和基本的语法高亮功能，在配置各种插件之前基本可以拿来模拟考场的开发环境，用来编辑代码，而且还能保证练习的时候是比较舒服的。 编译过程全部转到命令行用 g++完成。 调试两个最基本额调试手段：打印大法和单步调试大法。个人推荐第一种。单步调试大法需要掌握 gdb这个 g++配套的调试工具，相对来说比较费时间（无论上手还是在考场上使用），而且比较容易出一些奇奇怪怪的问题。想成为 AK 达人的话，倒是必须掌握的。 打印大法就是在关键步骤将关键变量输出的方法，简单易行，只要注意提交之前注释掉代码就OK。 参考教材注意到，机试是可以带任何纸质打印资料的，一本简介明了的语言参考指南显得非常重要。 抛弃所有国内教科书，包括但不限于谭浩强，除非你想拿成绩开玩笑在考试的时候验证一下int a++++会不会报错。 在这里，只推荐K&amp;R The C Programming Language小薄本。将 ANSI C 的所有内容都讲得很透彻而简洁，里面的习题也可以作为入门练手。 能力层级这一部分提供平时训练刷题的参考方向。列举我在去年准备的时候看过的一些题型，具体知识和代码在王道机试指南和算法竞赛入门经典介绍的比较详尽。 基本输入输出OJ 的输入输出风格可是能玩死不少人的，怎么保证循环接收输入，接收特定符号能退出，每一轮输入怎么界定，怎么输出小数点后三位浮点数，输出的时候删掉无谓信息（比如句子最后的致命空格），等等等等，都是值得关注的内容，也是首先要练习的。所幸 scanf 和 printf 函数在 KR 里面已经介绍得非常详尽，对照着看和练习就行。 数字和数组处理数字部分有点像小学数学的找规律填数，也会夹带私货弄些奇形怪状的浮点数处理，数组处理方面典型例子就是找最大最小数，找次小数，奇偶数分离这些。一般都在签到题出现。 日期问题闰年问题，星期几问题等等。 字符串处理翻转字符串，回文字符串判断，甚至字符串匹配、简易正则表达式识别、字符串搜索都是有可能出现的，活用 std::string 和 char 数组的下标嗯。 模板题图论的 D 算法 F 算法，深度优先搜索，矩阵乘法等等。这种基本都是最终 boss 级别，因为很多 ACM 资料都会有典型的算法题目，代码可以直接套用，改改关键变量就可以，所以称为模板题。 特别提名：模拟题模拟题，可不是模拟卷子，而是一类型模拟计算机内部操作比如进程调度，死锁识别等的题目，印象最深刻就是去年最后一题算进程完成时间的。 思维方法这里介绍一些玄学的东西，也是机试对以后的开发生涯最有帮助的东西 边界值控制和处理刚开始接触 OJ 的时候很容易会遇到本地编译没问题，提供的测试数据也能获得预期结果可是提交之后就是 WA 这种百思不得其解的问题，根源便在于边界值考虑不周全，比如整数0，范围的边界，字符串中的空串等等，解决之道便是通过大量的练习，对每个算法题首先花上几秒考虑可能的边界情况和特殊情况，久而久之形成严密的思维。 时间性能1ms 的时间限制，看起来非常的充分，那只是还没遇到大规模输入。在那种几万甚至十万级别的数据（OJ 上真的会有），就算是$O(n^3)$的算法，翻车也是随时随地的。 应对这个问题，得对计算机内部执行过程有最基本的认识，更好一点的得对算法的时间复杂度有认识，优化起来才不会像无头苍蝇一样。 还是祭出CSAPP，里面对程序优化的介绍比较详细，充分利用 Cache 可以编写更高效程序。 奇技淫巧这里特别提名位运算，关键时刻可以省下大量的时间。 安利Hackers’ Delight 基本的算法设计思想递归，动态规划，不一而足，还是那句话，需要不断的刷题积累经验。","tags":[{"name":"BOJ","slug":"BOJ","permalink":"https://antarx.com/tags/BOJ/"}]},{"title":"linuxnv","date":"2017-12-06T13:30:36.000Z","path":"2017/12/06/linuxnv/","text":"","tags":[]},{"title":"TensorFlow For Docker 初体验","date":"2017-12-06T13:30:22.000Z","path":"2017/12/06/dockertf/","text":"TensorFlow 是一套开源的机器学习工具。一般来说只用 TensorFlow 的话配置运行环境什么的并没有特别坑的地方，但如果想用到 GPU 加速计算的话配置起来就要费好大一番力气了，还经常遇到各种版本不兼容、找不到依赖关系等问题，让人头疼。而 Docker 刚好是解决开源软件各种依赖关系的神物，NVIDIA 刚好又有工具能让容器用上 GPU 进行计算。 下面分享配置过程。 测试环境是 GTX850M+Ubuntu16.04.3+CUDA9.0+GeForce 384.00 驱动及 CUDA 安装过程参考即将到来的另一篇文章。 安装 Docker可以用curl -sSL https://get.daocloud.io/docker | sh这条命令快速安装 Docker，不过，这个安装脚本默认会安装最新版本的 Docker（当前是17.11.0 docker-ce），而 NVIDIA Docker 并不支持这个新版本（跪 所以要进行一下卸载再降级操作… 123456# uninstall dockersudo apt-get purge docker-ce# 查看软件库中可用的历史版本sudo apt-cache policy docker-ce# install docker-ce 17.09sudo apt-get install -y docker-ce=17.09.0~ce-0~ubuntu 值得一提的是17年的某个版本开始，docker 的软件包统一到 docker-ce（社区）和 docker-ee（付费企业版）上面来了，开发使用的主要以 docker-ce 为主，网上很多教程（尤其是2016年、2016年的）说到安装 docker 的软件包名叫例如 lxc-docker docker.io 等的都是老旧版本的。 安装 NVIDIA-dockerNvidia-Docker是老黄提供的一套在 Docker 上制造跑核弹的工具（。 简单来说，这套工具提供了一个运行时，用来连接 Docker 容器和物理设备的 GPU 资源，使得 Docker 容器可以直接访问、调用物理机的 GPU 资源进行密集型计算操作。 安装步骤如下： 12345678910111213# Add the package repositories 添加软件仓库curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | \\ sudo apt-key add -curl -s -L https://nvidia.github.io/nvidia-docker/ubuntu16.04/amd64/nvidia-docker.list | \\ sudo tee /etc/apt/sources.list.d/nvidia-docker.listsudo apt-get update# Install nvidia-docker2 and reload the Docker daemon configurationsudo apt-get install -y nvidia-docker2sudo pkill -SIGHUP dockerd# Test nvidia-smi with the latest official CUDA imagedocker run --runtime=nvidia --rm nvidia/cuda nvidia-smi 在 Ubuntu16.04测试通过。 安装 TensorFlow 的 Docker 镜像TensorFlow 官方提供了 for Docker 的镜像，里面集成了完整的依赖关系，免去了用pip安装各种包的烦恼。 镜像包含很多 tag，常用的有下面几个： tensorflow/tensorflow:latest，运行环境是 python2.7，仅支持 CPU tensorflow/tensorflow:latest-gpu，运行环境是 python2.7，支持 GPU 计算 tensorflow/tensorflow:latest-py3，运行环境是 python3.5，仅支持 CPU tensorflow/tensorflow:latest-gpu-py3，运行环境是 python2.7，支持 调用GPU 我自己用的是最后一个。 首先下载镜像下来。 1docker pull tensorflow/tensorflow:latest-gpu-py3 然后跑个 python3交互环境试试水 1docker run --runtime=nvidia --rm -it tensorflow/tensorflow:latest-gpu-py3 python3 在交互环境下输入import tensorflow as tf，如果没提示依赖库错误则说明安装成功。 上面的—runtime=nvidia为调用 nvidia-docker 工具包（运行时）而不是标准运行时来运行镜像，只有加了这个选项才能调用 GPU。 最后跑一下多重感知机训练手写数字识别，效果图 多重感知机训练手写数字识别模型 输出显示调用 GPU:0进行计算，说明配置一路顺风了。","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://antarx.com/tags/TensorFlow/"},{"name":"Docker","slug":"Docker","permalink":"https://antarx.com/tags/Docker/"},{"name":"ML","slug":"ML","permalink":"https://antarx.com/tags/ML/"}]},{"title":"最大概率汉语切分算法研究-(0)-概览","date":"2017-11-27T13:48:13.000Z","path":"2017/11/27/mpseg0/","text":"最近忙活了将近一个多月总算把计算语言学布置的最大概率汉语切分作业写完了，虽然中途一波三折，还发生了很多五光十色奇形怪状让人难忘的事情，所幸最后还是比较完整的写了出来，也学到了不少的知识。因此便有了这个系列的文章。 在这篇给出这系列文章的导航帖汇总。 至于代码嘛，等交完实验报告再说嗯。。 最大概率汉语切分算法研究（一）词典构建 最大概率汉语切分算法研究（二）BiGram语言模型 最大概率汉语切分算法研究（三）有向无环图（DAG）与最优左近邻词 最大概率汉语切分算法研究(四）FMM 与 BMM 在分词中的应用","tags":[{"name":"NLP","slug":"NLP","permalink":"https://antarx.com/tags/NLP/"}]},{"title":"最大概率汉语切分算法研究(四）FMM 与 BMM 在分词中的应用","date":"2017-11-25T10:04:43.000Z","path":"2017/11/25/mpseg4/","text":"本篇继续讨论对输入句子的处理问题。FMM 和 BMM 是指对输入句子分别找前向最长词和后向最长词，某种程度上来说属于贪心算法的一种，比较惊喜的地方是两者结合常常能获得比较不错的分词效果。 FMMFMM，可以理解成前向（Forward）最长词，就是对一个句子，每次切分找词的时候，都是从前往后“切出”最长的词和剩下的子句，例如： “有意见分歧”这句话，用 FMM 进行切分找第一个词的时候就会切分成： 有意/见分歧 只利用 FMM 进行分词时，对每次切分后的子句都反复寻找最长前缀词，直到子句为空。注意到，FMM 得到的切分序列是唯一的。 BMMBMM，可以理解成后向（Backward）最长词，就是对一个句子进行切分的时候，都是从后往前“切出”最长词和剩下的子句，例如 “有意见分歧”这句话，用 BMM 切分的时候会分成： 有意见/分歧 其中，“分歧”是寻找到的“第一个词”，“有意见”是待切分的子句。 用 BMM 分词的时候，对每次切分后的子句都反复寻找最长后缀词，直到句子为空。 FMM 与 BMM 组合分词只用 FMM 或 BMM 进行分词的话，由于算法本身“贪心”的属性，往往得不到最理想的切分结果。所以在进行汉语切分的时候，可以将两个算法结合使用，用于发现歧义（因为对于没有歧义的句子，FMM 和 BMM 得到的切分结果一定是一致的），也可以将两个算法得到的序列计算整句话的概率（利用 BiGram 模型），选取概率较大者作为最终的切分结果。","tags":[{"name":"NLP","slug":"NLP","permalink":"https://antarx.com/tags/NLP/"}]},{"title":"最大概率汉语切分算法研究（三）有向无环图（DAG）与最优左近邻词","date":"2017-11-25T08:51:09.000Z","path":"2017/11/25/mpseg3/","text":"本篇讨论的是对特定输入句子进行的处理过程。基本思想是对特定输入句子从前往后遍历找出所有词构成有向无环图，然后从最后一个词开始往前找每个词的“最优左近邻词”构成一个完整的词语序列。 DAGDAG，也就是有向无环图，可以用来记录一个句子的不同的切分状态集合，所谓的“向”就是句子从开始到结束的方向。假定句子的开始符为S，以“他们有意见分歧”这个句子为例，可以得到如下的有向无环图： 有向无环图例子 在生成一个句子的有向无环图的过程中，利用 BiGram 模型计算所有的转移概率并进行储存。 之后，从后往前回溯，寻找每个词的最优左近邻词，直到‘S’字符。结束。 从句子生成 DAG假设开始标识符为‘S’。 对于特定的一条输入句子sentence，原始问题可以理解成：由sentence和其前一个词‘S’构建有向无环图。 对 sentence进行分词操作，假设找到的第一个词为firstWord，输入句子 sentence便可切分为 firstWord + subsentence两部分，其中firstWord作为 subsentence的“前一个词”。原始问题便可归约为由firstWord 和 subsentence构建有向无环图（构建结果作为最终 DAG 的子图）。 根据上面的分析，构建完整DAG 的过程是一个递归求解的过程，完整的算法步骤描述如下（简记为 Alg-1)： 输入句子 sentence 以开始标记符“S”和 sentence 开始构建 DAG。（“S”作为整个图的开始结点，“源”点） 对 sentence从前往后找“第一个词”（firstWord），找到第一个词后，将 sentence划分为 firstWord 和 subsentence两部分。firstWord即可作为最终 DAG 的一个结点。 对 subsentence重复第三步的切分操作（寻找第一个词和子句），找到的“第一个词”作为最终 DAG 的结点，对子句继续切分（递归）。 递归结束条件：子句为空。 结束时，将所有最后一个词放入 endSet（结束词集合）里。 在 Alg-1的步骤3中要寻找“第一个词”，要注意的是，这个寻找过程不是一次性的，因为“第一个词”可能有多种情况，譬如，“有意见分歧”这句话中，对于第一个词，存在着 有/意见分歧 和 有意/见分歧 这两种潜在可能的划分，需要一并进行考虑。因此，寻找词的过程是一个循环的过程，设定上限值为15（汉语中基本不存在长度超过15的词），从第一个字开始向前寻找（切片）： 12for i in range(1,15): word = sentence[:k] 如果“切”出来的 word在词典中，则作为一个子问题，这样才能保证最后生成的 DAG 是考虑了所有可能情况的（考虑了所有的歧义）。 不过，这个“粗暴”的切分方式也存在着可见的缺陷。它会大幅度增大了有向无环图的规模（最坏情况下，所有的单字都作为图的一个结点）。对于长句子来说会极大的增大了生成时间，而且，这里用递归来生成子图，因此甚至存在递归过深导致堆栈溢出等问题，即使不是这样，也会显著的增加了程序运行时间。 减少无用递归经过多次痛苦的测试过程，摸索出减少无用递归的方法可以短暂缓解上面提到的缺陷。 考虑如下句子： 因为他们有意见分歧，会议的时间未能确定下来。 虽然在中文语义上，可以以逗号为分隔直接划分成两个子问题再进行切分生成 DAG，但在计算机中还是视为一个句子进行处理。 在“有意见分歧，”这里，存在至少两种切分： 有/意见分歧 和 有意/见分歧 无论这个子句如何切分，切分之后的两个子句 意见分歧，··· 见分歧，··· 除了第一个词之外都是重叠的，生成的子图也是一样的，无需重复的递归进行处理。 基于这种分析，在考虑生成 DAG 函数的关键参数：firstWord和 subsentence，将这两个参数构成一个元组（tuple），用一个集合记录下已经进行了“子图生成”的元组，每次要执行递归前，首先判断关键参数组合是否在集合中，如果在集合中则直接跳过，否则再执行递归过程，执行完毕后将关键参数组合添加到集合中。 最优左近邻词（bLAW）考虑词序列 $$w_1,w_2,w_3,…,w_{i-1},w_i,…,w_n$$ $w_{i-1}$即为$w_i$的左近邻词。 用输入句子生成 DAG 之后，对结束词集合中的每一个词，从后往前回溯，寻找每一个词的最优左近邻词，直到“S”结束，得到潜在的切分序列。如果切分序列不止一个的时候，则计算每个切分句子的概率，取概率较大者作为切分结果序列。 如何寻找最优左近邻词？考虑累计概率计算公式： $$P_a(w_i)=P_a (w_{i-1})*P(w_i/w_{i-1})$$ 对每一个左近邻词（在 DAG 中表示为一个结点的所有前向相邻结点），计算累积概率，取概率较大者作为最优左近邻词。 潜在问题以下潜在问题的讨论仅限于本文讨论的 DAG 和寻找左近邻词的算法，并不一定 LAW 这个概念本身可能存在的问题。 “最优”只考虑了局部的情况，在语料库生成的搭配词典规模受到限制的场合，基于语料库训练出来的 BiGram 模型计算出来的累积概率与实际应用场景中“本该有”的概率存在较大差异，这种差异将直接反映在切分结果上。 生成 DAG 的过程以词本身而不是词在句子中的下标序号作为图的结点，对于一个存在重复词的句子，从后往前找左近邻词时可能进入死循环中。解决办法是每次寻找词的时候将这个词与它“本该”出现在句子中的位置进行比较再决定是不是 LAW 参考资料 jieba中文分词源码分析（三） 王小捷老师计算语言学课程相关课件资料","tags":[{"name":"算法","slug":"算法","permalink":"https://antarx.com/tags/算法/"},{"name":"NLP","slug":"NLP","permalink":"https://antarx.com/tags/NLP/"}]},{"title":"最大概率汉语切分算法研究（二）BiGram语言模型","date":"2017-11-25T08:51:06.000Z","path":"2017/11/25/mpseg2/","text":"BiGram 语言模型，也就是二元语法模型，起源于 NGram，属于 N = 2的情况。基本思想是当前词依赖于仅前一个词的出现概率。 模型简介N 元语法模型属于概率模型的一种。在 Ngram 语言模型的概念里，我们假设当前词出现的概率依赖于前面N-1个单词。 概率推导假设有单词序列$w_1,w_2,…,w_n$,将每个单词在它本身位置的出现看成一个独立事件，则这个单词串出现的概率可以表示为$P(w_1,w_2,…,w_n)$ 一般情况下将这个单词序列简记为$w_1^n$，由概率的链式分解规则，有 $P(w_1^n) = P(w_1)P(w_2|w_1)P(w_3|w_1^2)···P(w_n|w_1^{n-1})$ 在概率推导公式中，令$n=2$，式子可以简化为$P(w_1^n)=P(w_n|w_{n-1})$ 说人话？？？上面的概率推导很容易让人一头雾水，以“我喜欢你”这个句子为例，“我喜欢你”这个句子出现的概率，可以转化成“我喜欢”这个子句后面出现“你”这个词的概率，在二元语法模型中，就可以进一步等价成“喜欢”这个词后面出现“你”的概率。 也就是说，二元语法模型，将一句话出现的可能性，转化成一系列词语搭配出现的可能性。 模型训练由频率估计概率的方法，对于给定的语料库，不难得出如下公式： $P(w_n|w_{n-1})=\\frac{C(w_{n-1}w_n)}{C(w_n)}$ 还是以“喜欢你”这个句子为例，可以得到： $P(你|喜欢)=\\frac{“喜欢你”这个搭配在语料库中的出现次数}{所有以“喜欢”开头的双词搭配总数}$ 因此，训练的目标就是对于给定的语料库和词典，统计整个语料库中的所有双词搭配和对于具体的每一个词，统计以该词开头的所有双词搭配数目。也就是一个数数的过程。 平滑技术上面提及的 N 元语法的问题在于“数数”这个过程对语料库是强依赖的，而每个特定的语料库都是有限的，肯定无法覆盖汉语中出现的所有双词搭配。所以便有了平滑技术，为“零概率的二元语法”指派非零概率，也就是在计数后进行概率转换之前为计数为0的指派一个非零的计数值。 在这里使用了最简单的加一平滑，在二元计数矩阵中，归一化计算概率之前为所有的计数加一。 计算机编程实现模型表示在开发分词工具中，采用了 pandas 库提供的 DataFrame 这个二维的数据接口来表示整个模型，index部分是词典中的每一个词，col部分包含了两列，第一列是每个词出现的总数，第二列以字典类型来表示每个词所有可能的“下一个词”和对应出现次数。 平滑技术的处理假设词典里面有 $m$个词，按照上面的描述，需要一个$m \\times m$的矩阵来作为二元语法矩阵，加一平滑的时候遍历整个矩阵为每个元素加一。然而，从199801这个语料库中统计出来的词个数已经高达50000+，加载这么高维度的矩阵对于普通计算机来说显然是一笔很大的消耗。 而在这个模型表示中，只储存了所有出现过的“双词”搭配，将对未出现的搭配“赋值为1”的过程放在了概率计算部分，加快了模型的加载速度。 参考资料JMBook-自然语言处理综论","tags":[{"name":"NLP","slug":"NLP","permalink":"https://antarx.com/tags/NLP/"}]},{"title":"最大概率汉语切分算法研究（一）词典构建","date":"2017-11-25T08:51:02.000Z","path":"2017/11/25/mpseg1/","text":"最近忙活了将近一个多月总算把计算语言学布置的最大概率汉语切分作业写完了，虽然中途一波三折，还发生了很多让人难忘的事情，所幸最后还是比较完整的写了出来，也学到了不少的知识。因此便有了这个系列的文章。 问题基于最大概率的汉语切分工具的开发，是要利用计算语言学课上学到的知识，选用合适的模型开发一个汉语分词的工具并且进行代码测试与评估。 阶段划分一个完整的分词工具的开发包括以下几个步骤： 选择合适的语料库 根据语料库构建词典 选择合适的分词模型和平滑技术 语料库切分：训练集和测试集 模型训练 模型测试，包括分词技术调整等，增强代码健壮性 在本项目中选用的语料库是人民日报199801的语料库，分词模型选择2-gram 模型，平滑技术选用了最简单易行的加一平滑，分词技术包括了左近邻词，FMM 和 BMM 等，具体在接下来涉及到了再具体谈。 本文主要讨论的是从语料库构建词典的问题。 TrieTree与词典TrieTree，又名前缀词典树，是一个专门用于构建词典的数据结构，在这个数据结构上实现词语的添加和查找都可以获得非常高的效率。 TrieTree 的 python 实现在知乎的一个回答有非常简短的代码可以实现 TrieTree 的添加和查找功能，不过在这里要用 Trie 树构建词典的话还需要小小的修改，将该回答中叶子节点的’Exist’字段替换成’count’，用于统计每个词在语料库中出现的次数，每次添加一个词的时候，为后面的概率计算作铺垫。 语料库分析人民日报199801的语料库中，对于每一个词都是像泽民/nr这种形式，以/分割，前半部分为词，后半部分为该词的词性，词之间用两个空格进行分割。构建词典的时候，便可以读取语料库文件的每一行，用split()方法分割得到词列表，在每个词中再次执行分割获取每个词，添加到 Trie 树中，每次添加的时候首先进行判断，如果该词已经在树上，那么将该词的’ count’字段计数加一，否则，将词加入到词典树中，并将计数字段设为1。 词典写入到文件将词典写入到文件，其实就是遍历 Trie 树，每个包含‘count’键的节点对应于一个词，将这些词写入到文件中的过程。具体代码参考如下 123456789101112131415def foreachTree(TTree,string,file): if 'freq' in TTree : if len(TTree) == 1: print(string+' '+str(TTree['freq']),file=file) return else: print(string+' '+str(TTree['freq']),file=file) for kk in TTree: if kk == 'freq': pass else: foreachTree(TTree[kk],string+kk,file) else: for kk in TTree: foreachTree(TTree[kk],string+kk,file) 对于树这种递归定义的数据结构，解决问题的最方便的方法自然也是递归，由于汉语词汇挂在“树”上的时候，每个节点都是单个“字”，因此需要一个 String 变量作为函数参数，记录前面的遍历状态。 要注意的地方是判断是否是完整词语的条件是‘count’或者‘freq’是否在该节点对应的字典中，而不是是否为‘叶子节点’。","tags":[{"name":"Python","slug":"Python","permalink":"https://antarx.com/tags/Python/"},{"name":"NLP","slug":"NLP","permalink":"https://antarx.com/tags/NLP/"}]},{"title":"macOS 配置 libsvm for Python","date":"2017-11-22T07:18:29.000Z","path":"2017/11/22/macsvm/","text":"libsvm是一个高性能的 svm（支持向量机）实现，与 TensorFlow 这些非常热门的机器学习框架不同的地方在于它提供的是可执行文件、类库和针对不同编程语言的接口， 在 macOS 上配置这套接口的时候经常会出现一些奇奇怪怪的问题。","tags":[{"name":"ML","slug":"ML","permalink":"https://antarx.com/tags/ML/"},{"name":"macOS","slug":"macOS","permalink":"https://antarx.com/tags/macOS/"},{"name":"libsvm","slug":"libsvm","permalink":"https://antarx.com/tags/libsvm/"}]},{"title":"Javalin框架使用指南(2)","date":"2017-10-28T12:15:17.000Z","path":"2017/10/28/javalin2/","text":"前言 WebSocket协议是基于TCP的一种新的网络协议。它实现了浏览器与服务器全双工(full-duplex)通信——允许服务器主动发送信息给客户端。 最近在项目中需要开发响应 WebSocket 的服务器程序来实现向客户端推送视频流的功能，刚好 Javalin 在最新版本中已经添加了对 WebSocket 的基本支持，于是有了这篇文章。 依赖关系配置（基于 Maven）和前面一样，使用 Maven 作为项目的包管理工具。要使 Javalin 框架的应用程序完整支持 WebSocket，需要额外添加以下的依赖关系包： 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty.websocket&lt;/groupId&gt; &lt;artifactId&gt;websocket-servlet&lt;/artifactId&gt; &lt;version&gt;9.4.7.v20170914&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty.websocket&lt;/groupId&gt; &lt;artifactId&gt;websocket-server&lt;/artifactId&gt; &lt;version&gt;9.4.7.v20170914&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty.websocket&lt;/groupId&gt; &lt;artifactId&gt;websocket-common&lt;/artifactId&gt; &lt;version&gt;9.4.7.v20170914&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty.websocket&lt;/groupId&gt; &lt;artifactId&gt;websocket-api&lt;/artifactId&gt; &lt;version&gt;9.4.7.v20170914&lt;/version&gt;&lt;/dependency&gt; 为了避免一些千奇百怪的类、方法错误，建议加入的 jetty 依赖包的版本尽量保持严格一直（然而在目前的开发中还是遇到了奇奇怪怪的方法缺失错误，虽然不影响正常的运行不过看着还是蛮闹心的Orz） 四个基本方法和前面介绍的一样，Javalin 主要还是通过 lamada 表达式的方式来实现对特定路径的 WebSocket响应，基本的代码架构如下： 12345678910app.ws(\"/path\",ws -&gt;&#123; ws.onConnect(session -&gt; &#123; //do something &#125;); ws.onMessage((session,message) -&gt; &#123; &#125;); ws.onClose(/*insert you lamada expr*/); ws.onError(/*insert you lamada expr*/);&#125;); 四个以on开头的方法是实现 WebSocket 基本功能的方法，每个方法的基本含义如下： onConnect( session)用于处理客户端与服务器端的连接事件，用session来指代服务器端与具体某个客户端的连接本身。session中有个getRemoteEndpoint()的方法可以获取表征客户端的“端点”一类的东西，通过这个“端点”，可以随时“主动”的向客户端发送数据。这也是 WebSocket 的优势和魅力所在（一旦建立连接之后，服务器端可以根据具体情况随时主动的向客户端推送信息）。 onMessage(session,message)用于处理收到客户端信息时候的响应，session 的基本含义同上，message 表示来自客户端的信息。 onClose()用于处理连接关闭时的事件。 onError()用于发生错误时的响应。 其他Javalin 当中对于 WebSocket 的实现，主要是建基于 jetty 对 WebSocket 的支持的基础上进行了二次封装，所以，Javalin目前不支持的一些方法、操作等都可以单独引用 jetty 提供的方法进行实现，只是这时候更加要注意依赖关系等问题了。 除了绑定 lamada 表达式之外，app.ws()方法也可以将特定路径和实现了 WebSocket 响应的具体的类进行绑定，不过这个我还没有尝试过，理论上来说用起来会更加灵活，以后如果用到了也会写后续文章跟大家分享使用经验。","tags":[{"name":"Java","slug":"Java","permalink":"https://antarx.com/tags/Java/"},{"name":"Javalin","slug":"Javalin","permalink":"https://antarx.com/tags/Javalin/"},{"name":"WebSocket","slug":"WebSocket","permalink":"https://antarx.com/tags/WebSocket/"}]},{"title":"Javalin 框架使用指南（一）","date":"2017-10-24T06:28:20.000Z","path":"2017/10/24/javalin1/","text":"Javalin是一款建基于 jetty 的轻量级 RESTful 框架，支援 Java 和 Kotlin 编程语言，非常适合用来部署REST 风格的微服务程序，因为里面对 lamada 表达式的应用可以说是到了出神入化的地步，所以一直都是我最喜欢用的框架。这系列的文章主要是介绍如何在微服务开发中应用这套框架来进行开发。 安装Javalin 支持几乎所有常见的项目管理工具，出于一般性，文章中以 Maven 为例进行说明。 安装框架本体 在项目的 pom.xml文件中的&lt;dependencies&gt;&lt;/dependencies&gt;标签下粘贴以下代码。 12345&lt;dependency&gt; &lt;groupId&gt;io.javalin&lt;/groupId&gt; &lt;artifactId&gt;javalin&lt;/artifactId&gt; &lt;version&gt;0.5.4&lt;/version&gt;&lt;/dependency&gt; 这是官网中介绍的安装方法，要注意到，仅仅粘贴了以上代码段的话，会遇到两个问题： maven 默认的 JVM 环境是 JDK1.6，是不支持 Lamada 表达式这种尤物的，我们需要在项目中添加 Java8支持。 在pom.xml中粘贴以下代码： 123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 要注意到这段代码和&lt;dependencies&gt;&lt;/dependencies&gt;标签段是并行而不是包含关系的。 在运行过程中可能会遇到以下错误提示： 1SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. ​ ​ 虽然这个错误提示不会影响程序的正常运行，但强迫症总是让人不爽，解决方法是添加这个依赖关系 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt; 经过以上配置之后，就可以跑起第一段程序了 HelloWorldHelloWorld 是开发者学习新的编程语言、框架所绕不过去的坎，用 Javalin 开发一个 GET 方法访问根路径返回“helloworld”的 REST 服务器非常的简单。示例代码如下： 12345678import io.javalin.Javalin;public class HelloWorld &#123; public static void main(String[] args) &#123; Javalin app = Javalin.start(7000); app.get(\"/\", ctx -&gt; ctx.result(\"Hello World\")); &#125;&#125; 从代码中可以看出，通过一个 lamada 表达式就可以完成指定路径到具体响应方法的绑定操作，还有什么比这个更让 RESTful 微服务开发者拍手称快的呢。 简单说明一下，框架中用 Javalin 类型的一个对象实例来完成整个 RESTful 风格的服务器的全部操作。上述代码中，首先是实例化了一个名为app的 Javalin类型实体，然后调用了get(String path, lamada expression)，以 lamada 表达式的表示一个具体的响应操作，以字符串的形式表示具体的路径，将两者绑定到一体。方法名称get表示响应 REST 规范中的 GET 请求。 此外，ctx参数指代的是连接上下文，调用result()方法可以将字符串塞进响应体中进行返回。 MOREJavalin 框架的安装和第一个服务器程序都可以非常简便的就完成了，但这只是一个开始，通过 Javalin 框架可以完成非常复杂的响应逻辑，而且最近的更新版本中还加入了对 WebSocket 服务器的支持。接下来的文章将会介绍如何进行进一步的开发和遇到的常见问题等。 1024节日快乐:halloween:","tags":[{"name":"Java","slug":"Java","permalink":"https://antarx.com/tags/Java/"},{"name":"REST","slug":"REST","permalink":"https://antarx.com/tags/REST/"},{"name":"微服务","slug":"微服务","permalink":"https://antarx.com/tags/微服务/"}]},{"title":"vscode配置 c++ 开发环境(二):调试和头文件设置","date":"2017-10-18T06:28:45.000Z","path":"2017/10/18/vscode2/","text":"前言上次在vscode配置 c++ 开发环境(一):智能提示文章中介绍了如何在 vscode 中配置 c++语言的智能提示，时间又过了很久，vscode 用的也越来越得心应手，今天终于有机会更新这个系列的第二篇文章，讲讲如何配置includePath来避免不愉快的波浪线和怎么用 vscode 对 cpp 程序进行调试。 头文件目录配置在默认情况下，就算是已经将 cpp 开发相关的插件装好，用 VScode 打开一个 cpp 文件的时候，通常还会看到令人不悦的波浪线，就像下面这样： 软件找不到头文件时会有波浪线提示 刚开始的时候我也非常的头疼这个问题，后来在vscode 官方博客的文章中找到了解决方案。 首先，在使用习惯上，要用 vscode 打开源代码所在的文件夹而不是打开单个文件，比如所，我有个Josephus.cpp源文件在cppcode文件夹下，那么就要在终端上输入code cppcode 用 vscode 打开这个文件夹，再对那个源代码文件进行编辑和处理，而避免直接code Josephus.cpp打开单个文件。（下面的相关配置都是基于这个使用习惯的基础之上的） 然后，在文件夹下新建.vscode目录（如果该目录已经存在，则可以略过这一步）。 在.vscode文件夹下，新建c_cpp_properties.jsonjson 配置文件，在文件中粘贴以下代码： 12345678910111213141516171819202122232425262728&#123; \"configurations\": [ &#123; \"name\": \"Mac\", \"includePath\": [ \"/usr/include\", \"/usr/local/include\", \"/usr/include/c++/4.2.1\" ], \"browse\": &#123; \"limitSymbolsToIncludedHeaders\": true, \"databaseFilename\": \"\", \"path\": [ \"/usr/include\", \"/usr/local/include\", \"$&#123;workspaceRoot&#125;\" ] &#125;, \"intelliSenseMode\": \"clang-x64\", \"macFrameworkPath\": [ \"/System/Library/Frameworks\", \"/Library/Frameworks\" ] &#125; ], \"version\": 3&#125; 在这个配置文件中，includePath字段是指定 VScode\b 搜索头文件的目录，如果目录中不存在源代码里引用的头文件，则会有波浪线提示。 所以，将用到的头文件所在的位置都添加到该字段中，就可以解决“波浪线”问题了。 调试设置在 Windows 上面用 VS 进行 C++开发的时候，最吸引人的一个功能是完善的调试功能，\b类似的功能在 VScode 上也可以实现。 首先，在.vscode\b文件夹下新建 launch.json和tasks.json两个配置文件，其中，\blaunch.json文件是配置调试信息，tasks.json是用于配置编译信息。 tasks.json文件下，粘贴以下代码： 1234567891011121314151617&#123; \"version\": \"0.1.0\", \"command\": \"clang++\", \"args\": [\"-g\",\"$&#123;file&#125;\",\"-o\",\"$&#123;file&#125;.out\"], // 编译命令参数 \"problemMatcher\": &#123; \"owner\": \"cpp\", \"fileLocation\": [\"relative\", \"$&#123;workspaceRoot&#125;\"], \"pattern\": &#123; \"regexp\": \"^(.*):(\\\\d+):(\\\\d+):\\\\s+(warning|error):\\\\s+(.*)$\", \"file\": 1, \"line\": 2, \"column\": 3, \"severity\": 4, \"message\": 5 &#125; &#125;&#125; 上述代码中，command字段是编译程序（编译命令），根据个人喜好可以填g++或 clang++（编译 C++），如果想编译 c，也可以填 gcc 或 clang。args字段是编译时添加的指令，${file}.out\b\b中${file}指的是当前编辑文件的文件名。（如果是在 Windows 下面配置，需要写成${file}.exe） launch.json文件下，粘贴以下代码： 1234567891011121314151617&#123; \"version\": \"0.2.0\", \"configurations\": [ &#123; \"name\": \"(lldb) Launch\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"$&#123;file&#125;.out\", \"args\": [], \"stopAtEntry\": false, \"cwd\": \"$&#123;workspaceRoot&#125;\", \"environment\": [], \"externalConsole\": true, \"MIMode\": \"lldb\" &#125; ]&#125; &quot;program&quot;: &quot;${file}.out&quot;字段表示调试的目标程序。 两个文件都配置好之后，打开要调试的 cpp 文件，首先选择“任务”-&gt;“运行任务…”,弹出的窗口中选择\bclang++,这一步是编译程序生成.out 文件的过程。 运行完毕后，选择“调试”-&gt;”\b启动调试“或按 F5快捷键，启动调试。如果看到下面这样的\b界面，表示\b配置没有问题，进入调试过程。 调试Josephus.cpp 参考网站如何在VSCode内编译运行C++","tags":[{"name":"vscode","slug":"vscode","permalink":"https://antarx.com/tags/vscode/"},{"name":"Microsoft","slug":"Microsoft","permalink":"https://antarx.com/tags/Microsoft/"},{"name":"c++","slug":"c","permalink":"https://antarx.com/tags/c/"},{"name":"IDE","slug":"IDE","permalink":"https://antarx.com/tags/IDE/"}]},{"title":"macOS下使用 docker 进行 CSharp 开发（一）","date":"2017-08-27T10:46:52.000Z","path":"2017/08/27/dotnetdocker/","text":"前言过去一年多时间里一直忙着准备考研、OJ、毕设这些东西，都没时间在微软的技术方面进行更深入的学习。现在很多事情都尘埃落定之后，终于可以重操旧业继续传教之路。因为研究生研究的方向跟 docker 有些关系，自己也觉得这玩意挺有意思的。所以，以后的一大段时间里都会探索.net 跟 docker 的结合的相关应用。这一系列文章如果没有特别说明，都是以 macOS 为主要的开发环境，也算是为微软的跨平台大业添砖加瓦了。 这篇算是一个起点，探讨在 macOS 环境下进行开发的相关配置。 安装 Docker 环境现在在 macOS 上安装 docker 已经没有以前那么复杂了。基本上就是下载 dmg 文件回来拖拖鼠标的事儿。在毕设那段时间的体验中，甚至觉得在 macOS 上安装 Docker 是最为简便快捷，很难出什么幺蛾子的。：） 下载地址：Docker 官网经测试现在不用翻墙就可以访问啦。要下载镜像的话还是配置加速器会比较快一些，我自己是配了阿里云提供的一个加速器地址。注册阿里云账号之后会免费提供。 下载 dotnet 镜像运行命令1docker pull microsoft/dotnet 默认下载的是 latest 版本。 基于镜像运行容器在开发中我的习惯是将源代码放到本地的文件夹中，然后将这个文件夹挂载到 Docker 容器里面，这样在本地就可以用自己熟悉的环境对源代码各种修改，容器那边只需要重启一下就会自动运行新版本的代码，十分方便。 运行以下命令：1docker run -it -v `pwd`:/csharp -w /csharp microsoft/dotnet 命令中通过-it开启了实时交互模式，只是因为在家里没梯子\b，下载 dotnet core 的 SDK 贼慢，只好采取此方法。实际应用的时候\b可以在本地 shell 先建立好项目编辑完源代码直接甩容器里跑最方便的。 新建项目、编辑代码、运行运行容器之后，在容器弹出的交互界面中，输入1dotnet new console -o hwapp 命令的基本含义是以控制台为模板新建一个名为hwapp的项目。在本机，用 vscode 打开工作目录下的 Program.cs 源文件，编辑代码，本次以输出“hello docker‘为例。编辑完代码，保存之后，在\b容器的终端中运行dotnet run运行项目。 运行结果 //忽略第一次那个白痴错误（汗 后记到此为止，在 macOS 下用 Docker 运行.net 程序的第一次尝试就完成了。要补充的内容还有很多，比如配置 vscode 开发环境等等工作，也只能等到回校有畅快的开发环境再慢慢补完了。","tags":[{"name":"docker","slug":"docker","permalink":"https://antarx.com/tags/docker/"}]},{"title":"Java Mongodb 使用指南（一）增删查改","date":"2017-07-20T08:22:24.000Z","path":"2017/07/20/mongodbj/","text":"前言最近在重构之前宇宙 mei毕设项目的注册中心，为了跟 Docker 容器技术无缝衔接将原先的 SQLServer 换成了与前端统一的 mongodb。让人不愉快的是，java 调用 mongodb 时遇到了好些问题，首先是 mongo版本更新3.0.0之后DB 相关的 API 已经废弃不用了，直接导致很多不够新的书籍都不具有参考价值；此外无论官网提供的 API 参考还是网络上很多教程，要么就是甩了一堆天花龙凤的代码，要么就是摸不着头脑的类列表。所以才有了这篇方便理顺思路的文章。 基本概念先讲清楚两个后面用到的最重要的两个类：BSON和Document。 BSONBSON是 JSON 文件的二进制储存格式。在 mongodb 的 Java 驱动中，这种数据类型主要用于建立查询条件。比如说在 mongodb shell 里面.find({&quot;id&quot;:&quot;0001&quot;})这句话里面的{&quot;id&quot;:&quot;0001&quot;}部分对应在 Java 代码里面就是一个 BSON。 查询条件里面有个很有意思的概念是操作算子/条件算子，具体留到另一篇文章再说。 Document官方翻译是文档，就是对应于一条 JSON 格式数据。在使用中要注意的是这玩意不能用String 类型的 JSON 格式字符串来初始化，只能用 Map 类型或者单一键值对来初始化。 操作增（Insert）mongoCollection.insertOne(Document) 直接插入 Document 类型的数据。要注意的是这个插入默认是无条件的，是可以连续两次插入完全一样的文档（因为在 mongodb 内部是用_id来判断两个文档） 删（delete）mongoCollection.deleteOne(BSON) 这个方法可以用来删除满足条件的一条数据，BSON 用于定义条件，比方说，要删除 id 字段为0001的数据，构造的 BSON 对象就是new BasicDBObject(&quot;id&quot;,&quot;0001&quot;)，完整的调用语句就是mongoCollection(new BasicDBObject(&quot;id&quot;,&quot;0001&quot;))。 查（find）mongoCollection.find() 默认不加参数时，会返回这个集合中的所有文档，返回类型是一个类似迭代器的东西，要遍历查询结果时可以这样写： 1234FindIterable&lt;Document&gt; res = mongoCollection.find();for(Document item : res)&#123; //do something&#125; 在这段代码中的 res，有个.first()方法，返回所有结果的第一个元素，如果结果是空集的时候，方法返回null。有意思的是，就算结果集是空集（找不到任何东西），res 也不会是 null。所以判断查找是否成功对 first()方法判空。 mongoCollection.find(BSON) 传入参数是客制化的查找条件（BSON 格式） 改（update 或 replace）mongoCollection.replace(BSON,Document) 第一个参数是查询条件，第二个参数是完整的文档，这个方法的作用是将满足条件的文档用传入参数中的文档来进行替换。 .updateOne(BSON bson1,BSON bson2) 调用这个方法时，第一个 bson 是查询条件，第二个 bson （bson1）是替换目标，这个方法执行结果是查询满足条件bson1的结果，然后将这些文档的 bson1字段用 bson2代替。 这个方法执行起来可能会让人很无语，因为按照直觉，我们调用的时候可能更想做的是查找满足条件的文档，然后将里面的其他一些字段用 bson2替换掉。要实现这个功能也不是不可能的，不过要搞个嵌套 BasicDBObject，要用到$set操作算子。示例代码段如下： 12BasicDBObject opr = new BasicDBObject(\"$set\",new BasicDBObject(\"status\",\"on\"));mongoCollection.updateOne(new BasicDBObject(\"id\",\"0005\"),opr); 这段代码执行的结果是查找 id 是0005的文档，然后把这个文档中的 status 字段设为 on。","tags":[{"name":"java","slug":"java","permalink":"https://antarx.com/tags/java/"}]},{"title":"一年战争默示录","date":"2017-03-27T13:08:12.000Z","path":"2017/03/27/uc2017/","text":"前言2016年3月初, 正式确立考研的想法并且选择了跨考计算机科学与技术, 到2017年3月底刘老师的一句“已录取”一锤定音, 过去的整整一年, 就像是一场漫长的战争, 中间有很多事情需要被记录和回忆, 所以就有了这篇. 套用了 Gundam UC 时代番外篇作为标题, 不仅仅是因为时间的巧合, 还是因为考研这件事和UC0079的一年战争一样, 损耗了极大量的时间,精力, 金钱等等等等. 抉择在2016年年初,对考研这件事上还是抱着极端反对的态度, 因为这意味着会有大半年的时间放弃很多事情, 只能困在自习室里, 反复的刷题, 看书, 背诵, 更何况通信原理还是我不甚喜欢的科目, 而那个时候看803计算机学科综合, 还是四门极难的天书. 很庆幸的是, 改变会在三月份发生了. 那时候还想着一边跟父母说要考研, 一边默默去找实习找工作, 但第一次电话面试的时候, 就被狠狠的虐了一把, 操作系统, 计算机网络, 乃至很基本的计算机常识, 缺位的知识实在太多, 毕竟是大二的时候才培养出来的对计算机科学的兴趣, 平时虽然也写过一些洋洋得意的代码, 然而和科班出身的人还是没法比的. 那时候很后悔过去的三年没有好好的学习. 后悔归后悔, 丢下的东西就要想办法补回来. 在那个时间点上, 弥补的唯一方法就只有考研这条路了, 跨考803, 就可以有至少四个月完整的时间去真正接触计算机科学最基本的那几门学科, 就算最后考不上, 也至少为自己积累一些底蕴. 另外一个影响我决定的因素, 说起来有些不可思议又顺理成章. 过去三年, 由于某些众所周知的原因, 我一直在阅读各类关于思维, 学习习惯的心理学书籍, 看的书多了自然会手痒想实践,而都大三了也没几门专业课可以让我练手了, 剩下的都是通信网这么既没有兴趣也没什么大用的硬骨头. 于是, 我把目光放到了考研这件事上来, 从时间跨度,外部环境, 学习内容上看,确实也是不可多得的实验素材. 就这样, 做出了一年战争的决定. 改变世界的三本书没有这三本书, 我一定不可能坚持下来到现在, 更别说有看上去还不错的成绩了. 深入理解计算机系统( CSAPP)在追求计算机科学的路上绝对值得大书特书的一本书。其实大二的时候就买了,然而因为各种原因没有啃下来, 到了2016年的三月份作出决定之后, 忽然一下子就有了不妨试试的想法, 开始阅读. 对待这本书最好的方法当然是一边看书一边实践,在当时这么做的话很明显时间是相当不足的.无奈之下我只好采用了《如何阅读一本书》里面提到的快速阅读的方法.以尽可能快的速度通读全本, 记录每一章的重点, 寻找这本书的脉络和骨架. 即使是这么的阅读,拖延症的我也是花了整整一个月的时间。通读过后, 竟也有醍醐灌顶般的顿悟, 对于计算机学科, 从最开始的”信息=位+上下文”的基本公理，到操作系统的一系列基本概念,乃至最后的服务器编程, 都有了比较清晰的认知, 后来的学习中也慢慢发现，正是这种认知，为803专业课的学习扫清了几乎所有的障碍。除此之外,还在准备机试的时候体会到好些微妙的副作用, 这个以后有机会再说. 龟书——计算机科学的基础这是图灵社区一本免费公版的电子书，讲的内容非常之杂而且数学化，从递归思想讲起，到整整一章快五十页的大 O 复杂度推导，到常见的数据结构定义，再到离散数学基础，正则表达式，关系模型，再到最后的一点点数电知识，涉及的领域无孔不入。更加神奇的是，85%的概念都用递归的形式给出或者证明。 很遗憾，这本书没有看完，但最关键的地方都看了，涉及数据结构的都认真的看了一遍，尤其是大 O 那章，更是多遍过后仍然意犹未尽。 这本书带来的,是对数据结构概念的认知颠覆。大学的计算机类课程里，除了微机原理之外，唯一不到90分的就只有数据结构了，因为当时教材没选好，上课也不认真听，学的云里雾里，知其然不知其所以然，除了几个可以喃喃自语的弗洛伊德算法，D 算法之外，一无所获。正是这本龟书，展现给我不同的世界，每一种数据结构的由来，都能够结合递归讲得一清二楚。更加是给了我到后来面对笔试算法题“只要是递归能写的我都能做出来”的自信。 奇特的一生一本很普通的传记，讲述的一个不那么普通的前苏联昆虫学家的故事。里面贯穿的主题是时间统计法，这个方法给我接下来的几个月复习带来了无尽的启迪，也开始了一段颇为清奇的复习之路。 流水账模式-初试复习记录铺垫说了这么多，也是时候到了各种考研经验贴喜闻乐见的所谓时间分配+学习方法型的行文模式了。不过，在这篇默示录里，我并不想把接下来的这些作为经验方法来说，因为我自以为，无论是时间分配还是学习方法，都是极为私人的事情，每个人的思维习惯和自己的紧密相连的，靠模仿是不可能真正成功的（这也是我为什么现在不粉德约科维奇的原因之一）。再者，和北邮人论坛里一众大神的经验,尤其是那位我相当欣赏,佩服的成功考研清华的姑娘相比，我在复习的时候付出的东西也真的太少太少了。 八月份之前各种浪，期间看了麻省理工大学的线性代数公开课（这也是值得大书特书的课程，具体放到后面再讲），快速阅读了《现代操作系统》，《计算机网络——自顶向下方法》，顺路背了下红宝书英语单词。 八月份回家之后，全面复习正式拉开大幕。（别人都是七月回家八月回校开始复习。。我的奇葩复习之路就这么开始了(⊙﹏⊙)b） 在家二十五天时间，看完了一遍李永乐数学全书（没怎么做题，单纯记录一下重难点和奇技淫巧。。。），王道四本单科书看了两本半（差计算机组成后半部分和计算机网络全本，做每一节后面的选择题）。英语阅读看张剑的小黄文150篇，结果各种懵逼，只好作罢，继续背单词。 平均每天复习时间295分钟。 九月份到十月十五日回到学校之后，开始了每天直奔图书馆的日子，开始做题之后，发现了自己在数学尤其是微积分方面的严重不足，邂逅了《张宇高数18讲》，开始把每天学习数学的时间都放在了阅读18讲和做660题打基础上面了，一天二十几题，有点低效率。 专业课还是王道四本书，小题做完然后是极少的一些大题，然后看第二遍。没啥特别好说的。 英语继续小黄文，每天两篇，平均一篇错俩，一个单元错6到8个，心态略崩。 开始看政治大纲解析，抱着学累了娱乐的心态，画画重点，做做一千题。 平均每天学习时间330分钟。 十月中旬到十一月初一年战争中最为关键的一段时期，在 UC 时代里面大概是 阿姆罗坐上了RX-78，NewType 开始引起联邦和吉翁的注意。 在现实里也是这样，在这段时间，最重要的事情是投入时间做张宇《真题大全解30年数学真题》，在数学上收获了极为重要的自信。英语开始研究往年真题，第一遍。专业课的王道四本书二刷也完了，每天写一下阅读感悟之类的，把想了好久才想通的问题，看完特别叹为观止的问题记录一下。 政治还是老样子。 平均学习时间每天384分钟。 十一月白热化阶段。 数学每天都在做真题，有时还放放羊，并不能实现每天一套的宏愿，到最后十二月之前也总算能彻彻底底的完成了第一遍。张宇八套卷跟风买了，做了两套多一点，也确实太难，坚持不下去。找到自己薄弱的地方，针对性的看张宇的视频。 专业课开始撸小蓝书过去的十年408真题，也继续是选择大题拆分完成的思路，规定时间60分钟到75分钟完成选择题做完题分析一下不会的，做错的，也记录一下，顺带王道四本书挑重点三刷。 英语，真题二刷，这次是规定好时间90分钟完成选择题部分。然后就是开始整理作文模板了。并没有怎么写作文。。太懒 orz 政治，肖老八套卷上市，也就买回来做了，选择题部分认真做，错的也都不少，做完认真总结和回看大纲解析。风中劲草也上市了，看完了第一遍，记住的东西也并不多。 平均每天复习458分钟。 十二月这个月可就是争夺阿尔巴空的时候了。 数学没什么力气做四套卷八套卷，每天整理重做三十年真题中的错题，补补张宇的视频。然后看真题大全解的答案解析书。难题啃一啃。最后两周挑几份经典的往年真题重做一下，保持手感。 专业课做王道的八套模拟题，比408真题难，做下来还是很有收获的。 英语：练作文，练作文，练作文。翻译适当看看，真题可以再做一遍。 政治：肖秀荣四套卷，考完出来才会真正感叹准确度可以有多高。 平均复习时间每天497分钟。 每天的时间安排这里说的是复习阶段每天都适用的情况。 早上雷打不动做数学，无论状态多好或者多不好。一般早上有效复习时间最多150来分钟，八点多快九点的时候到图书馆，十二点吃饭，只有十二月才能经常实现180分钟+的有效复习时间。 下午是属于专业课和英语的时间，大概是60+90+25的套路，“60+90”是轮换制，比如说今天90分钟英语真题，60分钟专业课那么第二天就是60分钟英语90分钟专业课。25分钟是随心所欲的机动时间。 晚上属于整理知识点的时间，把白天做错的题目都再过一遍，以及回顾之类的。比较轻松 学科学习过程记录相比时间安排这种私人化的东西，针对不同学科的学习方法反而是更加固定一些,毕竟学科的特点都摆在那儿. 数学数学一包括完整的微积分部分,概率论和数理统计，线性代数。一个一个来。 微积分前面也说了，微积分部分的基础学的相当的不扎实，即是是看完了一遍全书，做题的时候还是被打成筛子了。这里很感谢一本书，《张宇高数十八讲》，如果说全书是极为详尽的知识参考的话，十八讲就是提供了解题最需要的方法论内容。而且张宇的娓娓道来的风格，很适合缺乏解题方法的初学者入手学习。 线性代数MIT 线性代数公开课+黄皮线性代数第七版（外国教材）+分阶习题线性代数部分 公开课是值得大书特书的部分。特别适合那种大一学线性代数最后通过了但还是一脸懵逼的同学。请扔掉所有从行列式入手的线性代数教材，这种从行列式再到矩阵的学习思路是及其反人类，也违反了线性代数学科最基本的原则的。 MIT公开课从线性方程组，再到矩阵，再到行列式的线索讲述这门极具吸引力的学科，把矩阵，线性空间，线性方程组，向量彻底的联系起来，才能够真正学懂线性代数。里面对于行列式用三大性质+延伸推导运算性质的方式来定义的方法，彻底帮我扫除了大一入学第一周就要面对用双竖线包围的一大堆数和奇奇怪怪的运算性质的恐惧。 概率论《概率与统计》一本书就够了，反而没什么好说的。。。 题集 660题-都是基础题，而且都是填空选择，拿来训练数学思维是相当有帮助的。一开始上手的时候千万不要因为题量大就产生恐惧心理，一天20道30道，坚持下来，就能发达。 30年真题——2017年刚好遇上了数学一放水的时候（习惯把这种年份比作快速硬地的比赛2333333333），所以往年真题的帮助特别大，难度适中，知识点覆盖全面。做的时候配合国誉双栏笔记本记录错题索引，得闲就翻一翻。到最后考试，发现每一道题都能在过去30年真题中找到解题方法。 四套卷八套卷：拿来观光奇技淫巧解题不错。 英语单词+真题，学习语言的方法不过是足够多的词汇量积累和大量重复的练习，将自己暴露在语言环境当中。 单词书红宝书+20天搞定考研词汇+不背单词 app 题集其实，只需要真题。 05-16年真题反复做，标注难词难句，理清结构，阅读题问题分类攻克 作文作文写得不大好，就算了不说太多了 作文素材是一定要积累的。模板要看，但也得会创新，要形成自己的东西，或者至少能将不同的模板搅在一起。 多总结，按照话题整理出不同的模板，例子，论证方法，这个是必须做的。追求高分的话还可以根据不同的论证方法按照不同行文方式来分类整理一次。 计算机学科基础综合这次考试专业课可是帮了大忙，本来还以为跨考的话专业课只要不拖后腿就行，结果貌似来了个网研院最高分，还是值得庆幸的。 书籍 王道四本单科书+八套模拟题+408真题+803真题，多做几遍，务求看懂。 现代操作系统+计算机网络(自顶向下)，拿来补基础知识用的。数据结构和计算机组成直接在龟书和 CSAPP 上顺带看了，帮助很大。不过国外的教材知识全面，内容充实，适合在特别早的阶段看，6月之后再开始的话时间会很紧，消化不良就不好了。 计算机专业课实际上都是融会贯通的，一切统一于 CSAPP（误。所以803的东西看起来虽然很多，但千万不要产生恐惧心理，要时刻从系统的观点来看待理解学习的知识，会事半功倍。 政治背背背背背背 书籍 大纲解析，肖秀荣精讲精练二选一 风中劲草+1000题（对于攻克选择题帮助会非常大） 肖老师八套卷四套卷：今年全面命中大题，不能不强烈推荐。四套卷大题必背，八套卷的选择题多做几次，大题多看，这儿肖老师的公众号讲得非常好，我就不班门弄斧了。 其实政治考的不算理想,选择题大翻车，所以更加没有什么学习方法可言了，毕竟在几乎整个复习阶段中政治都是拿来放松心情，拿来娱乐用的。 复试初试成绩出来之后就开始准备复试了。其实在初试结束彻底 happy 之后马上开始准备是相当好的，毕竟笔试6选4，时间紧任务重。再说诸如编译原理，计算机系统结构，人工智能这些课程，对于热爱计算机学科的人来说绝对是一道饕餮盛宴。 另外一个就是机试，OJ 的输入输出处理，测试数据覆盖等方面与平时开发写代码是很大的不一样的，等初试成绩出来之后就到kAri OJ 熟悉考试方式，每天水水题，美滋滋。 至于面试，运气还不错，碰到的题都是有点印象的东西，不至于哑口无言的尴尬局面，老师们也相当的友好。如果本科阶段多做些项目多参加一些竞赛的话会为面试增加更多的资本的。 后记能够保研还是千万别考研吧，牺牲的东西实在是太多太多了。 还是那句话，写下默示录目的就是拿来回忆用的，谈不上什么学习方法，时间分配方法，更加不能算什么经验。里面可能最有用的就是提到的几本书了。学习方法始终都是非常私人的事情，希望本文可以帮助准备考研的每一个人都能找到属于自己的学习方法。 如果有兴趣和我探讨心智思维相关的内容，或者交流计算机科学相关的东西，欢迎联系。 微信：antarx75 感谢一年战争能够有好不错的成功，光靠自己是完全不可能的，很多的人和事给我带来了无尽的帮助。 感谢小C 的图书馆座位，让我有四层大桌子的复习环境。 坐我右边的曹菊苣，平时交流数学，得到了很多的启发。 计算机学院事实上专业第一，大一就手撸操作系统的99壕，帮我解决了很多803的疑难杂症。 感谢 Andy Murray 的2016年年终第一，伦敦的终极之战为我的12月打了很多鸡血。 牛18带来的运气。 陪伴我刷题的钢笔们：三文堂 ECO，580RB，写乐1031，百乐74，永生698，Lamy Vista，等等等等。 墨水们：自由极乐，飞虎队，呆米家族，RK 铁胆 一半以上时间都用来种树的 oneplus3。 以及一时间可能想不起来的更多人和事。","tags":[{"name":"随笔","slug":"随笔","permalink":"https://antarx.com/tags/随笔/"}]},{"title":"2017考研-北邮网研院机试试题 ProblemC","date":"2017-03-27T02:13:00.000Z","path":"2017/03/27/2017c/","text":"题目大意求给定高度为 n 的 AVL 树最少的结点数模$1e9+7$的值. Hint: $(a+b)\\%p = (a\\%p) + (b\\%p)$ 难点和解题思路原题目给出了关于 AVL 树的相关定义,帮助我们理解题目的相关概念. AVL树就是平衡的二叉排序树, 能够保证这棵树在满足二叉排序树基本特性的同时, 每一个非叶子节点的左右子树节点数之差不大于1. 关于高度为$h$的 AVL 树的最少节点数,其实是有递推公式的, 就是$h[n] = h[n-1]+h[n-2]+1, n&gt;2$ 根据这个递推公式, 就可以将问题从看似复杂的树问题转化为类似求解斐波那契数列的简单问题了. 还有一个坑点, 就是题目给出的AVL树的高度可能会很高, 从数据规模上看, 斐波那契型的数列通项都是指数型增长的, “正常”的数据类型分分钟存不下这么大的数据. 再仔细看题目, 要求的只是结果模$1e9+7$然后输出, 还给出了余数相关的定理来”暗示”, 不由得想到这样的思路, 首先建一个long long 类型的大数组h[MAX_N], 高度为i 的 AVL 树的节点数对1e9+7取模的结果储存在h[i]中, 然后用相同的递推关系计算数组的每一个元素. 而且, 还可以将取余操作简化为减法操作, 大大的降低算法的运行时间. 代码因为题目的原题和测试数据在考试结束之后就及时关闭了, 所以只能凭借记忆写下来. 123456789101112131415161718192021#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;long long w = 1000000007;long long res[100050];int main()&#123; int T; cin&gt;&gt;T; memset(res,0,sizeof(res)); res[1] = 1; res[2] = 2; for(int i=3;i&lt;100050;i++)&#123; res[i] = res[i-1]+res[i-2]; if(res[i]&gt;w) res[i]-=w; &#125; while(T--)&#123; int h; cin&gt;&gt;h; cout&lt;&lt;res[h]&lt;&lt;endl; &#125;&#125; 注意事项 long long 类型最好还是使用cout 来处理读写, 在本机调试时发现,用 printf(&quot;%lld&quot;)处理出现了奇奇怪怪的 bug, 用cout 就没事了. 数组预处理放在循环以外进行, 否则很有可能超时. 上面的示例代码, 在 BOJ 测试时时间性能是59ms( 上限是1000ms)","tags":[{"name":"BOJ","slug":"BOJ","permalink":"https://antarx.com/tags/BOJ/"}]},{"title":"BOJ 解题报告-268进程管理","date":"2017-03-11T12:36:09.000Z","path":"2017/03/11/268/","text":"前言进行 OJ 练习以来做的最复杂的一个题目,A 完之后趁热打铁写个解题报告. 题目描述详情访问268.进程管理 大体的意思就是实现操作系统中进程管理基本的 fork, kill 和查询功能 输入输出处理输入第一行是整数 T, 表示有多少组输入数据. 第二行是整数 N, 表示本组数据中有多少行命令. 接下来每一行是一条命令.形式如下 FORK PID_1 PID_2 KILL PID QUERY PID 难点一: 同时出现输入组数和操作的数量这是在之前做的题目中没出现过的.解决办法如下面代码 1234567while(T--)&#123; int n; scanf(\"%d\",&amp;n); while(n--)&#123; //do something &#125;&#125; 难点二: 如何应对输入命令的不同格式从给出的示例可见, FORK 后面有两个整形参数,其他两个命令后面都只有一个参数,这个时候如果只使用scanf()函数处理输入,会因为输入的变量个数不一致而出现奇奇怪怪的问题,所以转而先使用gets( char*) 获取一整行命令读进 buff 数组,然后用sscanf(char* source, char* fomat, …)进行处理. 要注意的是,因为 scanf(&quot;%d&quot;,&amp;n)之后会有个\\n 会塞在缓冲区, 影响 gets() 函数的正常读入,所以要先getchar() 一下. 另外, gets() 函数在 c11标准中不再被支持,使用之前要注意运行环境限制. 输出当输入命令为QUERY PID 的形式时会产生输出,如果查询的进程存在则输出 Yes, 否则输出 No.( 注意大小写) 解题思路和坑点数据储存首先要解决数据储存的问题. 采用 bool 类型数组记录每个进程的存在情况, 并且使用下标记录进程号. map&lt;int,vector&lt;int&gt; &gt;来记录每个进程及其子进程的映射.按照操作系统课本的思想采用链表记录最为恰当,但在 OJ 这种特殊情况下, 自然可以选择更加”偷懒”的方法.更何况 STL 的性能还是相当可靠的. 对于每一条命令,用sscanf 处理后将指令部分赋值到string 变量, 方便判断. 坑点一: 0进程不能被删除题目条件中说到0进程在任何情况下都是存在的,因此输入KILL 0不会有任何响应. 坑点二: 子进程的子进程要被删除比如说如下以来关系0-&gt;1-&gt;2-&gt;3-&gt;4,杀死1进程之后,后继的2,3,4进程都必须被杀死,否则会导致 WA. 使用递归删除的办法可以确保子进程的子进程会被安全删除. 不算坑的坑点三题目中还说到KILL 指令中如果是不存在或者已经结束的进程,则不采取任何操作.这一点在本题中靠输入来保证了,所以不用在代码中额外处理.否则,需要额外的数组来记录每个进程的出现情况. 程序代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include&lt;cstdio&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;cstring&gt;#include&lt;map&gt;using std::vector;using std::map;using std::string;char buff[20];char cmd[10];;map&lt;int,vector&lt;int&gt; &gt; relation;bool pid[105];void killKids(int x)&#123; if(!relation[x].empty())&#123; //no empty vector&lt;int&gt;::iterator j; for(j=relation[x].begin();j!=relation[x].end();j++)&#123; pid[*j] = false;//kill it killKids(*j);//kill them all &#125; relation[x].clear(); &#125;&#125;// kill kids methodint main()&#123; int T; scanf(\"%d\",&amp;T); while(T--)&#123; relation.clear();//init memset(pid,0,sizeof(pid)); pid[0] = true; int n; scanf(\"%d\",&amp;n); getchar(); for(int z = n;z&gt;0;z--)&#123; int x,y; gets(buff); if(sscanf(buff,\"%s%d%d\",cmd,&amp;x,&amp;y)==3)&#123; //FORK command if(pid[x])&#123; //x exist relation[x].push_back(y); pid[y] = true; &#125; &#125;else&#123; string act = cmd; if(act == \"QUERY\")&#123; if(pid[x]==1)&#123; puts(\"Yes\"); &#125;else&#123; puts(\"No\"); &#125; &#125;else if(act == \"KILL\")&#123; //end all kids if(pid[x]&amp;&amp;(x!=0))&#123; killKids(x); pid[x] = false;//kill x &#125; &#125; &#125; &#125; &#125;&#125;","tags":[{"name":"BOJ","slug":"BOJ","permalink":"https://antarx.com/tags/BOJ/"}]},{"title":"BOJ解题报告(2)-89-统计时间间隔","date":"2017-03-07T12:23:30.000Z","path":"2017/03/07/89/","text":"题目描述给出两个时间(24小时制)，求第一个时间至少要经过多久才能到达第二个时间。给出的时间一定满足的形式，其中x和y分别代表小时和分钟。0≤x&lt;24,0≤y&lt;60。 输入输出处理输入格式hh:mm,也就是在数字时钟中最常见的24小时表示法, 对于这种输入形式, 可以仿照87题中的技巧通过 scanf(&quot;%d:%d&quot;,&amp;hh,&amp;mm)的形式将时间和分钟分别复制到两个整形变量当中. 输出是最少经过的分钟数, 是一个整形变量,没有太多的技巧. 思路因为题目中要求输出的是分钟数,所以可以先将输入的两个时间换算成当天的分钟数,然后计算时间差就是所求. 要注意的是起始时间大于结束时间的时候, 求出t1-t2要加上24*60(一天的分钟数). 源代码12345678910111213#include&lt;cstdio&gt;int main()&#123; int T,x1,y1,x2,y2; scanf(\"%d\",&amp;T); while(T--)&#123; scanf(\"%d:%d\",&amp;x1,&amp;y1); scanf(\"%d:%d\",&amp;x2,&amp;y2); int t1 = x1*60+y1; int t2 = x2*60+y2; int res = ((t2&gt;=t1)?(t2-t1):(t2-t1+24*60)); printf(\"%d\\n\",res); &#125;&#125;","tags":[{"name":"BOJ","slug":"BOJ","permalink":"https://antarx.com/tags/BOJ/"}]},{"title":"BOJ 解题报告(1)-87-日期","date":"2017-03-07T11:58:57.000Z","path":"2017/03/07/87-cpp/","text":"题目描述请你计算出第X年Y月Z日是第X年的第几天。其中，1月1日是第一天，1月2日是第二天，以此类推。 计算时请注意闰年的影响。对于非整百年，年数能整除4是闰年，否则不是闰年；对于整百年，年数能整除400是闰年，否则不是闰年。如1900年和1901年不是闰年，而2000年和2004年是闰年。 题目链接 思路这是个典型的涉及闰年的日期问题, 要求解某一年是第几天.思路很直接,从月份入手,先计算前$ Y-1$个月一共有多少天,然后在加上这个月中这一天之前有多少天,就可以得到结果. 输入输出处理在所有 OJ 中,输入输出都是绕不过的坎,很多时候会因为输出处理不好而导致莫名其妙的 WA, 又有很多时候可以从输入格式中获得解题的灵感. 回到本题,输入格式为X:Y:Z的形式, X,Y,Z 都是整数, 以冒号隔开.这不由得让我们想到了可以利用 scanf 的格式字段做”手脚”, 直接将 X, Y, Z 读入到整形变量当中进行后续的处理.所以有了以下代码来处理日期的输入. 12int X,Y,Z;scanf(\"%d:%d:%d\",&amp;X,&amp;Y,&amp;Z); 输出方面,只需要输出天数,是一个整形变量,没有什么特别的技巧. 注意事项这部分描述题目中的”边沿”情况, 如果忽略这些情况,就会导致 WA 闰年的处理题目中也给出了提示.在代码中可以利用宏来判断闰年. 1#define ISYEAP(x) ((x%100!=0)&amp;&amp;(x%4==0))||(x%400==0)?1:0 使用宏的时候一定要注意, 编译器在编译的时候会将宏展开之后插到每一个调用宏的地方,为了避免由于运算符优先级问题带来奇奇怪怪的 bug, 建议前后用括号括起来,像这样( ISYEA(X)) 一月份1月份的时候,天数即为当日的日期,直接输出 Z 字段即可. 二月份这也是个容易踩坑的地方,大家都知道闰年要算2月29天,但有时太匆忙的时候,会糊里糊涂把闰年1月2月的日期也会莫名其妙的加上了”1天”,导致 WA. 因此要单独处理.也可以通过构造合理的if 语句和一月份的情况一起处理. 对每个月的日子进行预处理在程序开始之前可以定义一个数组储存每个月的天数, 计算日子时直接根据下标找到天数相加即可,可以减少代码量和运行时间. 预处理的时候要注意, c 语言的数组下标从0开始, 而月份是从1月开始,所以可以构造一个13个元素的数组并且让第一个元素值为0避免不必要的麻烦. 代码1234567891011121314151617181920212223242526#include &lt;cstdio&gt;#define ISYEAP(x) ((x%100!=0)&amp;&amp;(x%4==0))||(x%400==0)?1:0int daysOfMonth[13] = &#123;0,31,28,31,30,31,30,31,31,30,31,30,31&#125;;int main()&#123; int T; scanf(\"%d\",&amp;T); while(T--)&#123; int yy,mm,dd; int days=0; scanf(\"%d:%d:%d\",&amp;yy,&amp;mm,&amp;dd); if(mm==1)&#123; days = dd;//special situation &#125;else&#123; for(int i = 1;i&lt;mm;i++)&#123; days+=daysOfMonth[i]; &#125; days+=dd; if(ISYEAP(yy))&#123; if(mm&gt;2)&#123; days++; &#125; &#125; &#125; printf(\"%d\\n\",days); &#125; &#125;","tags":[{"name":"BOJ","slug":"BOJ","permalink":"https://antarx.com/tags/BOJ/"}]},{"title":"vscode配置 c++ 开发环境(一):智能提示","date":"2017-02-18T10:48:20.000Z","path":"2017/02/18/vscode/","text":"#前言vscode是微软推出的跨平台的编辑器, 开发者可以通过丰富的插件把它定制成最适合自己使用的开发环境. 对于我来说,它最吸引的地方之一就是可以为 Mac 还有 Linux 平台提供了与 Visual Studio 类似的智能提示功能. 正文 首先, 下载对应系统的 VScode. 如果是 Mac 系统,那么请安装 xcode 命令行工具,如果是 Linux 系统,请安装clang 编译器. 安装 cpptools 和 C++clang 插件.其中, cpptools 可以提供代码检错等功能,而 IntelliSense 功能,是通过 C++clang 插件实现的. 按command+,,打开用户配置文件setting.json, 将以下代码拷贝进去. 123456789&#123; \"clang.executable\": \"/usr/bin/clang++\", \"clang.completion.enable\": true, \"clang.completion.triggerChars\": [ \".\", \":\", \"&gt;\"], \"clang.cxxflags\": [\"-std=c++11\"]&#125; 要注意到配置文件是 json 格式,所以,如果之前已经有其它的设置,请按照 json 文件的语法格式将大括号里面的内容拷贝进去. 重启应用程序,即可享受 vscode 带来的智能提示功能了.效果图如下.","tags":[{"name":"M$","slug":"M","permalink":"https://antarx.com/tags/M/"}]},{"title":"使用国际版Azure搭建梯子教程","date":"2016-08-07T14:16:40.000Z","path":"2016/08/07/Azure/","text":"前言本文基于MSDN订阅版本对应的Azure云服务提供的虚拟机服务，搭建自己的影子袜子（自己翻译成英文，懂的人都懂）。 过程中参考了众多软狗的相关文章，对此表示感谢。 准备阶段这部分介绍如何激活自己的Azure服务并配置自己的虚拟机。 首先用微软账号登录Azure云服务，注意与国内的Azure区别开来。然后选择新建-&gt;虚拟机-&gt;Ubuntu Server 14.04 LTS，部署类型选择资源管理器。 这一步结束之后，如果你之前已经激活了Azure服务，则跳过本段继续阅读。否则继续。在未激活Azure订阅时，上一步点击创建之后它会自动导航到“添加您的Azure订阅”的页面,选择Visual Studio Enterprise选项，点击了解更多，进到关于这项订阅的介绍页面，找到相关按钮然后点击激活Azure订阅。 此后，回到第一步，再新建一个虚拟机，镜像类型同样选择Ubuntu Server 14.04 LTS，就会弹出创建虚拟机的选项卡，基本配置中填写虚拟机的名字，用户名，密码（它默认是SSH公钥登录，你需要切换到密码登录的选项卡中），然后新建一个资源组。主机位置建议选择东亚（香港机房）或美国西部（加利福尼亚机房），虽然在铁通12M宽带环境下发现这俩的速度都差不多QAQ。点击确定以继续。 接下来，选择虚拟机套餐方案，A1足矣。 接下来就是虚拟机的配置部分。 磁盘类型选择标准。公共IP地址中注意选择静态IP（它默认给的是动态）。其他选项保持默认，点击确定.（有人提到在网络安全组当中要建一个入站规则允许所有网络连接，我在部署时未发现这个规则的必要性，所以暂且不表）。 进入第四步，确定相关信息没问题之后点击确定，开始部署。部署完成后，在概要中记下公共IP地址。 虚拟机安装影子袜子本步骤需要ssh连接虚拟机。在*nix下用bash自带的ssh命令行即可。Windows平台下，可以使用cmder或者Xshell或者securCRT，putty之类的软件，我自己用的是Cygwin。 输入 ssh [username]@[your IP] 回车之后，输入Yes，然后输入登录密码，登录到虚拟服务器。 注：方括号部分为根据自己的配置需要自行更改的部分。方括号里面已经标明字段含义。 登录成功后，输入 sudo apt-get update 更新Ubuntu的软件列表，否则会导致后续软件安装失败。 然后，输入 sudo apt-get install python-pip 安装pip软件管理程序。 输入 sudo pip install shadowsocks 安装影子袜子。 输入 sudo ssserver -p [port number] -k [password] -m aes-256-cfb --user nobody -d start 启动影子袜子的服务器端。 #客户端操作 至此，Azure部署影子袜子的服务器端部分已经完毕。接下来就是在需要梯子的地方，安装相关的客户端软件（貌似在水果手机上功能会受到很多限制）. 安装相关软件后，在设置页面，服务器地址，密码，端口，协议类型分别对应你的虚拟机IP地址，[passport]字段，[port]字段，以及 aes-256-cfb。点击连接，即可。","tags":[{"name":"Azure","slug":"Azure","permalink":"https://antarx.com/tags/Azure/"}]},{"title":"通信的基础——大学这三年到底学了啥（主线课程篇）","date":"2016-03-08T14:33:57.000Z","path":"2016/03/08/Communication/","text":"前言每次跟其他专业的同学聊天的时候往往会被问到，“你们通信工程这个专业到底是学些啥的”，之前回答这个问题的时候一直都是支支吾吾，实在惭愧。到了这个学期，在几乎所有的专业基础课都学完的时候，总算可以稍稍整理一下这个问题了。 正文整理的第一件事，就是明确通信的概念。通信，就是说白了就是实现两点之间的信息传输。所以就字面上看，着眼点并不多，主要在于怎么表示信息和怎么传的问题。 本文的写作思路根据学校培养方案给出的每个学期开设课程的时间顺序来叙述。这两年多来学的课程庞杂，近乎无所不包，这里先整理出与通信最密切相关的课程来整理一下。 信号与系统这是通信工程专业首先接触的一门与“通信”这个概念密切相关的专业基础课。在这门课中，我们首先接触到了“信号”这个概念。 平时我们现实生活中听到的声音，看到的图像，每一个场景，都是信息。目前受到技术的各种限制，这样的信息是没办法直接传输的（这么传输可能需要无限的带宽，需要极强的抗干扰性能，等等）。目前基于电的形式运作的通信系统只能传输“电”，所以，引入了“电信号”的概念。 好了，有了电信号的概念，一切就方便了，因为“电”这个东西的很多特性是从19世纪就开始有所研究的。于是，就有了各种用函数表示的确定信号。 只有函数表示的信号是没有用的，就像在二进制代码中只知道1和0而不了解上下文一样。要怎么对这些信号进行处理呢？这个时候引入了三大变换：傅立叶变换，Laplace变换和Z变换。三个变换的本质都是将时域信号转换成变换域进行分析处理。这些变换一个主要目的就是将时域中繁琐的卷积操作转换为变换域相成操作，为分析运算带来巨大的方便。 关于变换域概念的理解，是理解系统的一个先决条件。我们都是生活在时域世界，简单来说就是一切按照时间顺序发展和变化的，这样的缺点就是在自己的角度没办法“高屋建瓴”的去分析问题，所以很多小说为了描述整个故事，都会有并行支线，描写同一个时段不同人物的活动，还利用各种叙述方式。变换域也是同样的道理，拿傅立叶变换（时域频域变换）来举例，可以理解成在同一时间点有不同频率的分量同时活动，傅立叶变换的目的，就是把这样一个个“人物”抽离出来进行分析处理。 说完变换域之后，终于可以到“系统”这个词了。我记得通信原理老师的一句经典名言“通信里面对信号所有的处理都可以理解成滤波器。”滤波器是一个具体的系统，也就是说，“所有系统的本质就是对信号进行各种处理”。这个处理，通常是频域的，对某个频域分量进行操作，比如“砍掉”一部分分量，“强化（增益）”某些分量，等等。 数字信号处理DSP，俗称“大山炮”，是通信主线课程的第二门专业基础课，顾名思义，在这门课上，讨论了“数字信号”的分析问题。 在信号与系统中，所有的信号都是“模拟”的，也就是时域连续，取值连续的信号。模拟信号的缺点就是无法用计算机进行处理。 数字信号，就是时域离散，而且取值离散的信号。数字信号可以通过模拟信号“取样，保持，量化”得到，在坐标系上表现出来就是一个个离散的点。 为了对数字信号的分析处理，引入了离散时间傅立叶变换和离散傅立叶变换的概念。DTFT是时域离散，变换域连续的，DFT是时域离散，变换域离散的。考虑到“系统”是对信号在变换域中进行处理，DFT更适合用计算机对信号进行分析处理。 随机信号分析这门课讨论的重点是随机信号。这样做的实际背景是在实际通信系统中，信号都是随机的，我们永远不能预测别人下一句话会说什么；另外，在传输过程中会收到噪声的干扰，噪声也是一种随机信号。然而，之前学过的课程都是针对确定信号，也就是有确定数学表达式的信号的。所以我们有必要讨论如何处理随机信号，这样才能讨论信号的传输过程。 随机信号没有确定的数学表达式，这并不意味着在这些信号面前无计可施。在这门课程中，一个极为重要的地方就是引入平稳随机过程的概念，基本思想就是虽然在某一时间点我们不能确定信号的表达式，但如果以时间差为自变量，就可以将某一类随机过程转变为确定的函数表达式进行讨论了。这类随机过程，就是平稳随机过程。 讨论平稳随机过程引入了相关函数的概念，从物理意义上来看，这是两个信号表达式的乘积，因此在变换域中不能像以前那样用幅度谱来讨论了，在此引入了功率谱。 把要讨论的主角介绍完毕之后，就是就此引出的几个相关概念，其中最为挥之不去的就是加性高斯白噪声和匹配滤波器这两个牛鬼蛇神了。 通信原理有了前面一系列的铺垫，各种概念定义表达式粉墨登场之后，终于迎来了这个专业基础课的最终“BOSS”，有多重要？之前的几乎所有课程都只讨论了“信”的来龙去脉，这门课着重在“信”的基础上研究“如何通”，讨论了所有情形之下的信息传输过程，把之前涉及的几乎所有相关知识串联起来，打通天地线，实现真正的通信大业。 因为学习这门课的时候，学院已经把前三章大部分内容抽离到随机信号分析课程了，所以很快就进入了对传输的讨论当中。首先是模拟信号的传输，在讨论中引入了调制和解调的概念，本质上就是实现信号在频域上的搬移，也为以后的讨论打下基调。 讨论完模拟信号的传输之后，就来到这整本书的重点，数字信号的传输。数字信号的传输包括了基带传输和频带传输。跟模拟信号不同的是，数字信号在基带和频带传输中都要进行调制的。因为理想的数字信号是冲激信号的线性组合，频带带宽无限带，根本没法直接传输，要所以进行脉冲编码调制，将其绝大部分能量集中在受限的带宽（成为“主瓣”）中，使传输成为可能。既然是传输，自然会受到噪声的影响，这里终于轮到“加性高斯白噪声”登场了。这种噪声特殊的地方就是在所有频段有相同的取值（就像Gundam里面GN粒子产生全频段电磁波干扰一样。。。）。这种噪声可以非常好的模拟信道传输过程中受到的“热噪声”等的特性，所以将会是整个讨论信号传输过程中的半个“主角”，在讨论信噪比时都默认收到的噪声是加性高斯白噪声。 另外就是匹配滤波器的概念。通过匹配滤波器，将接收信号的高斯噪声限值在传输带宽所覆盖的频域之内，使接收信噪比能够达到最大。 基带传输讨论完毕之后，就是数字信号的频带传输，具体的调制过程和模拟信号的调制过程有异曲同工之妙。真正特别的地方，就是为了提高信道利用效率而引入M进制调制的概念。 之后，就是在本学期学到通原2中学到的关于信息编码处理和信道编码等内容，由于刚开始学习，所以暂且不表。 END原本以为可以简要介绍，但不知不觉就来了废话一堆，能够把一个专业的核心问题说清楚真的不是什么轻而易举的事情，能够整理下来发现大学两年多也并非一无所获。等有时间了继续把其他光怪陆离的课程整理一下，也是对本科四年的一个交代罢了。 纰漏之处，还希望留言指正:-)","tags":[{"name":"Communication","slug":"Communication","permalink":"https://antarx.com/tags/Communication/"}]},{"title":"“软狗”的2015学习总结","date":"2015-12-26T06:09:48.000Z","path":"2015/12/26/2015/","text":"背景2015年转眼间来到了最后一周。大四考研的周末，在宿舍阅读了知乎上一些关于编程学习的文章，深觉自己也应该写下这一年来自己学习上碰到的坑和经验教训，也列举自己看过的一些书，供以后回顾时参考。 絮絮叨叨的一些一言蔽之，2015年是我自己在各方面都大胆探索尝试的一年。年初受知乎上萧大编程入门指南的启发,加上换上了新电脑的推动,开始了自己在编程学习上的系统探索,有人指路总比2014年“盲人摸象”般的窘迫境况好了不少。 编程语言随着学习的深入，我逐渐觉得，活跃在很多程序员社区上的所谓编程语言的争论，所谓”***才是最好的语言”的言辞，纯属奇谈怪论。计算机领域门派众多，不同领域会有不同的开发需要，不同的语言配合不同的开发工具在不同的领域自有自己的独到之处。如果还没接触某个领域，对该领域的编程语言，是没有任何质疑的权力的。入门学习编程时，选择一门看上去最讨喜的，又能体现计算机程序开发的精要的语言，学下去变是了。经历过小白阶段之后，更应该先定下自己感兴趣的领域（诸如人工智能，ML，DM，游戏开发，前端，移动开发，嵌入式等等等等），再根据领域的需要学习相应的语言。 我自己2015年在编程语言上学习的收获，在于以下两门语言的深入学习： C# 作为一名自称的“软狗”，不学习微软技术大系.NET Framework是不行的。（逃 C#作为整个庞大的.NET技术平台的顶梁柱，再配合上自家VS2015的有力驱动，还有MSDN堪称逆天般完善的知识库的支持，自然是入门微软技术学习的首选。在2015年1月就订好了C#的学习计划之后，中间磕磕碰碰，到年末，终于可以说自己基本上是入门了。期间用C#完成了必修课大作业（在此特别感谢上学期教我程序设计实践课程的吴铭老师，让我有摆脱枯燥落后而无聊的MFC的束缚，选择自己喜欢的编程语言完成课程作业的机会），让我对图形界面应用程序的开发有了初步的认知和体会。 C#带给我的收获，不仅仅是那些语言语法逻辑，背后更是一大类带自动内存管理的”面向对象“语言所共有的知识体系。学习了C#语言之后，对待诸如值类型和引用类型，“引用”的概念，“代码托管”，“虚拟机”，“字节码”，”运行时“等等看起来庞杂的概念，有了基本的认识。这些知识，不仅仅对C#学习有极大的帮助，在其他类似语言诸如Python，哪怕是C#的“死对头”Java语言的学习中，也是会起到不可或缺的重要作用的。考虑到这门语言的学习难度，将其作为”面向对象”语言体系的入门语言来学习，是一个非常明智的选择。 Python 从去年年底就嚷嚷着想学的语言，在今年年底，终于可以说自己有所进步了。 对于C++的学习者来说，Python以四空格划分代码区块的“诡异”语法，是初学者在学习上极大的雷区，一不小心就会带来诸多莫名其妙的报错，连”Hello World“都写不出来。在微软俱乐部里面，”学习Python语言需要游标卡尺“这个老梗，也时常成为大家的笑谈。然而，一旦找到一个好看耐“艹”（比如代码高亮，智能提示，自动缩进，PEP 8 代码规范提示…)的IDE辅助学习之后,无论从学习过程还是成就感上，都会有质的飞跃。经过种种的摸索踩坑，庆幸自己终于找到了这个工具——JetBrains-Pycharm Python是一门很活，很活的语言，无论从语法形式上，还是运行调试上，都是如此。在学习Python过程中感触最深的一点，就是很多函数的用法，我都是在Python交互环境中“试”出来的。Python交互环境是我最喜欢Python的一个地方，在这里你可以像Linux Shell那样，输入一条Python指令，就可以获得输出，通过输出可以学习到很多函数的用法，查看某个变量的具体类型等等工作，为后续的编程开发，省了不少力。 Python最具魔力的地方，是那一堆堆用不完的第三方库。这堆库让Python语言在时下最火的领域——人工智能，机器学习，数据分析，数据挖掘，“你老婆”等有一展拳脚的机会。 领域方向2015年我还是挺迷惘的，哪门编程语言都想学，，哪个方向都想尝试，但又怕学而无用，或者碰到了不适合自己的深坑，误了时光。总结下来，自己这一年好像在很多领域都有所接触，但都没深究，近乎一事无成罢了。开荒的领域，在这里还是要提一下的，希望在来年能从中找到一两个自己喜欢的领域深挖下去吧。 UWP应用开发 UWP，微软在Win10平台上的通用应用，基于C#写后台逻辑，XAML写前台界面。XAML简单易懂的语法可以为初学者带来极大的满足感，然而真正想开发出精美绝伦的通用应用，还是需要深入学习和领悟的。WPF这个庞大、特性丰富的界面框架和C#丰富的高级语言特性的学习，是在这方面成为高手的必经之路。 Python开发Web网页应用 在这里特指Flask和Django框架相关的开发。 Android应用的开发 是的没错，一个软狗也有过考虑开发Android应用的时候，主要还是“揾食艰难”，想找一些来钱快的领域学学，找点外快什么的。然而到最后不了了之。 计算机视觉 缘起大二小学期时候的创新实验。当初用OpenCV库搞了个所谓之”人脸识别”的项目，开发过程也不可谓不艰辛，在配置开发环境的时候就走了不少“弯路”，也要摸索很多之前毫无概念的方法。回想起来那段时间其实是自己今年收获最丰富的其中一段时间了。迫使自己重拾了荒废半年的C++，重温了很多基本概念，学习了计算机图像处理的一下核心思想方法。另外，人脸识别也把我带进了模式识别、机器学习的坑。 机器学习 由“人脸识别”带来的坑，然而学的很皮毛，暂且不表。 魔法书 总的来说，这年开的坑确实有点多，但又学的很不深入。到年末才渐渐意识到自己之前的心态之浮躁，不禁为之惭愧不已。到年末想投个实习简历，却发现自己近乎空白的项目经历，甚为汗颜orz。 致那个一直想跳未跳的坑——Gawain Open Sources Project（GOSP）从高三毕业开始就有想做一个属于自己的Android ROM给自己的手机用。然而前两年收到电脑硬件和移动设备的限制（大一是魅族MX2这个万年锁BL的混蛋，大二时信仰挚爱Lumia930）毫无进展。这年年末在电脑硬件和移动设备都能满足的时候，却在漫长坑多的下载源码和编译时间上打了个退堂鼓。或许真的能发布的时候，已经“猴年马月”之后了。 Achieve？今年如果真的有什么建设的话，就是这个博客了。在这方面幸好没有太大的犹豫，Hexo+ GayHub的部署方式，50美刀五年买到了最喜欢的域名，部署过程还顺路入门了Gayhub和Markdown，之后开发过程上也开始积累写下自己的遇到的问题和解决方法。这里感谢微软MSP项目给予我的动力。微软大法好哦耶！ 一些教训 在学习过程中永远不应该害怕走弯路。编程学习本身就是不断在碰坑中修正的过程。事实上，因为害怕走弯路而盲目模仿前人的所谓”经验”,”捷径”的过程，才最弯的弯路。 切忌浮躁，切忌浮躁，切忌浮躁。重要的事情说三遍！ 实践，永远是检验真理的唯一标准。 开发工具这个必须提的。工欲善其事，必先利其器。 一个完整好用的工具链可以省去很多功夫。之前经历过一系列的摸索，从写C++时候的Dev C++，到后来学Python时碰过Vim，敲过Emacs，尝试Eclipse+DevPy，倒腾VS2015+Pytools，还折腾过Sublime，Atom，VSCode编辑器之流。现在总算得到一系列比较完善的开发工具体系。 操作系统上，一直对MacOS的华丽界面和好用到爆炸的终端心向往之，无奈受阻于高昂的价格。尝试过Ubuntu，却无论如何都未能称心如意。到最后躁动的心皈依Windows 10，用Cygwin + Cmder 打造了界面和灵活性不输水果的终端。也算满足了日常使用的基本需要。 现在将自己目前觉得最顺眼的工具链列举记录，供以后重装系统换电脑之后快速配置参考。 操作系统：Windows 10 TH2 Build 10586 终端：Cygwin+Cmder C#开发：宇宙第一IDE VS2015 Community Python开发IDE：Pycharm。强推Monokai配色+Consolas字体 Python交互窗口：使用Cygwin下基于GCC的独立Python环境并独立安装pip。 编辑器SublimeText3。 博客写作Atom + MarkdownPad 今年看过的书絮絮叨叨说了这么多，到最后应该是整理一下今年看过的几本让我“醍醐灌顶”的著作。 《编码的奥秘——隐匿在计算机背后的硬件语言》 上学期学习数字电路与逻辑设计课程，一开始被一大堆的逻辑门电路弄的一头雾水，后来找到了这本“神作”，从最开始的电筒闪亮传输信息的情节开始，循序渐进，以汇编语言收尾，讲述了计算机硬件的编码逻辑的来龙去脉，扫清了学习的迷雾和烦恼。 《程序是怎样跑起来的》 日本人写的一本小书，补充了很多计算机的基础知识，讲解了诸如Windows分页文件等系统级别的“冷”知识，也涉及了CPU，内存等“硬”功夫。 《数学之美》 吴军老师结合自己在项目研发上的实际经验撰写的一本讲述了目前最火的几个领域上用到的数学知识原理。言简意赅，毫不沉闷。 最后的最后写在最后的也不算是对未来的展望了。2016年希望不要摔在同样的坑上。还有就是能成为正式MSP继续传教233333333","tags":[{"name":"Life","slug":"Life","permalink":"https://antarx.com/tags/Life/"},{"name":"编程","slug":"编程","permalink":"https://antarx.com/tags/编程/"}]},{"title":"Cygwin安装独立的pip环境","date":"2015-12-25T10:37:31.000Z","path":"2015/12/25/cygpy/","text":"前言在Windows下配置python的虚拟环境时常常会遇到各种各样的问题。所幸Windows平台下有Cygwin这个虚拟Linux的环境。在cygwin下安装了独立的Python环境后，再安装pip，即可通过pip install virtualenv命令安装Python虚拟环境，之后通过虚拟环境安装Flask，Django等网络开发环境就可以一气呵成了。 安装步骤 首先，安装Cygwin并在软件包选择页面选择安装Python软件包。 前往Get Pip下载get-pip.py文件到cygwin的home目录. 在Cygwin命令行环境下进行pip的安装。执行python get-pip.py命令即可。 安装完毕之后，关闭Cygwin交互环境再打开，就可以进行虚拟环境的安装了。pip安装成功的标志注意: 直接输入pip命令没有提示command not found并不能说明pip被成功安装在cygwin的python运行环境下。如果Windows下也存在Python和pip的话，在Cygwin命令行输入pip会直接调用Windows平台下的pip命令。 可行的判断方法如下：（以下命令均在Cygwin交互环境下输入） 命令行输入which pip返回的结果为’/usr/bin/pip’ 命令行输入pip -V返回的结果为pip 1.5.6 from /usr/lib/python2.7/site-packages (python 2.7) 至此，Cygwin下独立的pip环境已经配置完毕，之后就可以安装Linux下配置Flask，Pyramid或者Django环境的办法愉快的玩耍了。","tags":[{"name":"Python","slug":"Python","permalink":"https://antarx.com/tags/Python/"}]},{"title":"numpy学习笔记（1）--ndarray类型常用属性","date":"2015-12-23T14:39:36.000Z","path":"2015/12/23/numpy/","text":"前言NumPy是python中用于机器学习和科学计算的常用库。opencv for python中cv2.imread(&#39;image.jpg&#39;)命令读取图像返回的数据类型也是ndarray。今天将ndarray的一些常用属性记录下来，以便以后学习时进行参考。 ndarray常用属性 size: 表示array中拥有的总元素数量。 shape: 元组类型。该属性描述了ndarray的“形状”信息。shape[0]为行信息，shape[1]为列信息。 example strides: 元组数据类型该属性返回每一个维度上元素的数量。 ndim: 表示这个ndarray的维度。也可以理解为shape属性返回的元组的数量。 T:表示ndarray矩阵的转置。 今天使用opencv做简单的图像处理时接触到的ndarray的相关属性主要就是以上5个。以后再学习过程中遇到的更多有用的属性时会及时做补充。","tags":[]},{"title":"使用动态规划求解字符串编辑距离问题(C#实现）","date":"2015-12-07T14:41:52.000Z","path":"2015/12/07/dp/","text":"前言上次提到会在后续通过实际例子更加深入的谈谈对解释四种四种基本算法设计模式的理解。今天说到的,是利用动态规划思想求解两个字符串的编辑距离。 正文问题背景 我们将两个字符串的相似度定义为：将一个字符串转换为另一个字符串时需要付出的代价。转换方法包括插入，删除和替换三种编辑方式。使用对字符串的编辑次数定义为转换的代价。最小的字符串编辑次数就是字符串的编辑距离。 –《算法的乐趣》 问题分析要使用动态规划思想解决这个问题，首先我们需要对问题进行阶段划分，确定边界条件，定义无后效性的几个子状态并且确定状态之间的转移关系，才能在每个子状态中寻找最优解最后得到原问题的解。 寻找子问题：在本问题中，假设原字符串为source，长度为m，目的字符串为target，长度为n。则问题可以描述为求解source[1..m]转换为target[1..n]所需要的最小编辑次数。注意到，当source的前i个字符和target的前j个字符之间的编辑距离确定之后，不会在后续求解中发生改变，因此此问题的子问题即可定义为求解source的前i个字符和target的前j个字符之间的编辑距离。 边界条件的确定：当source字符串长度为0时，编辑长度为target的字符串长度n（插入n个字符串）。当target的字符串长度为0时，编辑长度为source的字符串长度（删去m个字符串）。 关于“备忘录”：动态规划问题的一个特点是使用类似”备忘录“的”表“记录每个状态的相关信息。本问题中用d[i,j]定义为source的前i个字符和target的前j个字符之间的编辑距离，作为每个状态的标志。 状态之间的转换：以d[i-1,j]+1为删除字符时转移的状态,d[i,j-1]+1为插入字符时转移额状态，d[i-1,j-1]+1为替换字符串时转移的状态。 子问题的最优解：字符串之间的转换方式并不是唯一的，通过操作若干次添加字符，删除字符，替换字符操作都可以实现字符串转换，每次转换状态时，将三种操作方式中的距离的最小值作为d[i,j]，可以保证每个子问题的解都是最优的，从而保证整个问题的解是最优解。 具体代码使用C#语言实现。 using System; namespace EditDistance { class Program { public static int MAX_STR_LEN = 100;//initialize the max length of string static void Main(string[] args) { //test code Console.WriteLine(&quot;Please input Source string:&quot;); String src = Console.ReadLine(); Console.WriteLine(&quot;Please input Target string:&quot;); String dist = Console.ReadLine(); Console.WriteLine(EditDistance(src, dist)); } private static int EditDistance(string src, string dist) { int i, j; int[,] d = new int[MAX_STR_LEN,MAX_STR_LEN]; //initialize the margin condition for (i = 0; i &lt;= src.Length; i++) d[i, 0] = i; for (j = 0; j &lt;= dist.Length; j++) d[0, j] = j; for(i = 1;i&lt;=src.Length;i++) { for(j=1;j&lt;=dist.Length;j++) { if(src[i-1]==dist[j-1]) { d[i, j] = d[i - 1, j - 1]; } else { int edIns = d[i, j - 1] + 1; int edDel = d[i - 1, j] + 1; int edRep = d[i - 1, j - 1] + 1; d[i,j]=Math.Min(Math.Min(edIns,edDel),edRep); } } } return d[src.Length, dist.Length]; } } } 运行结果： 后记求解字符串的编辑距离问题应该是动态规划的最典型案例，体现了动态规划问题的基本特点。适合用动态规划解决的问题，一般都是可以划分多多个子状态的，每个子状态之间存在状态转移关系，每个状态的解一旦确定，就会用类似“备忘录”的表储存起来。在后续求解时，将会直接使用该状态的解，而且，不会再回溯子状态的时候改变该状态的解。 另外，边界条件的确定是问题求解时的一个重要步骤。如果忽略了边界条件，或者在求解时没有正确初始化边界条件（比如在本题中对d[i,0]和d[0,j]需要初始化为i和j），将得不到正确的解。","tags":[{"name":"算法","slug":"算法","permalink":"https://antarx.com/tags/算法/"}]},{"title":"用diskpart打造Win 10安装U盘","date":"2015-11-27T09:54:26.000Z","path":"2015/11/27/Win-10/","text":"前言本文主要介绍通过diskpart命令行的方式制作Windows10引导U盘，制作完毕后，该U盘可以用于安装（包括全新安装和升级安装）Windows10操作系统，也可以在系统无法启动的时候使用该U盘进行修复操作。 正文需要的材料 Windows 10 Build 10586 安装镜像。（推荐从北邮人BT或者IT之家搜索相关的镜像。另外32位或者64位的系统镜像均适用本教程。） 容量大于4GB的U盘一个。建议适用USB3.0的U盘以获得较快的安装速度。请提前备份好用户数据。 以管理员账号登录当前系统。制作步骤 启动当前系统进入桌面环境之后，将U盘插入电脑。在开始菜单中搜索cmd或命令提示符，并右键，选择以管理员身份运行。 在命令提示符窗口中输入diskpart，按回车。 弹出的UAC窗口中选择允许，进入diskpart程序。 在Diskpart程序中，输入list disk查看当前的磁盘列表。 根据容量查看自己的U盘对应的磁盘号。这里假定第一个磁盘为你的U盘。输入select disk 1选中你的U盘。 输入clean，清除U盘内容。 输入create part primary，用于在U盘中创建主分区。大小为U盘的容量大小。 输入format，格式化刚刚创建好的磁盘分区。磁盘格式默认是FAT32。 输入active，激活主分区。这步非常重要，如果忘记输入这条命令，制作的U盘将无法激活。 输入exit，退出程序。 用文件管理器打开下载好的Win10安装ISO镜像文件，将里面的内容全部复制到U盘中。 至此，一个可以在目前绝大部分新的笔记本电脑上启动的Windows10启动U盘已经制作完毕。在BIOS中选择用U盘启动即可进入亲切的Windows10安装界面了。后记虽然目前有很多工具可以制作启动U盘，但本文介绍的方式具有独特的优势，在你想更换别的版本的系统比如制作ubuntu启动盘（逃 的时候，只需要把U盘里面的内容全选删除，并且把ubuntu安装镜像的内容完整复制过去就可以了，不用借助任何其他工具再次制作。","tags":[{"name":"Win10","slug":"Win10","permalink":"https://antarx.com/tags/Win10/"}]},{"title":"四种基本的算法设计模式","date":"2015-11-16T15:15:01.000Z","path":"2015/11/16/四种基本的算法设计模式/","text":"前言最近在阅读一本有趣的算法书，书中作者列举了四种基本的算法设计模式，我总结摘录得到本文。今天先给出文字总结。随着阅读的深入，以后会给出四种设计模式的典型案例。 正文贪婪法- 核心思想： 将原问题划分为多个子情况考虑，在每一个子情况中寻求其局部最优解，然后将局部最优解按照一定的方式（这种方式通常与子问题的划分方式有关）堆叠得到原问题的解。 - 特点： 1. 这种方法不用考虑子问题之间的相互影响（这一点区别于动态规划方法），通俗的说，就是不用“瞻前顾后”。 2. 在每个子问题中都应用了局部最优原则，寻求该子问题的最优解。 - 一般思路： 定义最优解模型-&gt;划分子问题-&gt;定义子问题的最优解结构-&gt;确定局部最优解，并堆叠出全局最优解。 分治法- 核心思想： 将大问题划分为一系列子规模较小的相同问题（解结构相同，子问题之间相互独立），寻找子问题的解之后将结果合并得到原问题的解。 - 特点： 子问题的划分不一定只有一次，而且往往不止一次，划分的目的是使每一个子问题相互独立而且是容易求解和能够最后组合得到原问题的解。正因为这个特点，分治法与递归思想总是密不可分的。 - 难点： 子问题的划分方式和最后结果的合并。如果用递归去解决分治法问题时，难点就是寻找递归关系式和确定递归终止条件。 - 举例：N点离散傅里叶变换的快速计算 动态规划- 核心思想： 要解一个给定问题，我们需要解其不同部分，再合并子问题的解以得到原问题的解。 - 特点： 1. 动态规划在查找有很多重叠子问题的情况的最优解时有效。它将问题重新组合成子问题。为了避免多次解决这些子问题，它们的结果都逐渐被计算并被保存，从简单的问题直到整个问题都被解决。因此，动态规划保存递归时的结果，因而不会在解决同样的问题时花费时间。 2. 适用于无后效性的问题。子问题的解一旦确定之后就不会改变，不受之后包含它的更大的问题的求解。 3. 适用于子问题相互重叠的情况。动态规划会创建一张“表”记录每个子问题的计算结果，当再次需要计算此问题时就可以通过查表快速得到结果，简化计算。 - 一般思路： 定义最有子问题-&gt;定义状态-&gt;定义决策和状态转换方程式-&gt;确定边界条件。 - 举例： 斐波那契数列的计算（在计算过程中保存每一步的f(n)）、0-1背包问题 穷举法- 核心思想： 在解空间之内穷举并测试每个可能的结果。 - 穷举策略： 1. 盲目搜索算法。 2. 启发式搜索（开始搜索时加入了一定的附加条件） 3. 剪枝策略：跳过一些明显不会是最优解的分支的搜索。 - 应用举例：很多NP问题的求解最后都是用了枚举法。 后记四种基本的设计模式并不是相互对立的。有时一个问题可以用一种或多种的设计模式去解决，而且，附加的条件不同时，应用的设计方法也不同。一个典型例子就是背包问题（多件体积不同，价值不同的物品放入体积一定的背包，求解价值最大的方案），既可以通过穷举所有情况解决，也可以引入价值密度的概念，用贪婪法设计解决(每次都放入价值密度最高的物品），还可以用动态规划解决（还没透彻理解QAQ）。上面的内容很多都是自己整理书中内容加上自己的一点想法写成的，感觉还是太抽象了，也难免有各种疏漏和错误，欢迎大家留意指正，多多交流。以后补充实际问题结合代码更加深入的分析每一个方法的奥妙。","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://antarx.com/tags/读书笔记/"},{"name":"算法","slug":"算法","permalink":"https://antarx.com/tags/算法/"}]},{"title":".NET学习笔记（一）","date":"2015-10-21T08:28:40.000Z","path":"2015/10/21/NET学习笔记（一）/","text":"基础类型相关 .NET中所有内建类型都继承自System.Object,若同时继承自System.ValueType类则为值类型，否则为引用类型。 值类型和引用类型的区别如下： 赋值时，值类型变量会直接获得真实数据的一个副本，而引用类型只会将对象的引用赋值给变量，会造成多个对象指向同一个内存区块（对象实例）的情况。 内存分配时，引用类型对象会在堆上分配内存，而值类型变量会在堆栈上分配内存，运行效率比堆高很多。 装箱拆箱的概念 装箱，指的是CLR需要做额外工作把堆栈上的值类型移动到堆上。 拆箱，指的是把堆中的对象复制到堆栈中，返回其值。 应该注意的是，装箱和拆箱行为，都对应了堆栈上的一系列操作，会造成较大的性能代价。因此减少程装箱拆箱操作，是程序性能优化的一个重点。 避免装箱拆箱操作的思路，在于从两方面避免发生装箱拆箱行为的场合： 值类型的格式化输出。 System.Object类型的容器。对于这种情况，可以使用泛型技术来避免使用System.Object类型的容器。 原文链接.NET基础拾遗(1)类型语法基础和内存管理基础","tags":[{"name":"C#","slug":"C","permalink":"https://antarx.com/tags/C/"},{"name":".NET","slug":"NET","permalink":"https://antarx.com/tags/NET/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://antarx.com/tags/读书笔记/"}]},{"title":"Hello World","date":"2015-09-24T08:29:46.000Z","path":"2015/09/24/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://antarx.com/tags/Hexo/"}]}]