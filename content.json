[{"title":"redis的杂七杂八","date":"2018-02-25T15:09:10.000Z","path":"2018/02/25/redis/","text":"Redis 是目前应用比较广泛的数据库。最近的实验室项目中用到它作为实时数据库。把这个过程中学到的一些东西记录下来，权且作为小白的入门参考吧 基本概念Redis 是一种基于内存的数据库，这意味着在使用过程中的所有数据都是存放在内存当中的，省去硬盘读写的过程使得对数据库的操作会非常的快，很适合并发。 Redis 的基本储存单位是key-value，比 mongodb 中的“文档”的概念有着更细的粒度。key部分一般是字符串类型，value部分可以有以下五种类型： string。字符串类型 hash。一系列k-v的集合，适合用来储存对象实例或者 JSON list。简单的字符串列表，也就是说可以通过 list 数据结构在一个key对应的value字段储存多个字符串。这多个字符串是有序排列的。“序”指的是插入的顺序（可以选从头部或者尾部插入） set。String 类型的无序集合。满足唯一性。 有序集合。set 的有序版本 命令行操作服务器（server 端）安装 Redis 之后，在命令行窗口输入redis-server即可在本机运行一个radis 的 server 端，默认的端口是6379. DockerRedis 服务器端和其他主流数据库一样可以很方便的放到 Docker 容器里运行。 下载 Redis 镜像 1sudo docker pull redis 基于 redis 镜像运行容器 1sudo docker run --name redis-server -p 6379:6379 -d redis 镜像内部已经设置了运行redis-server和监听6379端口，所以不需要额外的设置项，只需要在运行容器时将端口暴露出来（与宿主机的6379端口或者自己指定的端口绑定）就可以了 client 端shell 界面下输入redis-cli -h 127.0.0.1 -p 6379启动 redis-client。其中，-h指定服务器的地址，-p指定服务器的端口。 基本操作命令注意到，命令的操作字段是不区分大小写的。 value 为 String 类型时。set key value用于为 key 设置值为 value。 get key用于获取键为 key 的值。 value 为 list类型时。lpush key value1 [value2]…用于将一个或者多个值。 LPOP key可以移出并获取列表的第一个元素。这两个操作换成rpush和rpop可以向列表尾部插入元素。LLEN key可以获取 key 对应的列表的长度。LRANGE key start stop用于获取特定key 的指定范围的元素，特别地，LRANGE key 0 -1可以用来遍历列表。 更加详细的命令教程可以参考Redis教程-菜鸟教程 编程语言支持Java在 Java 中主要通过 jedis 数据库驱动实现对 Redis 数据库的操作。 安装依赖 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; JedisPool和 JedisClientjedis 使用 JedisPool 作为一个Redis连接池，用于解决对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题。 连接池初始化代码如下 1234567891011121314151617public static JedisPool getPool(String host, int port)&#123; if(pool == null)&#123; JedisPoolConfig config = new JedisPoolConfig(); //设置最大连接数 config.setMaxTotal(100); config.setMaxIdle(5); if(host == null)&#123; pool = new JedisPool(config, \"127.0.0.1\", port); &#125;else&#123; pool = new JedisPool(config, host, port); &#125; &#125; return pool; &#125; 要使用Client 时，使用pool.getResource()方法获取单个JedisClient实例，在此基础上对 Redis 数据库进行操作。 GolangGo 语言中用来连接 Redis 数据库的库五花八门，主要分两个派系，将对 Redis 的操作封装成方法的，开发者通过调用库的方法实现对 Redis 数据库的操作；另一派是直接将 Redis 命令作为字符串提供给库来实现各种操作的。 这里以&quot;github.com/garyburd/redigo/redis&quot;为例。 安装依赖 1go get github.com/garyburd/redigo/redis 获取 redis pool实例 123456789101112redis.Pool&#123; MaxIdle:10, MaxActive:15, IdleTimeout:240*time.Second, Dial: func() (redis.Conn, error) &#123; c, err := redis.Dial(\"tcp\", redisURL) if err != nil&#123; return nil, err &#125; return c, err &#125;, &#125; 从 pool 中获取 Client 实例 1rClient := redisPool.Get() 执行操作 1rClient.Do(\"LPUSH\",\"key\", \"value\") Do 方法用于执行对 Redis 数据库的操作命令。方法的第一个参数字符串命令（就是在 shell 交互时的各种命令。","tags":[{"name":"Java","slug":"Java","permalink":"http://140.143.193.168/tags/Java/"},{"name":"Redis","slug":"Redis","permalink":"http://140.143.193.168/tags/Redis/"},{"name":"golang","slug":"golang","permalink":"http://140.143.193.168/tags/golang/"}]},{"title":"go-websocket","date":"2018-01-23T11:06:17.000Z","path":"2018/01/23/go-websocket/","text":"","tags":[]},{"title":"Keras 手写数字识别","date":"2018-01-23T10:42:42.000Z","path":"2018/01/23/aml/","text":"之前机器学习课程布置的大作业是用尽可能多的模型来探索经典的手写数字识别问题。这里分享一下Keras的基本使用 Keras简介Keras 是由纯 Python 写成的，调用 TensorFlow 或者 Theano（最新版本还支持 CNTK）进行运算的类库。相比于 TensorFlow，Keras 使用起来更加简洁方便，便于调参，非常适合初学者进行机器学习探索。 安装在安装好 anaconda 的前提下，输入conda install keras即可进行安装。 注意到，安装过程会自动判断机器是否已经安装好了TensorFlow，如果没有的话会自动进行安装。所以，如果想安装 TensorFlow GPU 版本加速计算过程的话，要先手动安装好 TensorFlow 的 GPU 版本，然后再安装 Keras。 实现单层感知机核心代码如下 12345678910111213141516171819202122232425batch_size = 128classes = 10epoch = 10img_size = 28 * 28print('Loading Data...')(X_train, y_train),(X_test,y_test) = mnist.load_data()X_train = X_train.reshape(y_train.shape[0], img_size).astype('float32') / 255X_test = X_test.reshape(y_test.shape[0], img_size).astype('float32') / 255#encode labelsY_train = np_utils.to_categorical(y_train,classes)Y_test = np_utils.to_categorical(y_test,classes)model = Sequential([Dense(10, input_shape=(img_size,), activation='softmax'),])model.compile(optimizer='rmsprop', loss='mean_absolute_error', metrics=['accuracy'])print(\"Training...\")model.fit(X_train, Y_train,batch_size=batch_size, epochs=epoch, verbose=1, validation_data=(X_test,Y_test))score = model.evaluate(X_test,Y_test,verbose=0)print('accuracy: &#123;&#125;'.format(score[1])) 前面很大一部分都是进行数据加载和处理，与模型有关的代码只有三行 model = Sequential([Dense(10, input_shape=(img_size,), activation=&#39;softmax&#39;),])这一行是模型基本形态的定义，以图像的 size 作为输入，激活函数采用 softmax。 model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;mean_absolute_error&#39;, metrics=[&#39;accuracy&#39;])这一行则是对模型的微观参数进行客制化。optimizer指定的是优化策略，rmsprop是一种改进的随机梯度下降策略。loss指的是损失函数。metrics是评估方法，这里用准确率进行评估。 model.fit(X_train, Y_train,batch_size=batch_size, epochs=epoch, verbose=1, validation_data=(X_test,Y_test))这一句是训练过程，指定训练数据，训练轮次（迭代次数），是否输出训练过程，验证数据。 多层全连接网络核心代码部分 12345678model = Sequential([Dense(512,input_shape=(img_size,)), Activation('relu'), Dropout(0.2), Dense(512, input_shape=(512,)), Activation('relu'), Dropout(0.2), Dense(10,input_shape=(512,),activation='softmax') ]) 每一个 Dense 都是一个神经元训练层。训练层输出接 ReLU 激活函数层。如此类推。最后一层接单层感知机获取结果。值得注意的是两个 Dropout 层，用于应付过拟合问题，经过 Dropout 层会随机丢弃数据集中一定比率的激活值，同时将剩余的神经元的输出进行放大。 卷积神经网络1234567891011model = Sequential()model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))model.add(Conv2D(64, (3, 3), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Dropout(0.25))model.add(Flatten())model.add(Dense(128, activation='relu'))model.add(Dropout(0.5))model.add(Dense(num_classes, activation='softmax')) 卷积神经网络中主角变成了 Conv2D （卷积层）和 Pooling 层（池化）。","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://140.143.193.168/tags/机器学习/"}]},{"title":"网研机试101","date":"2018-01-08T10:13:08.000Z","path":"2018/01/08/buptoj/","text":"2018考研的初试已经结束了，平时看考研群里已经有很多人在讨论在焦虑机试应该怎么复习，作为过来人在这里就随便说说自己的一些经验吧。 实现说明一下，这篇文章基本就是个扫盲，不能保证你看完文章就能从 A0变 AK，但帮助你脱离新手区，扫除对机试的恐惧，保个底让机试不会成为复试阶段的软肋还是可以的。 简单介绍首先得先了解机试的基本情况。按照去年的考试风格，是两个小时四道题的 OJ（Online Judge）形式，也就是在线提交，在线判题返回程序在测试结果集的运行结果。AC（accept）代表正确解题，WA（Wrong Answer）表示错误答案，另外还有超时、超出内存空间等等结果。所有考试前准备的目的，就是为了更多的 AC，或者保底情况，避免 A0。 编程语言该用什么语言北邮 OJ 平台可以用的编程语言有三种，C（gcc4.8），C++（g++ 4.8）和 Java（注意：没有 Python，没有 JavaScript）。另外，C++是不支持 c++11的，Java 只支持到 Java6。 在这个天煞的背景下，考虑到程序时间限制（1ms）和开发速度（避免无谓的造轮子），用 C + STL 是最理想的选择。 展开来说，就是用 C 的那一套输入输出（scanf 和 printf），C 与 C++通用的循环控制、选择结构、数组等，在加上 C++独特的“宝具”——STL 标准库，来进行解题。提交的时候编译器选 g++即可。 STL 标准库内容非常多，只需要了解 Map，stack，list，queue就够了。 IDE？不存在的两个小时做四道题对大脑转数的要求还是挺高的，更何况在那种紧张的气氛和不熟悉的开发环境之下。要保证解题能够快狠准，就需要从现在开始培养一定的针对考试的编程习惯，包括 编辑器和编译器、调试器的使用等等。 首先，抛弃手上所有的 IDE，包括但不限于 Visual Studio和 Clion，DevC++，或者只在疑难杂症的时候拿它们当单步调试的工具（但也不能依赖）。考试环境只提供了（没有智能提示的）devcpp，（长得贼丑的）CFree两种最“原始”的开发工具，也就拿来当代码高亮，保证括号补全没有基本的语法问题差不多了，很多现代 IDE、开发工具可以做的事它们一概做不了。 要适应这种艰苦恶劣的考试环境，就得从准备机试的时候开始，把开发工具换成 VScode and g++。VScode 是微软提供的跨平台编辑器，有着漂亮的界面和基本的语法高亮功能，在配置各种插件之前基本可以拿来模拟考场的开发环境，用来编辑代码，而且还能保证练习的时候是比较舒服的。 编译过程全部转到命令行用 g++完成。 调试两个最基本额调试手段：打印大法和单步调试大法。个人推荐第一种。单步调试大法需要掌握 gdb这个 g++配套的调试工具，相对来说比较费时间（无论上手还是在考场上使用），而且比较容易出一些奇奇怪怪的问题。想成为 AK 达人的话，倒是必须掌握的。 打印大法就是在关键步骤将关键变量输出的方法，简单易行，只要注意提交之前注释掉代码就OK。 参考教材注意到，机试是可以带任何纸质打印资料的，一本简介明了的语言参考指南显得非常重要。 抛弃所有国内教科书，包括但不限于谭浩强，除非你想拿成绩开玩笑在考试的时候验证一下int a++++会不会报错。 在这里，只推荐K&amp;R The C Programming Language小薄本。将 ANSI C 的所有内容都讲得很透彻而简洁，里面的习题也可以作为入门练手。 能力层级这一部分提供平时训练刷题的参考方向。列举我在去年准备的时候看过的一些题型，具体知识和代码在王道机试指南和算法竞赛入门经典介绍的比较详尽。 基本输入输出OJ 的输入输出风格可是能玩死不少人的，怎么保证循环接收输入，接收特定符号能退出，每一轮输入怎么界定，怎么输出小数点后三位浮点数，输出的时候删掉无谓信息（比如句子最后的致命空格），等等等等，都是值得关注的内容，也是首先要练习的。所幸 scanf 和 printf 函数在 KR 里面已经介绍得非常详尽，对照着看和练习就行。 数字和数组处理数字部分有点像小学数学的找规律填数，也会夹带私货弄些奇形怪状的浮点数处理，数组处理方面典型例子就是找最大最小数，找次小数，奇偶数分离这些。一般都在签到题出现。 日期问题闰年问题，星期几问题等等。 字符串处理翻转字符串，回文字符串判断，甚至字符串匹配、简易正则表达式识别、字符串搜索都是有可能出现的，活用 std::string 和 char 数组的下标嗯。 模板题图论的 D 算法 F 算法，深度优先搜索，矩阵乘法等等。这种基本都是最终 boss 级别，因为很多 ACM 资料都会有典型的算法题目，代码可以直接套用，改改关键变量就可以，所以称为模板题。 特别提名：模拟题模拟题，可不是模拟卷子，而是一类型模拟计算机内部操作比如进程调度，死锁识别等的题目，印象最深刻就是去年最后一题算进程完成时间的。 思维方法这里介绍一些玄学的东西，也是机试对以后的开发生涯最有帮助的东西 边界值控制和处理刚开始接触 OJ 的时候很容易会遇到本地编译没问题，提供的测试数据也能获得预期结果可是提交之后就是 WA 这种百思不得其解的问题，根源便在于边界值考虑不周全，比如整数0，范围的边界，字符串中的空串等等，解决之道便是通过大量的练习，对每个算法题首先花上几秒考虑可能的边界情况和特殊情况，久而久之形成严密的思维。 时间性能1ms 的时间限制，看起来非常的充分，那只是还没遇到大规模输入。在那种几万甚至十万级别的数据（OJ 上真的会有），就算是$O(n^3)$的算法，翻车也是随时随地的。 应对这个问题，得对计算机内部执行过程有最基本的认识，更好一点的得对算法的时间复杂度有认识，优化起来才不会像无头苍蝇一样。 还是祭出CSAPP，里面对程序优化的介绍比较详细，充分利用 Cache 可以编写更高效程序。 奇技淫巧这里特别提名位运算，关键时刻可以省下大量的时间。 安利Hackers’ Delight 基本的算法设计思想递归，动态规划，不一而足，还是那句话，需要不断的刷题积累经验。","tags":[{"name":"BOJ","slug":"BOJ","permalink":"http://140.143.193.168/tags/BOJ/"}]},{"title":"TensorFlow For Docker 初体验","date":"2017-12-06T13:30:22.000Z","path":"2017/12/06/dockertf/","text":"TensorFlow 是一套开源的机器学习工具。一般来说只用 TensorFlow 的话配置运行环境什么的并没有特别坑的地方，但如果想用到 GPU 加速计算的话配置起来就要费好大一番力气了，还经常遇到各种版本不兼容、找不到依赖关系等问题，让人头疼。而 Docker 刚好是解决开源软件各种依赖关系的神物，NVIDIA 刚好又有工具能让容器用上 GPU 进行计算。 下面分享配置过程。 测试环境是 GTX850M+Ubuntu16.04.3+CUDA9.0+GeForce 384.00 驱动及 CUDA 安装过程参考即将到来的另一篇文章。 安装 Docker可以用curl -sSL https://get.daocloud.io/docker | sh这条命令快速安装 Docker，不过，这个安装脚本默认会安装最新版本的 Docker（当前是17.11.0 docker-ce），而 NVIDIA Docker 并不支持这个新版本（跪 所以要进行一下卸载再降级操作… 123456# uninstall dockersudo apt-get purge docker-ce# 查看软件库中可用的历史版本sudo apt-cache policy docker-ce# install docker-ce 17.09sudo apt-get install -y docker-ce=17.09.0~ce-0~ubuntu 值得一提的是17年的某个版本开始，docker 的软件包统一到 docker-ce（社区）和 docker-ee（付费企业版）上面来了，开发使用的主要以 docker-ce 为主，网上很多教程（尤其是2016年、2016年的）说到安装 docker 的软件包名叫例如 lxc-docker docker.io 等的都是老旧版本的。 安装 NVIDIA-dockerNvidia-Docker是老黄提供的一套在 Docker 上制造跑核弹的工具（。 简单来说，这套工具提供了一个运行时，用来连接 Docker 容器和物理设备的 GPU 资源，使得 Docker 容器可以直接访问、调用物理机的 GPU 资源进行密集型计算操作。 安装步骤如下： 12345678910111213# Add the package repositories 添加软件仓库curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | \\ sudo apt-key add -curl -s -L https://nvidia.github.io/nvidia-docker/ubuntu16.04/amd64/nvidia-docker.list | \\ sudo tee /etc/apt/sources.list.d/nvidia-docker.listsudo apt-get update# Install nvidia-docker2 and reload the Docker daemon configurationsudo apt-get install -y nvidia-docker2sudo pkill -SIGHUP dockerd# Test nvidia-smi with the latest official CUDA imagedocker run --runtime=nvidia --rm nvidia/cuda nvidia-smi 在 Ubuntu16.04测试通过。 安装 TensorFlow 的 Docker 镜像TensorFlow 官方提供了 for Docker 的镜像，里面集成了完整的依赖关系，免去了用pip安装各种包的烦恼。 镜像包含很多 tag，常用的有下面几个： tensorflow/tensorflow:latest，运行环境是 python2.7，仅支持 CPU tensorflow/tensorflow:latest-gpu，运行环境是 python2.7，支持 GPU 计算 tensorflow/tensorflow:latest-py3，运行环境是 python3.5，仅支持 CPU tensorflow/tensorflow:latest-gpu-py3，运行环境是 python2.7，支持 调用GPU 我自己用的是最后一个。 首先下载镜像下来。 1docker pull tensorflow/tensorflow:latest-gpu-py3 然后跑个 python3交互环境试试水 1docker run --runtime=nvidia --rm -it tensorflow/tensorflow:latest-gpu-py3 python3 在交互环境下输入import tensorflow as tf，如果没提示依赖库错误则说明安装成功。 上面的—runtime=nvidia为调用 nvidia-docker 工具包（运行时）而不是标准运行时来运行镜像，只有加了这个选项才能调用 GPU。 最后跑一下多重感知机训练手写数字识别，效果图 输出显示调用 GPU:0进行计算，说明配置一路顺风了。","tags":[{"name":"ML","slug":"ML","permalink":"http://140.143.193.168/tags/ML/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://140.143.193.168/tags/TensorFlow/"},{"name":"Docker","slug":"Docker","permalink":"http://140.143.193.168/tags/Docker/"}]},{"title":"最大概率汉语切分算法研究-(0)-概览","date":"2017-11-27T13:48:13.000Z","path":"2017/11/27/mpseg0/","text":"最近忙活了将近一个多月总算把计算语言学布置的最大概率汉语切分作业写完了，虽然中途一波三折，还发生了很多五光十色奇形怪状让人难忘的事情，所幸最后还是比较完整的写了出来，也学到了不少的知识。因此便有了这个系列的文章。 在这篇给出这系列文章的导航帖汇总。 至于代码嘛，等交完实验报告再说嗯。。 最大概率汉语切分算法研究（一）词典构建 最大概率汉语切分算法研究（二）BiGram语言模型 最大概率汉语切分算法研究（三）有向无环图（DAG）与最优左近邻词 最大概率汉语切分算法研究(四）FMM 与 BMM 在分词中的应用","tags":[{"name":"NLP","slug":"NLP","permalink":"http://140.143.193.168/tags/NLP/"}]},{"title":"最大概率汉语切分算法研究(四）FMM 与 BMM 在分词中的应用","date":"2017-11-25T10:04:43.000Z","path":"2017/11/25/mpseg4/","text":"本篇继续讨论对输入句子的处理问题。FMM 和 BMM 是指对输入句子分别找前向最长词和后向最长词，某种程度上来说属于贪心算法的一种，比较惊喜的地方是两者结合常常能获得比较不错的分词效果。 FMMFMM，可以理解成前向（Forward）最长词，就是对一个句子，每次切分找词的时候，都是从前往后“切出”最长的词和剩下的子句，例如： “有意见分歧”这句话，用 FMM 进行切分找第一个词的时候就会切分成： 有意/见分歧 只利用 FMM 进行分词时，对每次切分后的子句都反复寻找最长前缀词，直到子句为空。注意到，FMM 得到的切分序列是唯一的。 BMMBMM，可以理解成后向（Backward）最长词，就是对一个句子进行切分的时候，都是从后往前“切出”最长词和剩下的子句，例如 “有意见分歧”这句话，用 BMM 切分的时候会分成： 有意见/分歧 其中，“分歧”是寻找到的“第一个词”，“有意见”是待切分的子句。 用 BMM 分词的时候，对每次切分后的子句都反复寻找最长后缀词，直到句子为空。 FMM 与 BMM 组合分词只用 FMM 或 BMM 进行分词的话，由于算法本身“贪心”的属性，往往得不到最理想的切分结果。所以在进行汉语切分的时候，可以将两个算法结合使用，用于发现歧义（因为对于没有歧义的句子，FMM 和 BMM 得到的切分结果一定是一致的），也可以将两个算法得到的序列计算整句话的概率（利用 BiGram 模型），选取概率较大者作为最终的切分结果。","tags":[{"name":"NLP","slug":"NLP","permalink":"http://140.143.193.168/tags/NLP/"}]},{"title":"最大概率汉语切分算法研究（三）有向无环图（DAG）与最优左近邻词","date":"2017-11-25T08:51:09.000Z","path":"2017/11/25/mpseg3/","text":"本篇讨论的是对特定输入句子进行的处理过程。基本思想是对特定输入句子从前往后遍历找出所有词构成有向无环图，然后从最后一个词开始往前找每个词的“最优左近邻词”构成一个完整的词语序列。 DAGDAG，也就是有向无环图，可以用来记录一个句子的不同的切分状态集合，所谓的“向”就是句子从开始到结束的方向。假定句子的开始符为S，以“他们有意见分歧”这个句子为例，可以得到如下的有向无环图： 在生成一个句子的有向无环图的过程中，利用 BiGram 模型计算所有的转移概率并进行储存。 之后，从后往前回溯，寻找每个词的最优左近邻词，直到‘S’字符。结束。 从句子生成 DAG假设开始标识符为‘S’。 对于特定的一条输入句子sentence，原始问题可以理解成：由sentence和其前一个词‘S’构建有向无环图。 对 sentence进行分词操作，假设找到的第一个词为firstWord，输入句子 sentence便可切分为 firstWord + subsentence两部分，其中firstWord作为 subsentence的“前一个词”。原始问题便可归约为由firstWord 和 subsentence构建有向无环图（构建结果作为最终 DAG 的子图）。 根据上面的分析，构建完整DAG 的过程是一个递归求解的过程，完整的算法步骤描述如下（简记为 Alg-1)： 输入句子 sentence 以开始标记符“S”和 sentence 开始构建 DAG。（“S”作为整个图的开始结点，“源”点） 对 sentence从前往后找“第一个词”（firstWord），找到第一个词后，将 sentence划分为 firstWord 和 subsentence两部分。firstWord即可作为最终 DAG 的一个结点。 对 subsentence重复第三步的切分操作（寻找第一个词和子句），找到的“第一个词”作为最终 DAG 的结点，对子句继续切分（递归）。 递归结束条件：子句为空。 结束时，将所有最后一个词放入 endSet（结束词集合）里。 在 Alg-1的步骤3中要寻找“第一个词”，要注意的是，这个寻找过程不是一次性的，因为“第一个词”可能有多种情况，譬如，“有意见分歧”这句话中，对于第一个词，存在着 有/意见分歧 和 有意/见分歧 这两种潜在可能的划分，需要一并进行考虑。因此，寻找词的过程是一个循环的过程，设定上限值为15（汉语中基本不存在长度超过15的词），从第一个字开始向前寻找（切片）： 12for i in range(1,15): word = sentence[:k] 如果“切”出来的 word在词典中，则作为一个子问题，这样才能保证最后生成的 DAG 是考虑了所有可能情况的（考虑了所有的歧义）。 不过，这个“粗暴”的切分方式也存在着可见的缺陷。它会大幅度增大了有向无环图的规模（最坏情况下，所有的单字都作为图的一个结点）。对于长句子来说会极大的增大了生成时间，而且，这里用递归来生成子图，因此甚至存在递归过深导致堆栈溢出等问题，即使不是这样，也会显著的增加了程序运行时间。 减少无用递归经过多次痛苦的测试过程，摸索出减少无用递归的方法可以短暂缓解上面提到的缺陷。 考虑如下句子： 因为他们有意见分歧，会议的时间未能确定下来。 虽然在中文语义上，可以以逗号为分隔直接划分成两个子问题再进行切分生成 DAG，但在计算机中还是视为一个句子进行处理。 在“有意见分歧，”这里，存在至少两种切分： 有/意见分歧 和 有意/见分歧 无论这个子句如何切分，切分之后的两个子句 意见分歧，··· 见分歧，··· 除了第一个词之外都是重叠的，生成的子图也是一样的，无需重复的递归进行处理。 基于这种分析，在考虑生成 DAG 函数的关键参数：firstWord和 subsentence，将这两个参数构成一个元组（tuple），用一个集合记录下已经进行了“子图生成”的元组，每次要执行递归前，首先判断关键参数组合是否在集合中，如果在集合中则直接跳过，否则再执行递归过程，执行完毕后将关键参数组合添加到集合中。 最优左近邻词（bLAW）考虑词序列 $$w_1,w_2,w3,…,w{i-1},w_i,…,w_n$$ $w_{i-1}$即为$w_i$的左近邻词。 用输入句子生成 DAG 之后，对结束词集合中的每一个词，从后往前回溯，寻找每一个词的最优左近邻词，直到“S”结束，得到潜在的切分序列。如果切分序列不止一个的时候，则计算每个切分句子的概率，取概率较大者作为切分结果序列。 如何寻找最优左近邻词？考虑累计概率计算公式： $$P_a(w_i)=Pa (w{i-1})*P(wi/w{i-1})$$ 对每一个左近邻词（在 DAG 中表示为一个结点的所有前向相邻结点），计算累积概率，取概率较大者作为最优左近邻词。 潜在问题以下潜在问题的讨论仅限于本文讨论的 DAG 和寻找左近邻词的算法，并不一定 LAW 这个概念本身可能存在的问题。 “最优”只考虑了局部的情况，在语料库生成的搭配词典规模受到限制的场合，基于语料库训练出来的 BiGram 模型计算出来的累积概率与实际应用场景中“本该有”的概率存在较大差异，这种差异将直接反映在切分结果上。 生成 DAG 的过程以词本身而不是词在句子中的下标序号作为图的结点，对于一个存在重复词的句子，从后往前找左近邻词时可能进入死循环中。解决办法是每次寻找词的时候将这个词与它“本该”出现在句子中的位置进行比较再决定是不是 LAW 参考资料 jieba中文分词源码分析（三） 王小捷老师计算语言学课程相关课件资料","tags":[{"name":"算法","slug":"算法","permalink":"http://140.143.193.168/tags/算法/"},{"name":"NLP","slug":"NLP","permalink":"http://140.143.193.168/tags/NLP/"}]},{"title":"最大概率汉语切分算法研究（二）BiGram语言模型","date":"2017-11-25T08:51:06.000Z","path":"2017/11/25/mpseg2/","text":"BiGram 语言模型，也就是二元语法模型，起源于 NGram，属于 N = 2的情况。基本思想是当前词依赖于仅前一个词的出现概率。 模型简介N 元语法模型属于概率模型的一种。在 Ngram 语言模型的概念里，我们假设当前词出现的概率依赖于前面N-1个单词。 概率推导假设有单词序列$w_1,w_2,…,w_n$,将每个单词在它本身位置的出现看成一个独立事件，则这个单词串出现的概率可以表示为$P(w_1,w_2,…,w_n)$ 一般情况下将这个单词序列简记为$w_1^n$，由概率的链式分解规则，有 $P(w_1^n) = P(w_1)P(w_2|w_1)P(w_3|w_1^2)···P(w_n|w_1^{n-1})$ 在概率推导公式中，令$n=2$，式子可以简化为$P(w_1^n)=P(wn|w{n-1})$ 说人话？？？上面的概率推导很容易让人一头雾水，以“我喜欢你”这个句子为例，“我喜欢你”这个句子出现的概率，可以转化成“我喜欢”这个子句后面出现“你”这个词的概率，在二元语法模型中，就可以进一步等价成“喜欢”这个词后面出现“你”的概率。 也就是说，二元语法模型，将一句话出现的可能性，转化成一系列词语搭配出现的可能性。 模型训练由频率估计概率的方法，对于给定的语料库，不难得出如下公式： $P(wn|w{n-1})=\\frac{C(w_{n-1}w_n)}{C(w_n)}$ 还是以“喜欢你”这个句子为例，可以得到： $P(你|喜欢)=\\frac{“喜欢你”这个搭配在语料库中的出现次数}{所有以“喜欢”开头的双词搭配总数}$ 因此，训练的目标就是对于给定的语料库和词典，统计整个语料库中的所有双词搭配和对于具体的每一个词，统计以该词开头的所有双词搭配数目。也就是一个数数的过程。 平滑技术上面提及的 N 元语法的问题在于“数数”这个过程对语料库是强依赖的，而每个特定的语料库都是有限的，肯定无法覆盖汉语中出现的所有双词搭配。所以便有了平滑技术，为“零概率的二元语法”指派非零概率，也就是在计数后进行概率转换之前为计数为0的指派一个非零的计数值。 在这里使用了最简单的加一平滑，在二元计数矩阵中，归一化计算概率之前为所有的计数加一。 计算机编程实现模型表示在开发分词工具中，采用了 pandas 库提供的 DataFrame 这个二维的数据接口来表示整个模型，index部分是词典中的每一个词，col部分包含了两列，第一列是每个词出现的总数，第二列以字典类型来表示每个词所有可能的“下一个词”和对应出现次数。 平滑技术的处理假设词典里面有 $m$个词，按照上面的描述，需要一个$m \\times m$的矩阵来作为二元语法矩阵，加一平滑的时候遍历整个矩阵为每个元素加一。然而，从199801这个语料库中统计出来的词个数已经高达50000+，加载这么高维度的矩阵对于普通计算机来说显然是一笔很大的消耗。 而在这个模型表示中，只储存了所有出现过的“双词”搭配，将对未出现的搭配“赋值为1”的过程放在了概率计算部分，加快了模型的加载速度。 参考资料JMBook-自然语言处理综论","tags":[{"name":"NLP","slug":"NLP","permalink":"http://140.143.193.168/tags/NLP/"}]},{"title":"最大概率汉语切分算法研究（一）词典构建","date":"2017-11-25T08:51:02.000Z","path":"2017/11/25/mpseg1/","text":"最近忙活了将近一个多月总算把计算语言学布置的最大概率汉语切分作业写完了，虽然中途一波三折，还发生了很多让人难忘的事情，所幸最后还是比较完整的写了出来，也学到了不少的知识。因此便有了这个系列的文章。 问题基于最大概率的汉语切分工具的开发，是要利用计算语言学课上学到的知识，选用合适的模型开发一个汉语分词的工具并且进行代码测试与评估。 阶段划分一个完整的分词工具的开发包括以下几个步骤： 选择合适的语料库 根据语料库构建词典 选择合适的分词模型和平滑技术 语料库切分：训练集和测试集 模型训练 模型测试，包括分词技术调整等，增强代码健壮性 在本项目中选用的语料库是人民日报199801的语料库，分词模型选择2-gram 模型，平滑技术选用了最简单易行的加一平滑，分词技术包括了左近邻词，FMM 和 BMM 等，具体在接下来涉及到了再具体谈。 本文主要讨论的是从语料库构建词典的问题。 TrieTree与词典TrieTree，又名前缀词典树，是一个专门用于构建词典的数据结构，在这个数据结构上实现词语的添加和查找都可以获得非常高的效率。 TrieTree 的 python 实现在知乎的一个回答有非常简短的代码可以实现 TrieTree 的添加和查找功能，不过在这里要用 Trie 树构建词典的话还需要小小的修改，将该回答中叶子节点的’Exist’字段替换成’count’，用于统计每个词在语料库中出现的次数，每次添加一个词的时候，为后面的概率计算作铺垫。 语料库分析人民日报199801的语料库中，对于每一个词都是像泽民/nr这种形式，以/分割，前半部分为词，后半部分为该词的词性，词之间用两个空格进行分割。构建词典的时候，便可以读取语料库文件的每一行，用split()方法分割得到词列表，在每个词中再次执行分割获取每个词，添加到 Trie 树中，每次添加的时候首先进行判断，如果该词已经在树上，那么将该词的’ count’字段计数加一，否则，将词加入到词典树中，并将计数字段设为1。 词典写入到文件将词典写入到文件，其实就是遍历 Trie 树，每个包含‘count’键的节点对应于一个词，将这些词写入到文件中的过程。具体代码参考如下 123456789101112131415def foreachTree(TTree,string,file): if 'freq' in TTree : if len(TTree) == 1: print(string+' '+str(TTree['freq']),file=file) return else: print(string+' '+str(TTree['freq']),file=file) for kk in TTree: if kk == 'freq': pass else: foreachTree(TTree[kk],string+kk,file) else: for kk in TTree: foreachTree(TTree[kk],string+kk,file) 对于树这种递归定义的数据结构，解决问题的最方便的方法自然也是递归，由于汉语词汇挂在“树”上的时候，每个节点都是单个“字”，因此需要一个 String 变量作为函数参数，记录前面的遍历状态。 要注意的地方是判断是否是完整词语的条件是‘count’或者‘freq’是否在该节点对应的字典中，而不是是否为‘叶子节点’。","tags":[{"name":"Python","slug":"Python","permalink":"http://140.143.193.168/tags/Python/"},{"name":"NLP","slug":"NLP","permalink":"http://140.143.193.168/tags/NLP/"}]},{"title":"Javalin框架使用指南(2)","date":"2017-10-28T12:15:17.000Z","path":"2017/10/28/javalin2/","text":"前言 WebSocket协议是基于TCP的一种新的网络协议。它实现了浏览器与服务器全双工(full-duplex)通信——允许服务器主动发送信息给客户端。 最近在项目中需要开发响应 WebSocket 的服务器程序来实现向客户端推送视频流的功能，刚好 Javalin 在最新版本中已经添加了对 WebSocket 的基本支持，于是有了这篇文章。 依赖关系配置（基于 Maven）和前面一样，使用 Maven 作为项目的包管理工具。要使 Javalin 框架的应用程序完整支持 WebSocket，需要额外添加以下的依赖关系包： 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty.websocket&lt;/groupId&gt; &lt;artifactId&gt;websocket-servlet&lt;/artifactId&gt; &lt;version&gt;9.4.7.v20170914&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty.websocket&lt;/groupId&gt; &lt;artifactId&gt;websocket-server&lt;/artifactId&gt; &lt;version&gt;9.4.7.v20170914&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty.websocket&lt;/groupId&gt; &lt;artifactId&gt;websocket-common&lt;/artifactId&gt; &lt;version&gt;9.4.7.v20170914&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty.websocket&lt;/groupId&gt; &lt;artifactId&gt;websocket-api&lt;/artifactId&gt; &lt;version&gt;9.4.7.v20170914&lt;/version&gt;&lt;/dependency&gt; 为了避免一些千奇百怪的类、方法错误，建议加入的 jetty 依赖包的版本尽量保持严格一直（然而在目前的开发中还是遇到了奇奇怪怪的方法缺失错误，虽然不影响正常的运行不过看着还是蛮闹心的Orz） 四个基本方法和前面介绍的一样，Javalin 主要还是通过 lamada 表达式的方式来实现对特定路径的 WebSocket响应，基本的代码架构如下： 12345678910app.ws(\"/path\",ws -&gt;&#123; ws.onConnect(session -&gt; &#123; //do something &#125;); ws.onMessage((session,message) -&gt; &#123; &#125;); ws.onClose(/*insert you lamada expr*/); ws.onError(/*insert you lamada expr*/);&#125;); 四个以on开头的方法是实现 WebSocket 基本功能的方法，每个方法的基本含义如下： onConnect( session)用于处理客户端与服务器端的连接事件，用session来指代服务器端与具体某个客户端的连接本身。session中有个getRemoteEndpoint()的方法可以获取表征客户端的“端点”一类的东西，通过这个“端点”，可以随时“主动”的向客户端发送数据。这也是 WebSocket 的优势和魅力所在（一旦建立连接之后，服务器端可以根据具体情况随时主动的向客户端推送信息）。 onMessage(session,message)用于处理收到客户端信息时候的响应，session 的基本含义同上，message 表示来自客户端的信息。 onClose()用于处理连接关闭时的事件。 onError()用于发生错误时的响应。 其他Javalin 当中对于 WebSocket 的实现，主要是建基于 jetty 对 WebSocket 的支持的基础上进行了二次封装，所以，Javalin目前不支持的一些方法、操作等都可以单独引用 jetty 提供的方法进行实现，只是这时候更加要注意依赖关系等问题了。 除了绑定 lamada 表达式之外，app.ws()方法也可以将特定路径和实现了 WebSocket 响应的具体的类进行绑定，不过这个我还没有尝试过，理论上来说用起来会更加灵活，以后如果用到了也会写后续文章跟大家分享使用经验。","tags":[{"name":"Java","slug":"Java","permalink":"http://140.143.193.168/tags/Java/"},{"name":"Javalin","slug":"Javalin","permalink":"http://140.143.193.168/tags/Javalin/"},{"name":"WebSocket","slug":"WebSocket","permalink":"http://140.143.193.168/tags/WebSocket/"}]},{"title":"Javalin 框架使用指南（一）","date":"2017-10-24T06:28:20.000Z","path":"2017/10/24/javalin1/","text":"Javalin是一款建基于 jetty 的轻量级 RESTful 框架，支援 Java 和 Kotlin 编程语言，非常适合用来部署REST 风格的微服务程序，因为里面对 lamada 表达式的应用可以说是到了出神入化的地步，所以一直都是我最喜欢用的框架。这系列的文章主要是介绍如何在微服务开发中应用这套框架来进行开发。 安装Javalin 支持几乎所有常见的项目管理工具，出于一般性，文章中以 Maven 为例进行说明。 安装框架本体 在项目的 pom.xml文件中的&lt;dependencies&gt;&lt;/dependencies&gt;标签下粘贴以下代码。 12345&lt;dependency&gt; &lt;groupId&gt;io.javalin&lt;/groupId&gt; &lt;artifactId&gt;javalin&lt;/artifactId&gt; &lt;version&gt;0.5.4&lt;/version&gt;&lt;/dependency&gt; 这是官网中介绍的安装方法，要注意到，仅仅粘贴了以上代码段的话，会遇到两个问题： maven 默认的 JVM 环境是 JDK1.6，是不支持 Lamada 表达式这种尤物的，我们需要在项目中添加 Java8支持。 在pom.xml中粘贴以下代码： 123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 要注意到这段代码和&lt;dependencies&gt;&lt;/dependencies&gt;标签段是并行而不是包含关系的。 在运行过程中可能会遇到以下错误提示： 1SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. ​ ​ 虽然这个错误提示不会影响程序的正常运行，但强迫症总是让人不爽，解决方法是添加这个依赖关系 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt; 经过以上配置之后，就可以跑起第一段程序了 HelloWorldHelloWorld 是开发者学习新的编程语言、框架所绕不过去的坎，用 Javalin 开发一个 GET 方法访问根路径返回“helloworld”的 REST 服务器非常的简单。示例代码如下： 12345678import io.javalin.Javalin;public class HelloWorld &#123; public static void main(String[] args) &#123; Javalin app = Javalin.start(7000); app.get(\"/\", ctx -&gt; ctx.result(\"Hello World\")); &#125;&#125; 从代码中可以看出，通过一个 lamada 表达式就可以完成指定路径到具体响应方法的绑定操作，还有什么比这个更让 RESTful 微服务开发者拍手称快的呢。 简单说明一下，框架中用 Javalin 类型的一个对象实例来完成整个 RESTful 风格的服务器的全部操作。上述代码中，首先是实例化了一个名为app的 Javalin类型实体，然后调用了get(String path, lamada expression)，以 lamada 表达式的表示一个具体的响应操作，以字符串的形式表示具体的路径，将两者绑定到一体。方法名称get表示响应 REST 规范中的 GET 请求。 此外，ctx参数指代的是连接上下文，调用result()方法可以将字符串塞进响应体中进行返回。 MOREJavalin 框架的安装和第一个服务器程序都可以非常简便的就完成了，但这只是一个开始，通过 Javalin 框架可以完成非常复杂的响应逻辑，而且最近的更新版本中还加入了对 WebSocket 服务器的支持。接下来的文章将会介绍如何进行进一步的开发和遇到的常见问题等。 1024节日快乐:halloween:","tags":[{"name":"Java","slug":"Java","permalink":"http://140.143.193.168/tags/Java/"},{"name":"REST","slug":"REST","permalink":"http://140.143.193.168/tags/REST/"},{"name":"微服务","slug":"微服务","permalink":"http://140.143.193.168/tags/微服务/"}]},{"title":"vscode配置 c++ 开发环境(二):调试和头文件设置","date":"2017-10-18T06:28:45.000Z","path":"2017/10/18/vscode2/","text":"前言上次在vscode配置 c++ 开发环境(一):智能提示文章中介绍了如何在 vscode 中配置 c++语言的智能提示，时间又过了很久，vscode 用的也越来越得心应手，今天终于有机会更新这个系列的第二篇文章，讲讲如何配置includePath来避免不愉快的波浪线和怎么用 vscode 对 cpp 程序进行调试。 头文件目录配置在默认情况下，就算是已经将 cpp 开发相关的插件装好，用 VScode 打开一个 cpp 文件的时候，通常还会看到令人不悦的波浪线，就像下面这样： 刚开始的时候我也非常的头疼这个问题，后来在vscode 官方博客的文章中找到了解决方案。 首先，在使用习惯上，要用 vscode 打开源代码所在的文件夹而不是打开单个文件，比如所，我有个Josephus.cpp源文件在cppcode文件夹下，那么就要在终端上输入code cppcode 用 vscode 打开这个文件夹，再对那个源代码文件进行编辑和处理，而避免直接code Josephus.cpp打开单个文件。（下面的相关配置都是基于这个使用习惯的基础之上的） 然后，在文件夹下新建.vscode目录（如果该目录已经存在，则可以略过这一步）。 在.vscode文件夹下，新建c_cpp_properties.jsonjson 配置文件，在文件中粘贴以下代码： 12345678910111213141516171819202122232425262728&#123; \"configurations\": [ &#123; \"name\": \"Mac\", \"includePath\": [ \"/usr/include\", \"/usr/local/include\", \"/usr/include/c++/4.2.1\" ], \"browse\": &#123; \"limitSymbolsToIncludedHeaders\": true, \"databaseFilename\": \"\", \"path\": [ \"/usr/include\", \"/usr/local/include\", \"$&#123;workspaceRoot&#125;\" ] &#125;, \"intelliSenseMode\": \"clang-x64\", \"macFrameworkPath\": [ \"/System/Library/Frameworks\", \"/Library/Frameworks\" ] &#125; ], \"version\": 3&#125; 在这个配置文件中，includePath字段是指定 VScode\b 搜索头文件的目录，如果目录中不存在源代码里引用的头文件，则会有波浪线提示。 所以，将用到的头文件所在的位置都添加到该字段中，就可以解决“波浪线”问题了。 调试设置在 Windows 上面用 VS 进行 C++开发的时候，最吸引人的一个功能是完善的调试功能，\b类似的功能在 VScode 上也可以实现。 首先，在.vscode\b文件夹下新建 launch.json和tasks.json两个配置文件，其中，\blaunch.json文件是配置调试信息，tasks.json是用于配置编译信息。 tasks.json文件下，粘贴以下代码： 1234567891011121314151617&#123; \"version\": \"0.1.0\", \"command\": \"clang++\", \"args\": [\"-g\",\"$&#123;file&#125;\",\"-o\",\"$&#123;file&#125;.out\"], // 编译命令参数 \"problemMatcher\": &#123; \"owner\": \"cpp\", \"fileLocation\": [\"relative\", \"$&#123;workspaceRoot&#125;\"], \"pattern\": &#123; \"regexp\": \"^(.*):(\\\\d+):(\\\\d+):\\\\s+(warning|error):\\\\s+(.*)$\", \"file\": 1, \"line\": 2, \"column\": 3, \"severity\": 4, \"message\": 5 &#125; &#125;&#125; 上述代码中，command字段是编译程序（编译命令），根据个人喜好可以填g++或 clang++（编译 C++），如果想编译 c，也可以填 gcc 或 clang。args字段是编译时添加的指令，${file}.out\b\b中${file}指的是当前编辑文件的文件名。（如果是在 Windows 下面配置，需要写成${file}.exe） launch.json文件下，粘贴以下代码： 1234567891011121314151617&#123; \"version\": \"0.2.0\", \"configurations\": [ &#123; \"name\": \"(lldb) Launch\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"$&#123;file&#125;.out\", \"args\": [], \"stopAtEntry\": false, \"cwd\": \"$&#123;workspaceRoot&#125;\", \"environment\": [], \"externalConsole\": true, \"MIMode\": \"lldb\" &#125; ]&#125; &quot;program&quot;: &quot;${file}.out&quot;字段表示调试的目标程序。 两个文件都配置好之后，打开要调试的 cpp 文件，首先选择“任务”-&gt;“运行任务…”,弹出的窗口中选择\bclang++,这一步是编译程序生成.out 文件的过程。 运行完毕后，选择“调试”-&gt;”\b启动调试“或按 F5快捷键，启动调试。如果看到下面这样的\b界面，表示\b配置没有问题，进入调试过程。 参考网站如何在VSCode内编译运行C++","tags":[{"name":"vscode","slug":"vscode","permalink":"http://140.143.193.168/tags/vscode/"},{"name":"Microsoft","slug":"Microsoft","permalink":"http://140.143.193.168/tags/Microsoft/"},{"name":"c++","slug":"c","permalink":"http://140.143.193.168/tags/c/"},{"name":"IDE","slug":"IDE","permalink":"http://140.143.193.168/tags/IDE/"}]},{"title":"macOS下使用 docker 进行 CSharp 开发（一）","date":"2017-08-27T10:46:52.000Z","path":"2017/08/27/dotnetdocker/","text":"前言过去一年多时间里一直忙着准备考研、OJ、毕设这些东西，都没时间在微软的技术方面进行更深入的学习。现在很多事情都尘埃落定之后，终于可以重操旧业继续传教之路。因为研究生研究的方向跟 docker 有些关系，自己也觉得这玩意挺有意思的。所以，以后的一大段时间里都会探索.net 跟 docker 的结合的相关应用。这一系列文章如果没有特别说明，都是以 macOS 为主要的开发环境，也算是为微软的跨平台大业添砖加瓦了。 这篇算是一个起点，探讨在 macOS 环境下进行开发的相关配置。 安装 Docker 环境现在在 macOS 上安装 docker 已经没有以前那么复杂了。基本上就是下载 dmg 文件回来拖拖鼠标的事儿。在毕设那段时间的体验中，甚至觉得在 macOS 上安装 Docker 是最为简便快捷，很难出什么幺蛾子的。：） 下载地址：Docker 官网经测试现在不用翻墙就可以访问啦。要下载镜像的话还是配置加速器会比较快一些，我自己是配了阿里云提供的一个加速器地址。注册阿里云账号之后会免费提供。 下载 dotnet 镜像运行命令1docker pull microsoft/dotnet 默认下载的是 latest 版本。 基于镜像运行容器在开发中我的习惯是将源代码放到本地的文件夹中，然后将这个文件夹挂载到 Docker 容器里面，这样在本地就可以用自己熟悉的环境对源代码各种修改，容器那边只需要重启一下就会自动运行新版本的代码，十分方便。 运行以下命令：1docker run -it -v `pwd`:/csharp -w /csharp microsoft/dotnet 命令中通过-it开启了实时交互模式，只是因为在家里没梯子\b，下载 dotnet core 的 SDK 贼慢，只好采取此方法。实际应用的时候\b可以在本地 shell 先建立好项目编辑完源代码直接甩容器里跑最方便的。 新建项目、编辑代码、运行运行容器之后，在容器弹出的交互界面中，输入1dotnet new console -o hwapp 命令的基本含义是以控制台为模板新建一个名为hwapp的项目。在本机，用 vscode 打开工作目录下的 Program.cs 源文件，编辑代码，本次以输出“hello docker‘为例。编辑完代码，保存之后，在\b容器的终端中运行dotnet run运行项目。 //忽略第一次那个白痴错误（汗 后记到此为止，在 macOS 下用 Docker 运行.net 程序的第一次尝试就完成了。要补充的内容还有很多，比如配置 vscode 开发环境等等工作，也只能等到回校有畅快的开发环境再慢慢补完了。","tags":[{"name":"docker","slug":"docker","permalink":"http://140.143.193.168/tags/docker/"}]},{"title":"Java Mongodb 使用指南（一）增删查改","date":"2017-07-20T08:22:24.000Z","path":"2017/07/20/mongodbj/","text":"前言最近在重构之前宇宙 mei毕设项目的注册中心，为了跟 Docker 容器技术无缝衔接将原先的 SQLServer 换成了与前端统一的 mongodb。让人不愉快的是，java 调用 mongodb 时遇到了好些问题，首先是 mongo版本更新3.0.0之后DB 相关的 API 已经废弃不用了，直接导致很多不够新的书籍都不具有参考价值；此外无论官网提供的 API 参考还是网络上很多教程，要么就是甩了一堆天花龙凤的代码，要么就是摸不着头脑的类列表。所以才有了这篇方便理顺思路的文章。 基本概念先讲清楚两个后面用到的最重要的两个类：BSON和Document。 BSONBSON是 JSON 文件的二进制储存格式。在 mongodb 的 Java 驱动中，这种数据类型主要用于建立查询条件。比如说在 mongodb shell 里面.find({&quot;id&quot;:&quot;0001&quot;})这句话里面的{&quot;id&quot;:&quot;0001&quot;}部分对应在 Java 代码里面就是一个 BSON。 查询条件里面有个很有意思的概念是操作算子/条件算子，具体留到另一篇文章再说。 Document官方翻译是文档，就是对应于一条 JSON 格式数据。在使用中要注意的是这玩意不能用String 类型的 JSON 格式字符串来初始化，只能用 Map 类型或者单一键值对来初始化。 操作增（Insert）mongoCollection.insertOne(Document) 直接插入 Document 类型的数据。要注意的是这个插入默认是无条件的，是可以连续两次插入完全一样的文档（因为在 mongodb 内部是用_id来判断两个文档） 删（delete）mongoCollection.deleteOne(BSON) 这个方法可以用来删除满足条件的一条数据，BSON 用于定义条件，比方说，要删除 id 字段为0001的数据，构造的 BSON 对象就是new BasicDBObject(&quot;id&quot;,&quot;0001&quot;)，完整的调用语句就是mongoCollection(new BasicDBObject(&quot;id&quot;,&quot;0001&quot;))。 查（find）mongoCollection.find() 默认不加参数时，会返回这个集合中的所有文档，返回类型是一个类似迭代器的东西，要遍历查询结果时可以这样写： 1234FindIterable&lt;Document&gt; res = mongoCollection.find();for(Document item : res)&#123; //do something&#125; 在这段代码中的 res，有个.first()方法，返回所有结果的第一个元素，如果结果是空集的时候，方法返回null。有意思的是，就算结果集是空集（找不到任何东西），res 也不会是 null。所以判断查找是否成功对 first()方法判空。 mongoCollection.find(BSON) 传入参数是客制化的查找条件（BSON 格式） 改（update 或 replace）mongoCollection.replace(BSON,Document) 第一个参数是查询条件，第二个参数是完整的文档，这个方法的作用是将满足条件的文档用传入参数中的文档来进行替换。 .updateOne(BSON bson1,BSON bson2) 调用这个方法时，第一个 bson 是查询条件，第二个 bson （bson1）是替换目标，这个方法执行结果是查询满足条件bson1的结果，然后将这些文档的 bson1字段用 bson2代替。 这个方法执行起来可能会让人很无语，因为按照直觉，我们调用的时候可能更想做的是查找满足条件的文档，然后将里面的其他一些字段用 bson2替换掉。要实现这个功能也不是不可能的，不过要搞个嵌套 BasicDBObject，要用到$set操作算子。示例代码段如下： 12BasicDBObject opr = new BasicDBObject(\"$set\",new BasicDBObject(\"status\",\"on\"));mongoCollection.updateOne(new BasicDBObject(\"id\",\"0005\"),opr); 这段代码执行的结果是查找 id 是0005的文档，然后把这个文档中的 status 字段设为 on。","tags":[{"name":"java","slug":"java","permalink":"http://140.143.193.168/tags/java/"}]},{"title":"一年战争默示录","date":"2017-03-27T13:08:12.000Z","path":"2017/03/27/uc2017/","text":"前言2016年3月初, 正式确立考研的想法并且选择了跨考计算机科学与技术, 到2017年3月底刘老师的一句“已录取”一锤定音, 过去的整整一年, 就像是一场漫长的战争, 中间有很多事情需要被记录和回忆, 所以就有了这篇. 套用了 Gundam UC 时代番外篇作为标题, 不仅仅是因为时间的巧合, 还是因为考研这件事和UC0079的一年战争一样, 损耗了极大量的时间,精力, 金钱等等等等. 抉择在2016年年初,对考研这件事上还是抱着极端反对的态度, 因为这意味着会有大半年的时间放弃很多事情, 只能困在自习室里, 反复的刷题, 看书, 背诵, 更何况通信原理还是我不甚喜欢的科目, 而那个时候看803计算机学科综合, 还是四门极难的天书. 很庆幸的是, 改变会在三月份发生了. 那时候还想着一边跟父母说要考研, 一边默默去找实习找工作, 但第一次电话面试的时候, 就被狠狠的虐了一把, 操作系统, 计算机网络, 乃至很基本的计算机常识, 缺位的知识实在太多, 毕竟是大二的时候才培养出来的对计算机科学的兴趣, 平时虽然也写过一些洋洋得意的代码, 然而和科班出身的人还是没法比的. 那时候很后悔过去的三年没有好好的学习. 后悔归后悔, 丢下的东西就要想办法补回来. 在那个时间点上, 弥补的唯一方法就只有考研这条路了, 跨考803, 就可以有至少四个月完整的时间去真正接触计算机科学最基本的那几门学科, 就算最后考不上, 也至少为自己积累一些底蕴. 另外一个影响我决定的因素, 说起来有些不可思议又顺理成章. 过去三年, 由于某些众所周知的原因, 我一直在阅读各类关于思维, 学习习惯的心理学书籍, 看的书多了自然会手痒想实践,而都大三了也没几门专业课可以让我练手了, 剩下的都是通信网这么既没有兴趣也没什么大用的硬骨头. 于是, 我把目光放到了考研这件事上来, 从时间跨度,外部环境, 学习内容上看,确实也是不可多得的实验素材. 就这样, 做出了一年战争的决定. 改变世界的三本书没有这三本书, 我一定不可能坚持下来到现在, 更别说有看上去还不错的成绩了. 深入理解计算机系统( CSAPP)在追求计算机科学的路上绝对值得大书特书的一本书。其实大二的时候就买了,然而因为各种原因没有啃下来, 到了2016年的三月份作出决定之后, 忽然一下子就有了不妨试试的想法, 开始阅读. 对待这本书最好的方法当然是一边看书一边实践,在当时这么做的话很明显时间是相当不足的.无奈之下我只好采用了《如何阅读一本书》里面提到的快速阅读的方法.以尽可能快的速度通读全本, 记录每一章的重点, 寻找这本书的脉络和骨架. 即使是这么的阅读,拖延症的我也是花了整整一个月的时间。通读过后, 竟也有醍醐灌顶般的顿悟, 对于计算机学科, 从最开始的”信息=位+上下文”的基本公理，到操作系统的一系列基本概念,乃至最后的服务器编程, 都有了比较清晰的认知, 后来的学习中也慢慢发现，正是这种认知，为803专业课的学习扫清了几乎所有的障碍。除此之外,还在准备机试的时候体会到好些微妙的副作用, 这个以后有机会再说. 龟书——计算机科学的基础这是图灵社区一本免费公版的电子书，讲的内容非常之杂而且数学化，从递归思想讲起，到整整一章快五十页的大 O 复杂度推导，到常见的数据结构定义，再到离散数学基础，正则表达式，关系模型，再到最后的一点点数电知识，涉及的领域无孔不入。更加神奇的是，85%的概念都用递归的形式给出或者证明。 很遗憾，这本书没有看完，但最关键的地方都看了，涉及数据结构的都认真的看了一遍，尤其是大 O 那章，更是多遍过后仍然意犹未尽。 这本书带来的,是对数据结构概念的认知颠覆。大学的计算机类课程里，除了微机原理之外，唯一不到90分的就只有数据结构了，因为当时教材没选好，上课也不认真听，学的云里雾里，知其然不知其所以然，除了几个可以喃喃自语的弗洛伊德算法，D 算法之外，一无所获。正是这本龟书，展现给我不同的世界，每一种数据结构的由来，都能够结合递归讲得一清二楚。更加是给了我到后来面对笔试算法题“只要是递归能写的我都能做出来”的自信。 奇特的一生一本很普通的传记，讲述的一个不那么普通的前苏联昆虫学家的故事。里面贯穿的主题是时间统计法，这个方法给我接下来的几个月复习带来了无尽的启迪，也开始了一段颇为清奇的复习之路。 流水账模式-初试复习记录铺垫说了这么多，也是时候到了各种考研经验贴喜闻乐见的所谓时间分配+学习方法型的行文模式了。不过，在这篇默示录里，我并不想把接下来的这些作为经验方法来说，因为我自以为，无论是时间分配还是学习方法，都是极为私人的事情，每个人的思维习惯和自己的紧密相连的，靠模仿是不可能真正成功的（这也是我为什么现在不粉德约科维奇的原因之一）。再者，和北邮人论坛里一众大神的经验,尤其是那位我相当欣赏,佩服的成功考研清华的姑娘相比，我在复习的时候付出的东西也真的太少太少了。 八月份之前各种浪，期间看了麻省理工大学的线性代数公开课（这也是值得大书特书的课程，具体放到后面再讲），快速阅读了《现代操作系统》，《计算机网络——自顶向下方法》，顺路背了下红宝书英语单词。 八月份回家之后，全面复习正式拉开大幕。（别人都是七月回家八月回校开始复习。。我的奇葩复习之路就这么开始了(⊙﹏⊙)b） 在家二十五天时间，看完了一遍李永乐数学全书（没怎么做题，单纯记录一下重难点和奇技淫巧。。。），王道四本单科书看了两本半（差计算机组成后半部分和计算机网络全本，做每一节后面的选择题）。英语阅读看张剑的小黄文150篇，结果各种懵逼，只好作罢，继续背单词。 平均每天复习时间295分钟。 九月份到十月十五日回到学校之后，开始了每天直奔图书馆的日子，开始做题之后，发现了自己在数学尤其是微积分方面的严重不足，邂逅了《张宇高数18讲》，开始把每天学习数学的时间都放在了阅读18讲和做660题打基础上面了，一天二十几题，有点低效率。 专业课还是王道四本书，小题做完然后是极少的一些大题，然后看第二遍。没啥特别好说的。 英语继续小黄文，每天两篇，平均一篇错俩，一个单元错6到8个，心态略崩。 开始看政治大纲解析，抱着学累了娱乐的心态，画画重点，做做一千题。 平均每天学习时间330分钟。 十月中旬到十一月初一年战争中最为关键的一段时期，在 UC 时代里面大概是 阿姆罗坐上了RX-78，NewType 开始引起联邦和吉翁的注意。 在现实里也是这样，在这段时间，最重要的事情是投入时间做张宇《真题大全解30年数学真题》，在数学上收获了极为重要的自信。英语开始研究往年真题，第一遍。专业课的王道四本书二刷也完了，每天写一下阅读感悟之类的，把想了好久才想通的问题，看完特别叹为观止的问题记录一下。 政治还是老样子。 平均学习时间每天384分钟。 十一月白热化阶段。 数学每天都在做真题，有时还放放羊，并不能实现每天一套的宏愿，到最后十二月之前也总算能彻彻底底的完成了第一遍。张宇八套卷跟风买了，做了两套多一点，也确实太难，坚持不下去。找到自己薄弱的地方，针对性的看张宇的视频。 专业课开始撸小蓝书过去的十年408真题，也继续是选择大题拆分完成的思路，规定时间60分钟到75分钟完成选择题做完题分析一下不会的，做错的，也记录一下，顺带王道四本书挑重点三刷。 英语，真题二刷，这次是规定好时间90分钟完成选择题部分。然后就是开始整理作文模板了。并没有怎么写作文。。太懒 orz 政治，肖老八套卷上市，也就买回来做了，选择题部分认真做，错的也都不少，做完认真总结和回看大纲解析。风中劲草也上市了，看完了第一遍，记住的东西也并不多。 平均每天复习458分钟。 十二月这个月可就是争夺阿尔巴空的时候了。 数学没什么力气做四套卷八套卷，每天整理重做三十年真题中的错题，补补张宇的视频。然后看真题大全解的答案解析书。难题啃一啃。最后两周挑几份经典的往年真题重做一下，保持手感。 专业课做王道的八套模拟题，比408真题难，做下来还是很有收获的。 英语：练作文，练作文，练作文。翻译适当看看，真题可以再做一遍。 政治：肖秀荣四套卷，考完出来才会真正感叹准确度可以有多高。 平均复习时间每天497分钟。 每天的时间安排这里说的是复习阶段每天都适用的情况。 早上雷打不动做数学，无论状态多好或者多不好。一般早上有效复习时间最多150来分钟，八点多快九点的时候到图书馆，十二点吃饭，只有十二月才能经常实现180分钟+的有效复习时间。 下午是属于专业课和英语的时间，大概是60+90+25的套路，“60+90”是轮换制，比如说今天90分钟英语真题，60分钟专业课那么第二天就是60分钟英语90分钟专业课。25分钟是随心所欲的机动时间。 晚上属于整理知识点的时间，把白天做错的题目都再过一遍，以及回顾之类的。比较轻松 学科学习过程记录相比时间安排这种私人化的东西，针对不同学科的学习方法反而是更加固定一些,毕竟学科的特点都摆在那儿. 数学数学一包括完整的微积分部分,概率论和数理统计，线性代数。一个一个来。 微积分前面也说了，微积分部分的基础学的相当的不扎实，即是是看完了一遍全书，做题的时候还是被打成筛子了。这里很感谢一本书，《张宇高数十八讲》，如果说全书是极为详尽的知识参考的话，十八讲就是提供了解题最需要的方法论内容。而且张宇的娓娓道来的风格，很适合缺乏解题方法的初学者入手学习。 线性代数MIT 线性代数公开课+黄皮线性代数第七版（外国教材）+分阶习题线性代数部分 公开课是值得大书特书的部分。特别适合那种大一学线性代数最后通过了但还是一脸懵逼的同学。请扔掉所有从行列式入手的线性代数教材，这种从行列式再到矩阵的学习思路是及其反人类，也违反了线性代数学科最基本的原则的。 MIT公开课从线性方程组，再到矩阵，再到行列式的线索讲述这门极具吸引力的学科，把矩阵，线性空间，线性方程组，向量彻底的联系起来，才能够真正学懂线性代数。里面对于行列式用三大性质+延伸推导运算性质的方式来定义的方法，彻底帮我扫除了大一入学第一周就要面对用双竖线包围的一大堆数和奇奇怪怪的运算性质的恐惧。 概率论《概率与统计》一本书就够了，反而没什么好说的。。。 题集 660题-都是基础题，而且都是填空选择，拿来训练数学思维是相当有帮助的。一开始上手的时候千万不要因为题量大就产生恐惧心理，一天20道30道，坚持下来，就能发达。 30年真题——2017年刚好遇上了数学一放水的时候（习惯把这种年份比作快速硬地的比赛2333333333），所以往年真题的帮助特别大，难度适中，知识点覆盖全面。做的时候配合国誉双栏笔记本记录错题索引，得闲就翻一翻。到最后考试，发现每一道题都能在过去30年真题中找到解题方法。 四套卷八套卷：拿来观光奇技淫巧解题不错。 英语单词+真题，学习语言的方法不过是足够多的词汇量积累和大量重复的练习，将自己暴露在语言环境当中。 单词书红宝书+20天搞定考研词汇+不背单词 app 题集其实，只需要真题。 05-16年真题反复做，标注难词难句，理清结构，阅读题问题分类攻克 作文作文写得不大好，就算了不说太多了 作文素材是一定要积累的。模板要看，但也得会创新，要形成自己的东西，或者至少能将不同的模板搅在一起。 多总结，按照话题整理出不同的模板，例子，论证方法，这个是必须做的。追求高分的话还可以根据不同的论证方法按照不同行文方式来分类整理一次。 计算机学科基础综合这次考试专业课可是帮了大忙，本来还以为跨考的话专业课只要不拖后腿就行，结果貌似来了个网研院最高分，还是值得庆幸的。 书籍 王道四本单科书+八套模拟题+408真题+803真题，多做几遍，务求看懂。 现代操作系统+计算机网络(自顶向下)，拿来补基础知识用的。数据结构和计算机组成直接在龟书和 CSAPP 上顺带看了，帮助很大。不过国外的教材知识全面，内容充实，适合在特别早的阶段看，6月之后再开始的话时间会很紧，消化不良就不好了。 计算机专业课实际上都是融会贯通的，一切统一于 CSAPP（误。所以803的东西看起来虽然很多，但千万不要产生恐惧心理，要时刻从系统的观点来看待理解学习的知识，会事半功倍。 政治背背背背背背 书籍 大纲解析，肖秀荣精讲精练二选一 风中劲草+1000题（对于攻克选择题帮助会非常大） 肖老师八套卷四套卷：今年全面命中大题，不能不强烈推荐。四套卷大题必背，八套卷的选择题多做几次，大题多看，这儿肖老师的公众号讲得非常好，我就不班门弄斧了。 其实政治考的不算理想,选择题大翻车，所以更加没有什么学习方法可言了，毕竟在几乎整个复习阶段中政治都是拿来放松心情，拿来娱乐用的。 复试初试成绩出来之后就开始准备复试了。其实在初试结束彻底 happy 之后马上开始准备是相当好的，毕竟笔试6选4，时间紧任务重。再说诸如编译原理，计算机系统结构，人工智能这些课程，对于热爱计算机学科的人来说绝对是一道饕餮盛宴。 另外一个就是机试，OJ 的输入输出处理，测试数据覆盖等方面与平时开发写代码是很大的不一样的，等初试成绩出来之后就到kAri OJ 熟悉考试方式，每天水水题，美滋滋。 至于面试，运气还不错，碰到的题都是有点印象的东西，不至于哑口无言的尴尬局面，老师们也相当的友好。如果本科阶段多做些项目多参加一些竞赛的话会为面试增加更多的资本的。 后记能够保研还是千万别考研吧，牺牲的东西实在是太多太多了。 还是那句话，写下默示录目的就是拿来回忆用的，谈不上什么学习方法，时间分配方法，更加不能算什么经验了。里面可能最有用的就是提到的几本书了。 感谢一年战争能够有好不错的成功，光靠自己是完全不可能的，很多的人和事给我带来了无尽的帮助。 感谢小C 的图书馆座位，让我有四层大桌子的复习环境。 坐我右边的曹菊苣，平时交流数学，得到了很多的启发。 计算机学院事实上专业第一，大一就手撸操作系统的99壕，帮我解决了很多803的疑难杂症。 感谢 Andy Murray 的2016年年终第一，伦敦的终极之战为我的12月打了很多鸡血。 牛18带来的运气。 陪伴我刷题的钢笔们：三文堂 ECO，580RB，写乐1031，百乐74，永生698，Lamy Vista，等等等等。 墨水们：自由极乐，飞虎队，呆米家族，RK 铁胆 一半以上时间都用来种树的 oneplus3。 以及一时间可能想不起来的更多人和事。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://140.143.193.168/tags/随笔/"}]},{"title":"2017考研-北邮网研院机试试题 ProblemC","date":"2017-03-27T02:13:00.000Z","path":"2017/03/27/2017c/","text":"题目大意求给定高度为 n 的 AVL 树最少的结点数模$1e9+7$的值. Hint: $(a+b)\\%p = (a\\%p) + (b\\%p)$ 难点和解题思路原题目给出了关于 AVL 树的相关定义,帮助我们理解题目的相关概念. AVL树就是平衡的二叉排序树, 能够保证这棵树在满足二叉排序树基本特性的同时, 每一个非叶子节点的左右子树节点数之差不大于1. 关于高度为$h$的 AVL 树的最少节点数,其实是有递推公式的, 就是$h[n] = h[n-1]+h[n-2]+1, n&gt;2$ 根据这个递推公式, 就可以将问题从看似复杂的树问题转化为类似求解斐波那契数列的简单问题了. 还有一个坑点, 就是题目给出的AVL树的高度可能会很高, 从数据规模上看, 斐波那契型的数列通项都是指数型增长的, “正常”的数据类型分分钟存不下这么大的数据. 再仔细看题目, 要求的只是结果模$1e9+7$然后输出, 还给出了余数相关的定理来”暗示”, 不由得想到这样的思路, 首先建一个long long 类型的大数组h[MAX_N], 高度为i 的 AVL 树的节点数对1e9+7取模的结果储存在h[i]中, 然后用相同的递推关系计算数组的每一个元素. 而且, 还可以将取余操作简化为减法操作, 大大的降低算法的运行时间. 代码因为题目的原题和测试数据在考试结束之后就及时关闭了, 所以只能凭借记忆写下来. 123456789101112131415161718192021#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;long long w = 1000000007;long long res[100050];int main()&#123; int T; cin&gt;&gt;T; memset(res,0,sizeof(res)); res[1] = 1; res[2] = 2; for(int i=3;i&lt;100050;i++)&#123; res[i] = res[i-1]+res[i-2]; if(res[i]&gt;w) res[i]-=w; &#125; while(T--)&#123; int h; cin&gt;&gt;h; cout&lt;&lt;res[h]&lt;&lt;endl; &#125;&#125; 注意事项 long long 类型最好还是使用cout 来处理读写, 在本机调试时发现,用 printf(&quot;%lld&quot;)处理出现了奇奇怪怪的 bug, 用cout 就没事了. 数组预处理放在循环以外进行, 否则很有可能超时. 上面的示例代码, 在 BOJ 测试时时间性能是59ms( 上限是1000ms)","tags":[{"name":"BOJ","slug":"BOJ","permalink":"http://140.143.193.168/tags/BOJ/"}]},{"title":"BOJ 解题报告-268进程管理","date":"2017-03-11T12:36:09.000Z","path":"2017/03/11/268/","text":"前言进行 OJ 练习以来做的最复杂的一个题目,A 完之后趁热打铁写个解题报告. 题目描述详情访问268.进程管理 大体的意思就是实现操作系统中进程管理基本的 fork, kill 和查询功能 输入输出处理输入第一行是整数 T, 表示有多少组输入数据. 第二行是整数 N, 表示本组数据中有多少行命令. 接下来每一行是一条命令.形式如下 FORK PID_1 PID_2 KILL PID QUERY PID 难点一: 同时出现输入组数和操作的数量这是在之前做的题目中没出现过的.解决办法如下面代码 1234567while(T--)&#123; int n; scanf(\"%d\",&amp;n); while(n--)&#123; //do something &#125;&#125; 难点二: 如何应对输入命令的不同格式从给出的示例可见, FORK 后面有两个整形参数,其他两个命令后面都只有一个参数,这个时候如果只使用scanf()函数处理输入,会因为输入的变量个数不一致而出现奇奇怪怪的问题,所以转而先使用gets( char*) 获取一整行命令读进 buff 数组,然后用sscanf(char* source, char* fomat, …)进行处理. 要注意的是,因为 scanf(&quot;%d&quot;,&amp;n)之后会有个\\n 会塞在缓冲区, 影响 gets() 函数的正常读入,所以要先getchar() 一下. 另外, gets() 函数在 c11标准中不再被支持,使用之前要注意运行环境限制. 输出当输入命令为QUERY PID 的形式时会产生输出,如果查询的进程存在则输出 Yes, 否则输出 No.( 注意大小写) 解题思路和坑点数据储存首先要解决数据储存的问题. 采用 bool 类型数组记录每个进程的存在情况, 并且使用下标记录进程号. map&lt;int,vector&lt;int&gt; &gt;来记录每个进程及其子进程的映射.按照操作系统课本的思想采用链表记录最为恰当,但在 OJ 这种特殊情况下, 自然可以选择更加”偷懒”的方法.更何况 STL 的性能还是相当可靠的. 对于每一条命令,用sscanf 处理后将指令部分赋值到string 变量, 方便判断. 坑点一: 0进程不能被删除题目条件中说到0进程在任何情况下都是存在的,因此输入KILL 0不会有任何响应. 坑点二: 子进程的子进程要被删除比如说如下以来关系0-&gt;1-&gt;2-&gt;3-&gt;4,杀死1进程之后,后继的2,3,4进程都必须被杀死,否则会导致 WA. 使用递归删除的办法可以确保子进程的子进程会被安全删除. 不算坑的坑点三题目中还说到KILL 指令中如果是不存在或者已经结束的进程,则不采取任何操作.这一点在本题中靠输入来保证了,所以不用在代码中额外处理.否则,需要额外的数组来记录每个进程的出现情况. 程序代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include&lt;cstdio&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;cstring&gt;#include&lt;map&gt;using std::vector;using std::map;using std::string;char buff[20];char cmd[10];;map&lt;int,vector&lt;int&gt; &gt; relation;bool pid[105];void killKids(int x)&#123; if(!relation[x].empty())&#123; //no empty vector&lt;int&gt;::iterator j; for(j=relation[x].begin();j!=relation[x].end();j++)&#123; pid[*j] = false;//kill it killKids(*j);//kill them all &#125; relation[x].clear(); &#125;&#125;// kill kids methodint main()&#123; int T; scanf(\"%d\",&amp;T); while(T--)&#123; relation.clear();//init memset(pid,0,sizeof(pid)); pid[0] = true; int n; scanf(\"%d\",&amp;n); getchar(); for(int z = n;z&gt;0;z--)&#123; int x,y; gets(buff); if(sscanf(buff,\"%s%d%d\",cmd,&amp;x,&amp;y)==3)&#123; //FORK command if(pid[x])&#123; //x exist relation[x].push_back(y); pid[y] = true; &#125; &#125;else&#123; string act = cmd; if(act == \"QUERY\")&#123; if(pid[x]==1)&#123; puts(\"Yes\"); &#125;else&#123; puts(\"No\"); &#125; &#125;else if(act == \"KILL\")&#123; //end all kids if(pid[x]&amp;&amp;(x!=0))&#123; killKids(x); pid[x] = false;//kill x &#125; &#125; &#125; &#125; &#125;&#125;","tags":[{"name":"BOJ","slug":"BOJ","permalink":"http://140.143.193.168/tags/BOJ/"}]},{"title":"BOJ解题报告(2)-89-统计时间间隔","date":"2017-03-07T12:23:30.000Z","path":"2017/03/07/89/","text":"题目描述给出两个时间(24小时制)，求第一个时间至少要经过多久才能到达第二个时间。给出的时间一定满足的形式，其中x和y分别代表小时和分钟。0≤x&lt;24,0≤y&lt;60。 输入输出处理输入格式hh:mm,也就是在数字时钟中最常见的24小时表示法, 对于这种输入形式, 可以仿照87题中的技巧通过 scanf(&quot;%d:%d&quot;,&amp;hh,&amp;mm)的形式将时间和分钟分别复制到两个整形变量当中. 输出是最少经过的分钟数, 是一个整形变量,没有太多的技巧. 思路因为题目中要求输出的是分钟数,所以可以先将输入的两个时间换算成当天的分钟数,然后计算时间差就是所求. 要注意的是起始时间大于结束时间的时候, 求出t1-t2要加上24*60(一天的分钟数). 源代码12345678910111213#include&lt;cstdio&gt;int main()&#123; int T,x1,y1,x2,y2; scanf(\"%d\",&amp;T); while(T--)&#123; scanf(\"%d:%d\",&amp;x1,&amp;y1); scanf(\"%d:%d\",&amp;x2,&amp;y2); int t1 = x1*60+y1; int t2 = x2*60+y2; int res = ((t2&gt;=t1)?(t2-t1):(t2-t1+24*60)); printf(\"%d\\n\",res); &#125;&#125;","tags":[{"name":"BOJ","slug":"BOJ","permalink":"http://140.143.193.168/tags/BOJ/"}]},{"title":"BOJ 解题报告(1)-87-日期","date":"2017-03-07T11:58:57.000Z","path":"2017/03/07/87-cpp/","text":"题目描述请你计算出第X年Y月Z日是第X年的第几天。其中，1月1日是第一天，1月2日是第二天，以此类推。 计算时请注意闰年的影响。对于非整百年，年数能整除4是闰年，否则不是闰年；对于整百年，年数能整除400是闰年，否则不是闰年。如1900年和1901年不是闰年，而2000年和2004年是闰年。 题目链接 思路这是个典型的涉及闰年的日期问题, 要求解某一年是第几天.思路很直接,从月份入手,先计算前$ Y-1$个月一共有多少天,然后在加上这个月中这一天之前有多少天,就可以得到结果. 输入输出处理在所有 OJ 中,输入输出都是绕不过的坎,很多时候会因为输出处理不好而导致莫名其妙的 WA, 又有很多时候可以从输入格式中获得解题的灵感. 回到本题,输入格式为X:Y:Z的形式, X,Y,Z 都是整数, 以冒号隔开.这不由得让我们想到了可以利用 scanf 的格式字段做”手脚”, 直接将 X, Y, Z 读入到整形变量当中进行后续的处理.所以有了以下代码来处理日期的输入. 12int X,Y,Z;scanf(\"%d:%d:%d\",&amp;X,&amp;Y,&amp;Z); 输出方面,只需要输出天数,是一个整形变量,没有什么特别的技巧. 注意事项这部分描述题目中的”边沿”情况, 如果忽略这些情况,就会导致 WA 闰年的处理题目中也给出了提示.在代码中可以利用宏来判断闰年. 1#define ISYEAP(x) ((x%100!=0)&amp;&amp;(x%4==0))||(x%400==0)?1:0 使用宏的时候一定要注意, 编译器在编译的时候会将宏展开之后插到每一个调用宏的地方,为了避免由于运算符优先级问题带来奇奇怪怪的 bug, 建议前后用括号括起来,像这样( ISYEA(X)) 一月份1月份的时候,天数即为当日的日期,直接输出 Z 字段即可. 二月份这也是个容易踩坑的地方,大家都知道闰年要算2月29天,但有时太匆忙的时候,会糊里糊涂把闰年1月2月的日期也会莫名其妙的加上了”1天”,导致 WA. 因此要单独处理.也可以通过构造合理的if 语句和一月份的情况一起处理. 对每个月的日子进行预处理在程序开始之前可以定义一个数组储存每个月的天数, 计算日子时直接根据下标找到天数相加即可,可以减少代码量和运行时间. 预处理的时候要注意, c 语言的数组下标从0开始, 而月份是从1月开始,所以可以构造一个13个元素的数组并且让第一个元素值为0避免不必要的麻烦. 代码1234567891011121314151617181920212223242526#include &lt;cstdio&gt;#define ISYEAP(x) ((x%100!=0)&amp;&amp;(x%4==0))||(x%400==0)?1:0int daysOfMonth[13] = &#123;0,31,28,31,30,31,30,31,31,30,31,30,31&#125;;int main()&#123; int T; scanf(\"%d\",&amp;T); while(T--)&#123; int yy,mm,dd; int days=0; scanf(\"%d:%d:%d\",&amp;yy,&amp;mm,&amp;dd); if(mm==1)&#123; days = dd;//special situation &#125;else&#123; for(int i = 1;i&lt;mm;i++)&#123; days+=daysOfMonth[i]; &#125; days+=dd; if(ISYEAP(yy))&#123; if(mm&gt;2)&#123; days++; &#125; &#125; &#125; printf(\"%d\\n\",days); &#125; &#125;","tags":[{"name":"BOJ","slug":"BOJ","permalink":"http://140.143.193.168/tags/BOJ/"}]},{"title":"vscode配置 c++ 开发环境(一):智能提示","date":"2017-02-18T10:48:20.000Z","path":"2017/02/18/vscode/","text":"#前言vscode是微软推出的跨平台的编辑器, 开发者可以通过丰富的插件把它定制成最适合自己使用的开发环境. 对于我来说,它最吸引的地方之一就是可以为 Mac 还有 Linux 平台提供了与 Visual Studio 类似的智能提示功能. 正文 首先, 下载对应系统的 VScode. 如果是 Mac 系统,那么请安装 xcode 命令行工具,如果是 Linux 系统,请安装clang 编译器. 安装 cpptools 和 C++clang 插件.其中, cpptools 可以提供代码检错等功能,而 IntelliSense 功能,是通过 C++clang 插件实现的. 按command+,,打开用户配置文件setting.json, 将以下代码拷贝进去. 123456789&#123; \"clang.executable\": \"/usr/bin/clang++\", \"clang.completion.enable\": true, \"clang.completion.triggerChars\": [ \".\", \":\", \"&gt;\"], \"clang.cxxflags\": [\"-std=c++11\"]&#125; 要注意到配置文件是 json 格式,所以,如果之前已经有其它的设置,请按照 json 文件的语法格式将大括号里面的内容拷贝进去. 重启应用程序,即可享受 vscode 带来的智能提示功能了.效果图如下.","tags":[{"name":"M$","slug":"M","permalink":"http://140.143.193.168/tags/M/"}]},{"title":"通信的基础——大学这三年到底学了啥（主线课程篇）","date":"2016-03-08T14:33:57.000Z","path":"2016/03/08/Communication/","text":"前言每次跟其他专业的同学聊天的时候往往会被问到，“你们通信工程这个专业到底是学些啥的”，之前回答这个问题的时候一直都是支支吾吾，实在惭愧。到了这个学期，在几乎所有的专业基础课都学完的时候，总算可以稍稍整理一下这个问题了。 正文整理的第一件事，就是明确通信的概念。通信，就是说白了就是实现两点之间的信息传输。所以就字面上看，着眼点并不多，主要在于怎么表示信息和怎么传的问题。 本文的写作思路根据学校培养方案给出的每个学期开设课程的时间顺序来叙述。这两年多来学的课程庞杂，近乎无所不包，这里先整理出与通信最密切相关的课程来整理一下。 信号与系统这是通信工程专业首先接触的一门与“通信”这个概念密切相关的专业基础课。在这门课中，我们首先接触到了“信号”这个概念。 平时我们现实生活中听到的声音，看到的图像，每一个场景，都是信息。目前受到技术的各种限制，这样的信息是没办法直接传输的（这么传输可能需要无限的带宽，需要极强的抗干扰性能，等等）。目前基于电的形式运作的通信系统只能传输“电”，所以，引入了“电信号”的概念。 好了，有了电信号的概念，一切就方便了，因为“电”这个东西的很多特性是从19世纪就开始有所研究的。于是，就有了各种用函数表示的确定信号。 只有函数表示的信号是没有用的，就像在二进制代码中只知道1和0而不了解上下文一样。要怎么对这些信号进行处理呢？这个时候引入了三大变换：傅立叶变换，Laplace变换和Z变换。三个变换的本质都是将时域信号转换成变换域进行分析处理。这些变换一个主要目的就是将时域中繁琐的卷积操作转换为变换域相成操作，为分析运算带来巨大的方便。 关于变换域概念的理解，是理解系统的一个先决条件。我们都是生活在时域世界，简单来说就是一切按照时间顺序发展和变化的，这样的缺点就是在自己的角度没办法“高屋建瓴”的去分析问题，所以很多小说为了描述整个故事，都会有并行支线，描写同一个时段不同人物的活动，还利用各种叙述方式。变换域也是同样的道理，拿傅立叶变换（时域频域变换）来举例，可以理解成在同一时间点有不同频率的分量同时活动，傅立叶变换的目的，就是把这样一个个“人物”抽离出来进行分析处理。 说完变换域之后，终于可以到“系统”这个词了。我记得通信原理老师的一句经典名言“通信里面对信号所有的处理都可以理解成滤波器。”滤波器是一个具体的系统，也就是说，“所有系统的本质就是对信号进行各种处理”。这个处理，通常是频域的，对某个频域分量进行操作，比如“砍掉”一部分分量，“强化（增益）”某些分量，等等。 数字信号处理DSP，俗称“大山炮”，是通信主线课程的第二门专业基础课，顾名思义，在这门课上，讨论了“数字信号”的分析问题。 在信号与系统中，所有的信号都是“模拟”的，也就是时域连续，取值连续的信号。模拟信号的缺点就是无法用计算机进行处理。 数字信号，就是时域离散，而且取值离散的信号。数字信号可以通过模拟信号“取样，保持，量化”得到，在坐标系上表现出来就是一个个离散的点。 为了对数字信号的分析处理，引入了离散时间傅立叶变换和离散傅立叶变换的概念。DTFT是时域离散，变换域连续的，DFT是时域离散，变换域离散的。考虑到“系统”是对信号在变换域中进行处理，DFT更适合用计算机对信号进行分析处理。 随机信号分析这门课讨论的重点是随机信号。这样做的实际背景是在实际通信系统中，信号都是随机的，我们永远不能预测别人下一句话会说什么；另外，在传输过程中会收到噪声的干扰，噪声也是一种随机信号。然而，之前学过的课程都是针对确定信号，也就是有确定数学表达式的信号的。所以我们有必要讨论如何处理随机信号，这样才能讨论信号的传输过程。 随机信号没有确定的数学表达式，这并不意味着在这些信号面前无计可施。在这门课程中，一个极为重要的地方就是引入平稳随机过程的概念，基本思想就是虽然在某一时间点我们不能确定信号的表达式，但如果以时间差为自变量，就可以将某一类随机过程转变为确定的函数表达式进行讨论了。这类随机过程，就是平稳随机过程。 讨论平稳随机过程引入了相关函数的概念，从物理意义上来看，这是两个信号表达式的乘积，因此在变换域中不能像以前那样用幅度谱来讨论了，在此引入了功率谱。 把要讨论的主角介绍完毕之后，就是就此引出的几个相关概念，其中最为挥之不去的就是加性高斯白噪声和匹配滤波器这两个牛鬼蛇神了。 通信原理有了前面一系列的铺垫，各种概念定义表达式粉墨登场之后，终于迎来了这个专业基础课的最终“BOSS”，有多重要？之前的几乎所有课程都只讨论了“信”的来龙去脉，这门课着重在“信”的基础上研究“如何通”，讨论了所有情形之下的信息传输过程，把之前涉及的几乎所有相关知识串联起来，打通天地线，实现真正的通信大业。 因为学习这门课的时候，学院已经把前三章大部分内容抽离到随机信号分析课程了，所以很快就进入了对传输的讨论当中。首先是模拟信号的传输，在讨论中引入了调制和解调的概念，本质上就是实现信号在频域上的搬移，也为以后的讨论打下基调。 讨论完模拟信号的传输之后，就来到这整本书的重点，数字信号的传输。数字信号的传输包括了基带传输和频带传输。跟模拟信号不同的是，数字信号在基带和频带传输中都要进行调制的。因为理想的数字信号是冲激信号的线性组合，频带带宽无限带，根本没法直接传输，要所以进行脉冲编码调制，将其绝大部分能量集中在受限的带宽（成为“主瓣”）中，使传输成为可能。既然是传输，自然会受到噪声的影响，这里终于轮到“加性高斯白噪声”登场了。这种噪声特殊的地方就是在所有频段有相同的取值（就像Gundam里面GN粒子产生全频段电磁波干扰一样。。。）。这种噪声可以非常好的模拟信道传输过程中受到的“热噪声”等的特性，所以将会是整个讨论信号传输过程中的半个“主角”，在讨论信噪比时都默认收到的噪声是加性高斯白噪声。 另外就是匹配滤波器的概念。通过匹配滤波器，将接收信号的高斯噪声限值在传输带宽所覆盖的频域之内，使接收信噪比能够达到最大。 基带传输讨论完毕之后，就是数字信号的频带传输，具体的调制过程和模拟信号的调制过程有异曲同工之妙。真正特别的地方，就是为了提高信道利用效率而引入M进制调制的概念。 之后，就是在本学期学到通原2中学到的关于信息编码处理和信道编码等内容，由于刚开始学习，所以暂且不表。 END原本以为可以简要介绍，但不知不觉就来了废话一堆，能够把一个专业的核心问题说清楚真的不是什么轻而易举的事情，能够整理下来发现大学两年多也并非一无所获。等有时间了继续把其他光怪陆离的课程整理一下，也是对本科四年的一个交代罢了。 纰漏之处，还希望留言指正:-)","tags":[{"name":"Communication","slug":"Communication","permalink":"http://140.143.193.168/tags/Communication/"}]},{"title":"“软狗”的2015学习总结","date":"2015-12-26T06:09:48.000Z","path":"2015/12/26/2015/","text":"背景2015年转眼间来到了最后一周。大四考研的周末，在宿舍阅读了知乎上一些关于编程学习的文章，深觉自己也应该写下这一年来自己学习上碰到的坑和经验教训，也列举自己看过的一些书，供以后回顾时参考。 絮絮叨叨的一些一言蔽之，2015年是我自己在各方面都大胆探索尝试的一年。年初受知乎上萧大编程入门指南的启发,加上换上了新电脑的推动,开始了自己在编程学习上的系统探索,有人指路总比2014年“盲人摸象”般的窘迫境况好了不少。 编程语言随着学习的深入，我逐渐觉得，活跃在很多程序员社区上的所谓编程语言的争论，所谓”***才是最好的语言”的言辞，纯属奇谈怪论。计算机领域门派众多，不同领域会有不同的开发需要，不同的语言配合不同的开发工具在不同的领域自有自己的独到之处。如果还没接触某个领域，对该领域的编程语言，是没有任何质疑的权力的。入门学习编程时，选择一门看上去最讨喜的，又能体现计算机程序开发的精要的语言，学下去变是了。经历过小白阶段之后，更应该先定下自己感兴趣的领域（诸如人工智能，ML，DM，游戏开发，前端，移动开发，嵌入式等等等等），再根据领域的需要学习相应的语言。 我自己2015年在编程语言上学习的收获，在于以下两门语言的深入学习： C# 作为一名自称的“软狗”，不学习微软技术大系.NET Framework是不行的。（逃 C#作为整个庞大的.NET技术平台的顶梁柱，再配合上自家VS2015的有力驱动，还有MSDN堪称逆天般完善的知识库的支持，自然是入门微软技术学习的首选。在2015年1月就订好了C#的学习计划之后，中间磕磕碰碰，到年末，终于可以说自己基本上是入门了。期间用C#完成了必修课大作业（在此特别感谢上学期教我程序设计实践课程的吴铭老师，让我有摆脱枯燥落后而无聊的MFC的束缚，选择自己喜欢的编程语言完成课程作业的机会），让我对图形界面应用程序的开发有了初步的认知和体会。 C#带给我的收获，不仅仅是那些语言语法逻辑，背后更是一大类带自动内存管理的”面向对象“语言所共有的知识体系。学习了C#语言之后，对待诸如值类型和引用类型，“引用”的概念，“代码托管”，“虚拟机”，“字节码”，”运行时“等等看起来庞杂的概念，有了基本的认识。这些知识，不仅仅对C#学习有极大的帮助，在其他类似语言诸如Python，哪怕是C#的“死对头”Java语言的学习中，也是会起到不可或缺的重要作用的。考虑到这门语言的学习难度，将其作为”面向对象”语言体系的入门语言来学习，是一个非常明智的选择。 Python 从去年年底就嚷嚷着想学的语言，在今年年底，终于可以说自己有所进步了。 对于C++的学习者来说，Python以四空格划分代码区块的“诡异”语法，是初学者在学习上极大的雷区，一不小心就会带来诸多莫名其妙的报错，连”Hello World“都写不出来。在微软俱乐部里面，”学习Python语言需要游标卡尺“这个老梗，也时常成为大家的笑谈。然而，一旦找到一个好看耐“艹”（比如代码高亮，智能提示，自动缩进，PEP 8 代码规范提示…)的IDE辅助学习之后,无论从学习过程还是成就感上，都会有质的飞跃。经过种种的摸索踩坑，庆幸自己终于找到了这个工具——JetBrains-Pycharm Python是一门很活，很活的语言，无论从语法形式上，还是运行调试上，都是如此。在学习Python过程中感触最深的一点，就是很多函数的用法，我都是在Python交互环境中“试”出来的。Python交互环境是我最喜欢Python的一个地方，在这里你可以像Linux Shell那样，输入一条Python指令，就可以获得输出，通过输出可以学习到很多函数的用法，查看某个变量的具体类型等等工作，为后续的编程开发，省了不少力。 Python最具魔力的地方，是那一堆堆用不完的第三方库。这堆库让Python语言在时下最火的领域——人工智能，机器学习，数据分析，数据挖掘，“你老婆”等有一展拳脚的机会。 领域方向2015年我还是挺迷惘的，哪门编程语言都想学，，哪个方向都想尝试，但又怕学而无用，或者碰到了不适合自己的深坑，误了时光。总结下来，自己这一年好像在很多领域都有所接触，但都没深究，近乎一事无成罢了。开荒的领域，在这里还是要提一下的，希望在来年能从中找到一两个自己喜欢的领域深挖下去吧。 UWP应用开发 UWP，微软在Win10平台上的通用应用，基于C#写后台逻辑，XAML写前台界面。XAML简单易懂的语法可以为初学者带来极大的满足感，然而真正想开发出精美绝伦的通用应用，还是需要深入学习和领悟的。WPF这个庞大、特性丰富的界面框架和C#丰富的高级语言特性的学习，是在这方面成为高手的必经之路。 Python开发Web网页应用 在这里特指Flask和Django框架相关的开发。 Android应用的开发 是的没错，一个软狗也有过考虑开发Android应用的时候，主要还是“揾食艰难”，想找一些来钱快的领域学学，找点外快什么的。然而到最后不了了之。 计算机视觉 缘起大二小学期时候的创新实验。当初用OpenCV库搞了个所谓之”人脸识别”的项目，开发过程也不可谓不艰辛，在配置开发环境的时候就走了不少“弯路”，也要摸索很多之前毫无概念的方法。回想起来那段时间其实是自己今年收获最丰富的其中一段时间了。迫使自己重拾了荒废半年的C++，重温了很多基本概念，学习了计算机图像处理的一下核心思想方法。另外，人脸识别也把我带进了模式识别、机器学习的坑。 机器学习 由“人脸识别”带来的坑，然而学的很皮毛，暂且不表。 魔法书 总的来说，这年开的坑确实有点多，但又学的很不深入。到年末才渐渐意识到自己之前的心态之浮躁，不禁为之惭愧不已。到年末想投个实习简历，却发现自己近乎空白的项目经历，甚为汗颜orz。 致那个一直想跳未跳的坑——Gawain Open Sources Project（GOSP）从高三毕业开始就有想做一个属于自己的Android ROM给自己的手机用。然而前两年收到电脑硬件和移动设备的限制（大一是魅族MX2这个万年锁BL的混蛋，大二时信仰挚爱Lumia930）毫无进展。这年年末在电脑硬件和移动设备都能满足的时候，却在漫长坑多的下载源码和编译时间上打了个退堂鼓。或许真的能发布的时候，已经“猴年马月”之后了。 Achieve？今年如果真的有什么建设的话，就是这个博客了。在这方面幸好没有太大的犹豫，Hexo+ GayHub的部署方式，50美刀五年买到了最喜欢的域名，部署过程还顺路入门了Gayhub和Markdown，之后开发过程上也开始积累写下自己的遇到的问题和解决方法。这里感谢微软MSP项目给予我的动力。微软大法好哦耶！ 一些教训 在学习过程中永远不应该害怕走弯路。编程学习本身就是不断在碰坑中修正的过程。事实上，因为害怕走弯路而盲目模仿前人的所谓”经验”,”捷径”的过程，才最弯的弯路。 切忌浮躁，切忌浮躁，切忌浮躁。重要的事情说三遍！ 实践，永远是检验真理的唯一标准。 开发工具这个必须提的。工欲善其事，必先利其器。 一个完整好用的工具链可以省去很多功夫。之前经历过一系列的摸索，从写C++时候的Dev C++，到后来学Python时碰过Vim，敲过Emacs，尝试Eclipse+DevPy，倒腾VS2015+Pytools，还折腾过Sublime，Atom，VSCode编辑器之流。现在总算得到一系列比较完善的开发工具体系。 操作系统上，一直对MacOS的华丽界面和好用到爆炸的终端心向往之，无奈受阻于高昂的价格。尝试过Ubuntu，却无论如何都未能称心如意。到最后躁动的心皈依Windows 10，用Cygwin + Cmder 打造了界面和灵活性不输水果的终端。也算满足了日常使用的基本需要。 现在将自己目前觉得最顺眼的工具链列举记录，供以后重装系统换电脑之后快速配置参考。 操作系统：Windows 10 TH2 Build 10586 终端：Cygwin+Cmder C#开发：宇宙第一IDE VS2015 Community Python开发IDE：Pycharm。强推Monokai配色+Consolas字体 Python交互窗口：使用Cygwin下基于GCC的独立Python环境并独立安装pip。 编辑器SublimeText3。 博客写作Atom + MarkdownPad 今年看过的书絮絮叨叨说了这么多，到最后应该是整理一下今年看过的几本让我“醍醐灌顶”的著作。 《编码的奥秘——隐匿在计算机背后的硬件语言》 上学期学习数字电路与逻辑设计课程，一开始被一大堆的逻辑门电路弄的一头雾水，后来找到了这本“神作”，从最开始的电筒闪亮传输信息的情节开始，循序渐进，以汇编语言收尾，讲述了计算机硬件的编码逻辑的来龙去脉，扫清了学习的迷雾和烦恼。 《程序是怎样跑起来的》 日本人写的一本小书，补充了很多计算机的基础知识，讲解了诸如Windows分页文件等系统级别的“冷”知识，也涉及了CPU，内存等“硬”功夫。 《数学之美》 吴军老师结合自己在项目研发上的实际经验撰写的一本讲述了目前最火的几个领域上用到的数学知识原理。言简意赅，毫不沉闷。 最后的最后写在最后的也不算是对未来的展望了。2016年希望不要摔在同样的坑上。还有就是能成为正式MSP继续传教233333333","tags":[{"name":"Life","slug":"Life","permalink":"http://140.143.193.168/tags/Life/"},{"name":"编程","slug":"编程","permalink":"http://140.143.193.168/tags/编程/"}]},{"title":"Cygwin安装独立的pip环境","date":"2015-12-25T10:37:31.000Z","path":"2015/12/25/cygpy/","text":"前言在Windows下配置python的虚拟环境时常常会遇到各种各样的问题。所幸Windows平台下有Cygwin这个虚拟Linux的环境。在cygwin下安装了独立的Python环境后，再安装pip，即可通过pip install virtualenv命令安装Python虚拟环境，之后通过虚拟环境安装Flask，Django等网络开发环境就可以一气呵成了。 安装步骤 首先，安装Cygwin并在软件包选择页面选择安装Python软件包。 前往Get Pip下载get-pip.py文件到cygwin的home目录. 在Cygwin命令行环境下进行pip的安装。执行python get-pip.py命令即可。 安装完毕之后，关闭Cygwin交互环境再打开，就可以进行虚拟环境的安装了。pip安装成功的标志注意: 直接输入pip命令没有提示command not found并不能说明pip被成功安装在cygwin的python运行环境下。如果Windows下也存在Python和pip的话，在Cygwin命令行输入pip会直接调用Windows平台下的pip命令。 可行的判断方法如下：（以下命令均在Cygwin交互环境下输入） 命令行输入which pip返回的结果为’/usr/bin/pip’ 命令行输入pip -V返回的结果为pip 1.5.6 from /usr/lib/python2.7/site-packages (python 2.7) 至此，Cygwin下独立的pip环境已经配置完毕，之后就可以安装Linux下配置Flask，Pyramid或者Django环境的办法愉快的玩耍了。","tags":[{"name":"Python","slug":"Python","permalink":"http://140.143.193.168/tags/Python/"}]},{"title":"numpy学习笔记（1）--ndarray类型常用属性","date":"2015-12-23T14:39:36.000Z","path":"2015/12/23/numpy/","text":"前言NumPy是python中用于机器学习和科学计算的常用库。opencv for python中cv2.imread(&#39;image.jpg&#39;)命令读取图像返回的数据类型也是ndarray。今天将ndarray的一些常用属性记录下来，以便以后学习时进行参考。 ndarray常用属性 size: 表示array中拥有的总元素数量。 shape: 元组类型。该属性描述了ndarray的“形状”信息。shape[0]为行信息，shape[1]为列信息。 strides: 元组数据类型该属性返回每一个维度上元素的数量。 ndim: 表示这个ndarray的维度。也可以理解为shape属性返回的元组的数量。 T:表示ndarray矩阵的转置。 今天使用opencv做简单的图像处理时接触到的ndarray的相关属性主要就是以上5个。以后再学习过程中遇到的更多有用的属性时会及时做补充。","tags":[]},{"title":"使用动态规划求解字符串编辑距离问题(C#实现）","date":"2015-12-07T14:41:52.000Z","path":"2015/12/07/dp/","text":"前言上次提到会在后续通过实际例子更加深入的谈谈对解释四种四种基本算法设计模式的理解。今天说到的,是利用动态规划思想求解两个字符串的编辑距离。 正文问题背景 我们将两个字符串的相似度定义为：将一个字符串转换为另一个字符串时需要付出的代价。转换方法包括插入，删除和替换三种编辑方式。使用对字符串的编辑次数定义为转换的代价。最小的字符串编辑次数就是字符串的编辑距离。 –《算法的乐趣》 问题分析要使用动态规划思想解决这个问题，首先我们需要对问题进行阶段划分，确定边界条件，定义无后效性的几个子状态并且确定状态之间的转移关系，才能在每个子状态中寻找最优解最后得到原问题的解。 寻找子问题：在本问题中，假设原字符串为source，长度为m，目的字符串为target，长度为n。则问题可以描述为求解source[1..m]转换为target[1..n]所需要的最小编辑次数。注意到，当source的前i个字符和target的前j个字符之间的编辑距离确定之后，不会在后续求解中发生改变，因此此问题的子问题即可定义为求解source的前i个字符和target的前j个字符之间的编辑距离。 边界条件的确定：当source字符串长度为0时，编辑长度为target的字符串长度n（插入n个字符串）。当target的字符串长度为0时，编辑长度为source的字符串长度（删去m个字符串）。 关于“备忘录”：动态规划问题的一个特点是使用类似”备忘录“的”表“记录每个状态的相关信息。本问题中用d[i,j]定义为source的前i个字符和target的前j个字符之间的编辑距离，作为每个状态的标志。 状态之间的转换：以d[i-1,j]+1为删除字符时转移的状态,d[i,j-1]+1为插入字符时转移额状态，d[i-1,j-1]+1为替换字符串时转移的状态。 子问题的最优解：字符串之间的转换方式并不是唯一的，通过操作若干次添加字符，删除字符，替换字符操作都可以实现字符串转换，每次转换状态时，将三种操作方式中的距离的最小值作为d[i,j]，可以保证每个子问题的解都是最优的，从而保证整个问题的解是最优解。 具体代码使用C#语言实现。 using System; namespace EditDistance { class Program { public static int MAX_STR_LEN = 100;//initialize the max length of string static void Main(string[] args) { //test code Console.WriteLine(&quot;Please input Source string:&quot;); String src = Console.ReadLine(); Console.WriteLine(&quot;Please input Target string:&quot;); String dist = Console.ReadLine(); Console.WriteLine(EditDistance(src, dist)); } private static int EditDistance(string src, string dist) { int i, j; int[,] d = new int[MAX_STR_LEN,MAX_STR_LEN]; //initialize the margin condition for (i = 0; i &lt;= src.Length; i++) d[i, 0] = i; for (j = 0; j &lt;= dist.Length; j++) d[0, j] = j; for(i = 1;i&lt;=src.Length;i++) { for(j=1;j&lt;=dist.Length;j++) { if(src[i-1]==dist[j-1]) { d[i, j] = d[i - 1, j - 1]; } else { int edIns = d[i, j - 1] + 1; int edDel = d[i - 1, j] + 1; int edRep = d[i - 1, j - 1] + 1; d[i,j]=Math.Min(Math.Min(edIns,edDel),edRep); } } } return d[src.Length, dist.Length]; } } } 运行结果： 后记求解字符串的编辑距离问题应该是动态规划的最典型案例，体现了动态规划问题的基本特点。适合用动态规划解决的问题，一般都是可以划分多多个子状态的，每个子状态之间存在状态转移关系，每个状态的解一旦确定，就会用类似“备忘录”的表储存起来。在后续求解时，将会直接使用该状态的解，而且，不会再回溯子状态的时候改变该状态的解。 另外，边界条件的确定是问题求解时的一个重要步骤。如果忽略了边界条件，或者在求解时没有正确初始化边界条件（比如在本题中对d[i,0]和d[0,j]需要初始化为i和j），将得不到正确的解。","tags":[{"name":"算法","slug":"算法","permalink":"http://140.143.193.168/tags/算法/"}]},{"title":"用diskpart打造Win 10安装U盘","date":"2015-11-27T09:54:26.000Z","path":"2015/11/27/Win-10/","text":"前言本文主要介绍通过diskpart命令行的方式制作Windows10引导U盘，制作完毕后，该U盘可以用于安装（包括全新安装和升级安装）Windows10操作系统，也可以在系统无法启动的时候使用该U盘进行修复操作。 正文需要的材料 Windows 10 Build 10586 安装镜像。（推荐从北邮人BT或者IT之家搜索相关的镜像。另外32位或者64位的系统镜像均适用本教程。） 容量大于4GB的U盘一个。建议适用USB3.0的U盘以获得较快的安装速度。请提前备份好用户数据。 以管理员账号登录当前系统。制作步骤 启动当前系统进入桌面环境之后，将U盘插入电脑。在开始菜单中搜索cmd或命令提示符，并右键，选择以管理员身份运行。 在命令提示符窗口中输入diskpart，按回车。 弹出的UAC窗口中选择允许，进入diskpart程序。 在Diskpart程序中，输入list disk查看当前的磁盘列表。 根据容量查看自己的U盘对应的磁盘号。这里假定第一个磁盘为你的U盘。输入select disk 1选中你的U盘。 输入clean，清除U盘内容。 输入create part primary，用于在U盘中创建主分区。大小为U盘的容量大小。 输入format，格式化刚刚创建好的磁盘分区。磁盘格式默认是FAT32。 输入active，激活主分区。这步非常重要，如果忘记输入这条命令，制作的U盘将无法激活。 输入exit，退出程序。 用文件管理器打开下载好的Win10安装ISO镜像文件，将里面的内容全部复制到U盘中。 至此，一个可以在目前绝大部分新的笔记本电脑上启动的Windows10启动U盘已经制作完毕。在BIOS中选择用U盘启动即可进入亲切的Windows10安装界面了。后记虽然目前有很多工具可以制作启动U盘，但本文介绍的方式具有独特的优势，在你想更换别的版本的系统比如制作ubuntu启动盘（逃 的时候，只需要把U盘里面的内容全选删除，并且把ubuntu安装镜像的内容完整复制过去就可以了，不用借助任何其他工具再次制作。","tags":[{"name":"Win10","slug":"Win10","permalink":"http://140.143.193.168/tags/Win10/"}]},{"title":"四种基本的算法设计模式","date":"2015-11-16T15:15:01.000Z","path":"2015/11/16/四种基本的算法设计模式/","text":"前言最近在阅读一本有趣的算法书，书中作者列举了四种基本的算法设计模式，我总结摘录得到本文。今天先给出文字总结。随着阅读的深入，以后会给出四种设计模式的典型案例。 正文贪婪法- 核心思想： 将原问题划分为多个子情况考虑，在每一个子情况中寻求其局部最优解，然后将局部最优解按照一定的方式（这种方式通常与子问题的划分方式有关）堆叠得到原问题的解。 - 特点： 1. 这种方法不用考虑子问题之间的相互影响（这一点区别于动态规划方法），通俗的说，就是不用“瞻前顾后”。 2. 在每个子问题中都应用了局部最优原则，寻求该子问题的最优解。 - 一般思路： 定义最优解模型-&gt;划分子问题-&gt;定义子问题的最优解结构-&gt;确定局部最优解，并堆叠出全局最优解。 分治法- 核心思想： 将大问题划分为一系列子规模较小的相同问题（解结构相同，子问题之间相互独立），寻找子问题的解之后将结果合并得到原问题的解。 - 特点： 子问题的划分不一定只有一次，而且往往不止一次，划分的目的是使每一个子问题相互独立而且是容易求解和能够最后组合得到原问题的解。正因为这个特点，分治法与递归思想总是密不可分的。 - 难点： 子问题的划分方式和最后结果的合并。如果用递归去解决分治法问题时，难点就是寻找递归关系式和确定递归终止条件。 - 举例：N点离散傅里叶变换的快速计算 动态规划- 核心思想： 要解一个给定问题，我们需要解其不同部分，再合并子问题的解以得到原问题的解。 - 特点： 1. 动态规划在查找有很多重叠子问题的情况的最优解时有效。它将问题重新组合成子问题。为了避免多次解决这些子问题，它们的结果都逐渐被计算并被保存，从简单的问题直到整个问题都被解决。因此，动态规划保存递归时的结果，因而不会在解决同样的问题时花费时间。 2. 适用于无后效性的问题。子问题的解一旦确定之后就不会改变，不受之后包含它的更大的问题的求解。 3. 适用于子问题相互重叠的情况。动态规划会创建一张“表”记录每个子问题的计算结果，当再次需要计算此问题时就可以通过查表快速得到结果，简化计算。 - 一般思路： 定义最有子问题-&gt;定义状态-&gt;定义决策和状态转换方程式-&gt;确定边界条件。 - 举例： 斐波那契数列的计算（在计算过程中保存每一步的f(n)）、0-1背包问题 穷举法- 核心思想： 在解空间之内穷举并测试每个可能的结果。 - 穷举策略： 1. 盲目搜索算法。 2. 启发式搜索（开始搜索时加入了一定的附加条件） 3. 剪枝策略：跳过一些明显不会是最优解的分支的搜索。 - 应用举例：很多NP问题的求解最后都是用了枚举法。 后记四种基本的设计模式并不是相互对立的。有时一个问题可以用一种或多种的设计模式去解决，而且，附加的条件不同时，应用的设计方法也不同。一个典型例子就是背包问题（多件体积不同，价值不同的物品放入体积一定的背包，求解价值最大的方案），既可以通过穷举所有情况解决，也可以引入价值密度的概念，用贪婪法设计解决(每次都放入价值密度最高的物品），还可以用动态规划解决（还没透彻理解QAQ）。上面的内容很多都是自己整理书中内容加上自己的一点想法写成的，感觉还是太抽象了，也难免有各种疏漏和错误，欢迎大家留意指正，多多交流。以后补充实际问题结合代码更加深入的分析每一个方法的奥妙。","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://140.143.193.168/tags/读书笔记/"},{"name":"算法","slug":"算法","permalink":"http://140.143.193.168/tags/算法/"}]},{"title":".NET学习笔记（一）","date":"2015-10-21T08:28:40.000Z","path":"2015/10/21/NET学习笔记（一）/","text":"基础类型相关 .NET中所有内建类型都继承自System.Object,若同时继承自System.ValueType类则为值类型，否则为引用类型。 值类型和引用类型的区别如下： 赋值时，值类型变量会直接获得真实数据的一个副本，而引用类型只会将对象的引用赋值给变量，会造成多个对象指向同一个内存区块（对象实例）的情况。 内存分配时，引用类型对象会在堆上分配内存，而值类型变量会在堆栈上分配内存，运行效率比堆高很多。 装箱拆箱的概念 装箱，指的是CLR需要做额外工作把堆栈上的值类型移动到堆上。 拆箱，指的是把堆中的对象复制到堆栈中，返回其值。 应该注意的是，装箱和拆箱行为，都对应了堆栈上的一系列操作，会造成较大的性能代价。因此减少程装箱拆箱操作，是程序性能优化的一个重点。 避免装箱拆箱操作的思路，在于从两方面避免发生装箱拆箱行为的场合： 值类型的格式化输出。 System.Object类型的容器。对于这种情况，可以使用泛型技术来避免使用System.Object类型的容器。 原文链接.NET基础拾遗(1)类型语法基础和内存管理基础","tags":[{"name":"C#","slug":"C","permalink":"http://140.143.193.168/tags/C/"},{"name":".NET","slug":"NET","permalink":"http://140.143.193.168/tags/NET/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://140.143.193.168/tags/读书笔记/"}]},{"title":"Hello World","date":"2015-09-24T08:29:46.000Z","path":"2015/09/24/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://140.143.193.168/tags/Hexo/"}]}]